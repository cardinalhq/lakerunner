// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0

package lrdb

import (
	"database/sql/driver"
	"fmt"
	"time"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

type ActionEnum string

const (
	ActionEnumCompact ActionEnum = "compact"
	ActionEnumRollup  ActionEnum = "rollup"
)

func (e *ActionEnum) Scan(src interface{}) error {
	switch s := src.(type) {
	case []byte:
		*e = ActionEnum(s)
	case string:
		*e = ActionEnum(s)
	default:
		return fmt.Errorf("unsupported scan type for ActionEnum: %T", src)
	}
	return nil
}

type NullActionEnum struct {
	ActionEnum ActionEnum `json:"action_enum"`
	Valid      bool       `json:"valid"` // Valid is true if ActionEnum is not NULL
}

// Scan implements the Scanner interface.
func (ns *NullActionEnum) Scan(value interface{}) error {
	if value == nil {
		ns.ActionEnum, ns.Valid = "", false
		return nil
	}
	ns.Valid = true
	return ns.ActionEnum.Scan(value)
}

// Value implements the driver Valuer interface.
func (ns NullActionEnum) Value() (driver.Value, error) {
	if !ns.Valid {
		return nil, nil
	}
	return string(ns.ActionEnum), nil
}

type SignalEnum string

const (
	SignalEnumLogs    SignalEnum = "logs"
	SignalEnumMetrics SignalEnum = "metrics"
	SignalEnumTraces  SignalEnum = "traces"
)

func (e *SignalEnum) Scan(src interface{}) error {
	switch s := src.(type) {
	case []byte:
		*e = SignalEnum(s)
	case string:
		*e = SignalEnum(s)
	default:
		return fmt.Errorf("unsupported scan type for SignalEnum: %T", src)
	}
	return nil
}

type NullSignalEnum struct {
	SignalEnum SignalEnum `json:"signal_enum"`
	Valid      bool       `json:"valid"` // Valid is true if SignalEnum is not NULL
}

// Scan implements the Scanner interface.
func (ns *NullSignalEnum) Scan(value interface{}) error {
	if value == nil {
		ns.SignalEnum, ns.Valid = "", false
		return nil
	}
	ns.Valid = true
	return ns.SignalEnum.Scan(value)
}

// Value implements the driver Valuer interface.
func (ns NullSignalEnum) Value() (driver.Value, error) {
	if !ns.Valid {
		return nil, nil
	}
	return string(ns.SignalEnum), nil
}

// Tracks the last successfully processed Kafka message offset per consumer group/topic/partition to enable exactly-once processing semantics
type KafkaOffsetJournal struct {
	// Kafka consumer group name (e.g., lakerunner.ingest.metrics)
	ConsumerGroup string `json:"consumer_group"`
	// Kafka topic name (e.g., lakerunner.objstore.ingest.metrics)
	Topic string `json:"topic"`
	// Kafka partition number within the topic
	Partition int32 `json:"partition"`
	// Last Kafka message offset that was successfully processed and committed to storage
	LastProcessedOffset int64 `json:"last_processed_offset"`
	// Timestamp when this offset was last updated
	UpdatedAt time.Time `json:"updated_at"`
	// Organization UUID for multi-tenant offset tracking
	OrganizationID uuid.UUID `json:"organization_id"`
	// Instance number for distributed processing offset tracking
	InstanceNum int16 `json:"instance_num"`
}

type LogSeg struct {
	OrganizationID uuid.UUID                 `json:"organization_id"`
	Dateint        int32                     `json:"dateint"`
	SegmentID      int64                     `json:"segment_id"`
	InstanceNum    int16                     `json:"instance_num"`
	Fingerprints   []int64                   `json:"fingerprints"`
	RecordCount    int64                     `json:"record_count"`
	FileSize       int64                     `json:"file_size"`
	IngestDateint  int32                     `json:"ingest_dateint"`
	TsRange        pgtype.Range[pgtype.Int8] `json:"ts_range"`
	CreatedBy      CreatedBy                 `json:"created_by"`
	CreatedAt      time.Time                 `json:"created_at"`
	SlotID         int32                     `json:"slot_id"`
}

type LrdbExemplarLog struct {
	CreatedAt           time.Time      `json:"created_at"`
	UpdatedAt           time.Time      `json:"updated_at"`
	OrganizationID      uuid.UUID      `json:"organization_id"`
	ServiceIdentifierID uuid.UUID      `json:"service_identifier_id"`
	Attributes          map[string]any `json:"attributes"`
	Exemplar            map[string]any `json:"exemplar"`
	Fingerprint         int64          `json:"fingerprint"`
	RelatedFingerprints []int64        `json:"related_fingerprints"`
}

type LrdbExemplarMetric struct {
	CreatedAt           time.Time      `json:"created_at"`
	UpdatedAt           time.Time      `json:"updated_at"`
	OrganizationID      uuid.UUID      `json:"organization_id"`
	ServiceIdentifierID uuid.UUID      `json:"service_identifier_id"`
	Attributes          map[string]any `json:"attributes"`
	Exemplar            map[string]any `json:"exemplar"`
	MetricName          string         `json:"metric_name"`
	MetricType          string         `json:"metric_type"`
}

type LrdbExemplarTrace struct {
	CreatedAt           time.Time      `json:"created_at"`
	UpdatedAt           time.Time      `json:"updated_at"`
	OrganizationID      uuid.UUID      `json:"organization_id"`
	ServiceIdentifierID uuid.UUID      `json:"service_identifier_id"`
	Attributes          map[string]any `json:"attributes"`
	Exemplar            map[string]any `json:"exemplar"`
	Fingerprint         int64          `json:"fingerprint"`
	SpanName            string         `json:"span_name"`
	SpanKind            int32          `json:"span_kind"`
}

type LrdbServiceIdentifier struct {
	ID             uuid.UUID   `json:"id"`
	CreatedAt      time.Time   `json:"created_at"`
	UpdatedAt      time.Time   `json:"updated_at"`
	OrganizationID pgtype.UUID `json:"organization_id"`
	ServiceName    pgtype.Text `json:"service_name"`
	ClusterName    pgtype.Text `json:"cluster_name"`
	Namespace      pgtype.Text `json:"namespace"`
}

type MetricSeg struct {
	OrganizationID uuid.UUID                 `json:"organization_id"`
	Dateint        int32                     `json:"dateint"`
	FrequencyMs    int32                     `json:"frequency_ms"`
	SegmentID      int64                     `json:"segment_id"`
	InstanceNum    int16                     `json:"instance_num"`
	TsRange        pgtype.Range[pgtype.Int8] `json:"ts_range"`
	RecordCount    int64                     `json:"record_count"`
	FileSize       int64                     `json:"file_size"`
	IngestDateint  int32                     `json:"ingest_dateint"`
	Published      bool                      `json:"published"`
	Rolledup       bool                      `json:"rolledup"`
	CreatedAt      time.Time                 `json:"created_at"`
	CreatedBy      CreatedBy                 `json:"created_by"`
	SlotID         int32                     `json:"slot_id"`
	Fingerprints   []int64                   `json:"fingerprints"`
	SortVersion    int16                     `json:"sort_version"`
	SlotCount      int32                     `json:"slot_count"`
	Compacted      bool                      `json:"compacted"`
}

type ObjCleanup struct {
	ID             uuid.UUID `json:"id"`
	DeleteAt       time.Time `json:"delete_at"`
	OrganizationID uuid.UUID `json:"organization_id"`
	InstanceNum    int16     `json:"instance_num"`
	BucketID       string    `json:"bucket_id"`
	ObjectID       string    `json:"object_id"`
	Tries          int32     `json:"tries"`
}

type PackEstimate struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	FrequencyMs    int32     `json:"frequency_ms"`
	TargetRecords  *int64    `json:"target_records"`
	UpdatedAt      time.Time `json:"updated_at"`
	Signal         string    `json:"signal"`
}

// Enhanced debugging journal for segment operations. Tracks record counts, time windows, and frequency changes for compaction and rollup debugging.
type SegmentJournal struct {
	ID int64 `json:"id"`
	// Signal type being processed (1=logs, 2=metrics, 3=traces)
	Signal int16 `json:"signal"`
	// Action being performed (1=ingest, 2=compact, 3=rollup)
	Action    int16     `json:"action"`
	CreatedAt time.Time `json:"created_at"`
	// Organization ID for determining storage bucket/profile
	OrganizationID uuid.UUID `json:"organization_id"`
	// Instance number for determining storage bucket/profile
	InstanceNum int16 `json:"instance_num"`
	// Date being processed (YYYYMMDD format)
	Dateint     int32 `json:"dateint"`
	SourceCount int32 `json:"source_count"`
	// S3 object keys for source files (for fetching and testing)
	SourceObjectKeys []string `json:"source_object_keys"`
	// Total records from all source files
	SourceTotalRecords int64 `json:"source_total_records"`
	// Total bytes from all source files
	SourceTotalSize int64 `json:"source_total_size"`
	DestCount       int32 `json:"dest_count"`
	// S3 object keys for destination files (for verification)
	DestObjectKeys []string `json:"dest_object_keys"`
	// Total records in all destination files
	DestTotalRecords int64 `json:"dest_total_records"`
	// Total bytes in all destination files
	DestTotalSize int64 `json:"dest_total_size"`
	// Additional debugging information in JSON format
	Metadata map[string]any `json:"metadata"`
	// Estimated record count used for compaction planning and comparison with actual results
	RecordEstimate int64 `json:"record_estimate"`
	// Minimum timestamp (ms) in source data
	SourceMinTimestamp int64 `json:"source_min_timestamp"`
	// Maximum timestamp (ms) in source data
	SourceMaxTimestamp int64 `json:"source_max_timestamp"`
	// Minimum timestamp (ms) in destination data
	DestMinTimestamp int64 `json:"dest_min_timestamp"`
	// Maximum timestamp (ms) in destination data
	DestMaxTimestamp int64 `json:"dest_max_timestamp"`
	// Source frequency in milliseconds
	SourceFrequencyMs int32 `json:"source_frequency_ms"`
	// Destination frequency in milliseconds
	DestFrequencyMs int32 `json:"dest_frequency_ms"`
}

type SignalLock struct {
	ID             int64                            `json:"id"`
	WorkID         *int64                           `json:"work_id"`
	OrganizationID uuid.UUID                        `json:"organization_id"`
	InstanceNum    int16                            `json:"instance_num"`
	Dateint        int32                            `json:"dateint"`
	FrequencyMs    int32                            `json:"frequency_ms"`
	Signal         SignalEnum                       `json:"signal"`
	TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
	ClaimedBy      int64                            `json:"claimed_by"`
	ClaimedAt      *time.Time                       `json:"claimed_at"`
	HeartbeatedAt  time.Time                        `json:"heartbeated_at"`
	SlotID         int32                            `json:"slot_id"`
}

type TraceSeg struct {
	OrganizationID uuid.UUID                 `json:"organization_id"`
	Dateint        int32                     `json:"dateint"`
	SegmentID      int64                     `json:"segment_id"`
	InstanceNum    int16                     `json:"instance_num"`
	SlotID         int32                     `json:"slot_id"`
	Fingerprints   []int64                   `json:"fingerprints"`
	RecordCount    int64                     `json:"record_count"`
	FileSize       int64                     `json:"file_size"`
	IngestDateint  int32                     `json:"ingest_dateint"`
	TsRange        pgtype.Range[pgtype.Int8] `json:"ts_range"`
	CreatedBy      CreatedBy                 `json:"created_by"`
	CreatedAt      time.Time                 `json:"created_at"`
}

type WorkQueue struct {
	ID             int64                            `json:"id"`
	Priority       int32                            `json:"priority"`
	RunnableAt     time.Time                        `json:"runnable_at"`
	OrganizationID uuid.UUID                        `json:"organization_id"`
	InstanceNum    int16                            `json:"instance_num"`
	Dateint        int32                            `json:"dateint"`
	FrequencyMs    int32                            `json:"frequency_ms"`
	Signal         SignalEnum                       `json:"signal"`
	Action         ActionEnum                       `json:"action"`
	NeedsRun       bool                             `json:"needs_run"`
	Tries          int32                            `json:"tries"`
	TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
	ClaimedBy      int64                            `json:"claimed_by"`
	ClaimedAt      *time.Time                       `json:"claimed_at"`
	HeartbeatedAt  time.Time                        `json:"heartbeated_at"`
	SlotID         int32                            `json:"slot_id"`
}
