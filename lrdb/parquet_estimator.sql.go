// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: parquet_estimator.sql

package lrdb

import (
	"context"

	"github.com/google/uuid"
)

const logSegEstimator = `-- name: LogSegEstimator :many
SELECT
  organization_id,
  instance_num,
  (sum(file_size)::float8 / sum(record_count))::float8 AS avg_bpr
FROM log_seg
WHERE
  record_count > 100
  AND dateint IN ($1, $2)
  AND ts_range && int8range($3, $4, '[)')
GROUP BY
  organization_id,
  instance_num
ORDER BY
  organization_id,
  instance_num
`

type LogSegEstimatorParams struct {
	DateintLow  int32 `json:"dateint_low"`
	DateintHigh int32 `json:"dateint_high"`
	MsLow       int64 `json:"ms_low"`
	MsHigh      int64 `json:"ms_high"`
}

type LogSegEstimatorRow struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	InstanceNum    int16     `json:"instance_num"`
	AvgBpr         float64   `json:"avg_bpr"`
}

// Returns an estimate of the number of log segments, average bytes, average records,
// and average bytes per record for log segments in the last hour per organization and instance.
// This query is basically identical to the MetricSegEstimator, but for log segments.
func (q *Queries) LogSegEstimator(ctx context.Context, arg LogSegEstimatorParams) ([]LogSegEstimatorRow, error) {
	rows, err := q.db.Query(ctx, logSegEstimator,
		arg.DateintLow,
		arg.DateintHigh,
		arg.MsLow,
		arg.MsHigh,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []LogSegEstimatorRow
	for rows.Next() {
		var i LogSegEstimatorRow
		if err := rows.Scan(&i.OrganizationID, &i.InstanceNum, &i.AvgBpr); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const metricSegEstimator = `-- name: MetricSegEstimator :many
SELECT
  organization_id,
  instance_num,
  (sum(file_size)::float8 / sum(record_count))::float8 AS avg_bpr
FROM metric_seg
WHERE
  record_count > 100
  AND dateint IN ($1, $2)
  AND ts_range && int8range($3, $4, '[)')
GROUP BY
  organization_id,
  instance_num
ORDER BY
  organization_id,
  instance_num
`

type MetricSegEstimatorParams struct {
	DateintLow  int32 `json:"dateint_low"`
	DateintHigh int32 `json:"dateint_high"`
	MsLow       int64 `json:"ms_low"`
	MsHigh      int64 `json:"ms_high"`
}

type MetricSegEstimatorRow struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	InstanceNum    int16     `json:"instance_num"`
	AvgBpr         float64   `json:"avg_bpr"`
}

// Returns an estimate of the number of metric segments, average bytes, average records,
// and average bytes per record for metric segments in the last hour per organization and instance.
// This query is basically identical to the LogSegEstimator, but for metric segments.
func (q *Queries) MetricSegEstimator(ctx context.Context, arg MetricSegEstimatorParams) ([]MetricSegEstimatorRow, error) {
	rows, err := q.db.Query(ctx, metricSegEstimator,
		arg.DateintLow,
		arg.DateintHigh,
		arg.MsLow,
		arg.MsHigh,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []MetricSegEstimatorRow
	for rows.Next() {
		var i MetricSegEstimatorRow
		if err := rows.Scan(&i.OrganizationID, &i.InstanceNum, &i.AvgBpr); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
