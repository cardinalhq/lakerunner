// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: batch.go

package lrdb

import (
	"context"
	"errors"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const batchDeleteMetricSegs = `-- name: BatchDeleteMetricSegs :batchexec
DELETE FROM public.metric_seg
 WHERE organization_id = $1
   AND dateint         = $2
   AND frequency_ms    = $3
   AND segment_id      = $4
   AND instance_num    = $5
   AND slot_id         = $6
`

type BatchDeleteMetricSegsBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type BatchDeleteMetricSegsParams struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	Dateint        int32     `json:"dateint"`
	FrequencyMs    int32     `json:"frequency_ms"`
	SegmentID      int64     `json:"segment_id"`
	InstanceNum    int16     `json:"instance_num"`
	SlotID         int32     `json:"slot_id"`
}

func (q *Queries) BatchDeleteMetricSegs(ctx context.Context, arg []BatchDeleteMetricSegsParams) *BatchDeleteMetricSegsBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.Dateint,
			a.FrequencyMs,
			a.SegmentID,
			a.InstanceNum,
			a.SlotID,
		}
		batch.Queue(batchDeleteMetricSegs, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &BatchDeleteMetricSegsBatchResults{br, len(arg), false}
}

func (b *BatchDeleteMetricSegsBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *BatchDeleteMetricSegsBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const batchMarkMetricSegsRolledup = `-- name: BatchMarkMetricSegsRolledup :batchexec
UPDATE public.metric_seg
   SET rolledup = true
 WHERE organization_id = $1
   AND dateint         = $2
   AND frequency_ms    = $3
   AND segment_id      = $4
   AND instance_num    = $5
   AND slot_id         = $6
`

type BatchMarkMetricSegsRolledupBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type BatchMarkMetricSegsRolledupParams struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	Dateint        int32     `json:"dateint"`
	FrequencyMs    int32     `json:"frequency_ms"`
	SegmentID      int64     `json:"segment_id"`
	InstanceNum    int16     `json:"instance_num"`
	SlotID         int32     `json:"slot_id"`
}

func (q *Queries) BatchMarkMetricSegsRolledup(ctx context.Context, arg []BatchMarkMetricSegsRolledupParams) *BatchMarkMetricSegsRolledupBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.Dateint,
			a.FrequencyMs,
			a.SegmentID,
			a.InstanceNum,
			a.SlotID,
		}
		batch.Queue(batchMarkMetricSegsRolledup, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &BatchMarkMetricSegsRolledupBatchResults{br, len(arg), false}
}

func (b *BatchMarkMetricSegsRolledupBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *BatchMarkMetricSegsRolledupBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const batchUpsertExemplarLogs = `-- name: BatchUpsertExemplarLogs :batchone
INSERT INTO lrdb_exemplar_logs
            ( organization_id,  service_identifier_id,  fingerprint,  attributes,  exemplar)
VALUES      ($1, $2, $3, $4, $5)
ON CONFLICT ( organization_id,  service_identifier_id,  fingerprint)
DO UPDATE SET
  attributes = EXCLUDED.attributes,
  exemplar   = EXCLUDED.exemplar,
  updated_at = now(),
  related_fingerprints = CASE
    WHEN $6::BIGINT != 0
      AND $3 != $6
      THEN add_to_bigint_list(lrdb_exemplar_logs.related_fingerprints, $6, 100)
    ELSE lrdb_exemplar_logs.related_fingerprints
  END
RETURNING (created_at = updated_at) as is_new
`

type BatchUpsertExemplarLogsBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type BatchUpsertExemplarLogsParams struct {
	OrganizationID      uuid.UUID      `json:"organization_id"`
	ServiceIdentifierID uuid.UUID      `json:"service_identifier_id"`
	Fingerprint         int64          `json:"fingerprint"`
	Attributes          map[string]any `json:"attributes"`
	Exemplar            map[string]any `json:"exemplar"`
	OldFingerprint      int64          `json:"old_fingerprint"`
}

// This will upsert a new log exemplar. Attributes, exemplar, and updated_at are always updated
// to the provided values. If old_fingerprint is not 0, it is added to the list of related
// fingerprints. This means the "old" fingerprint should be fingerprint, so it always updates
// an existing record, not changing it to the new one.
// The return value is a boolean indicating if the record is new.
func (q *Queries) BatchUpsertExemplarLogs(ctx context.Context, arg []BatchUpsertExemplarLogsParams) *BatchUpsertExemplarLogsBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.ServiceIdentifierID,
			a.Fingerprint,
			a.Attributes,
			a.Exemplar,
			a.OldFingerprint,
		}
		batch.Queue(batchUpsertExemplarLogs, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &BatchUpsertExemplarLogsBatchResults{br, len(arg), false}
}

func (b *BatchUpsertExemplarLogsBatchResults) QueryRow(f func(int, bool, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var is_new bool
		if b.closed {
			if f != nil {
				f(t, is_new, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&is_new)
		if f != nil {
			f(t, is_new, err)
		}
	}
}

func (b *BatchUpsertExemplarLogsBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const batchUpsertExemplarMetrics = `-- name: BatchUpsertExemplarMetrics :batchone
INSERT INTO lrdb_exemplar_metrics
            ( organization_id,  service_identifier_id,  metric_name,  metric_type,  attributes,  exemplar)
VALUES      ($1, $2, $3, $4, $5, $6)
ON CONFLICT ( organization_id,  service_identifier_id,  metric_name,  metric_type)
DO UPDATE SET
  attributes = EXCLUDED.attributes,
  exemplar = EXCLUDED.exemplar,
  updated_at = now()
RETURNING (created_at = updated_at) as is_new
`

type BatchUpsertExemplarMetricsBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type BatchUpsertExemplarMetricsParams struct {
	OrganizationID      uuid.UUID      `json:"organization_id"`
	ServiceIdentifierID uuid.UUID      `json:"service_identifier_id"`
	MetricName          string         `json:"metric_name"`
	MetricType          string         `json:"metric_type"`
	Attributes          map[string]any `json:"attributes"`
	Exemplar            map[string]any `json:"exemplar"`
}

func (q *Queries) BatchUpsertExemplarMetrics(ctx context.Context, arg []BatchUpsertExemplarMetricsParams) *BatchUpsertExemplarMetricsBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.ServiceIdentifierID,
			a.MetricName,
			a.MetricType,
			a.Attributes,
			a.Exemplar,
		}
		batch.Queue(batchUpsertExemplarMetrics, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &BatchUpsertExemplarMetricsBatchResults{br, len(arg), false}
}

func (b *BatchUpsertExemplarMetricsBatchResults) QueryRow(f func(int, bool, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var is_new bool
		if b.closed {
			if f != nil {
				f(t, is_new, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&is_new)
		if f != nil {
			f(t, is_new, err)
		}
	}
}

func (b *BatchUpsertExemplarMetricsBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const batchUpsertExemplarTraces = `-- name: BatchUpsertExemplarTraces :batchone
INSERT INTO lrdb_exemplar_traces
( organization_id
, service_identifier_id
, fingerprint
, attributes
, exemplar
, span_name
, span_kind
)
VALUES      ( $1
            , $2
            , $3
            , $4
            , $5
            , $6
            , $7
            )
    ON CONFLICT ( organization_id
            , service_identifier_id
            , fingerprint
            )
DO UPDATE SET
           attributes        = EXCLUDED.attributes,
           exemplar          = EXCLUDED.exemplar,
           span_name         = EXCLUDED.span_name,
           span_kind         = EXCLUDED.span_kind,
           updated_at        = now()
RETURNING (created_at = updated_at) AS is_new
`

type BatchUpsertExemplarTracesBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type BatchUpsertExemplarTracesParams struct {
	OrganizationID      uuid.UUID      `json:"organization_id"`
	ServiceIdentifierID uuid.UUID      `json:"service_identifier_id"`
	Fingerprint         int64          `json:"fingerprint"`
	Attributes          map[string]any `json:"attributes"`
	Exemplar            map[string]any `json:"exemplar"`
	SpanName            string         `json:"span_name"`
	SpanKind            int32          `json:"span_kind"`
}

func (q *Queries) BatchUpsertExemplarTraces(ctx context.Context, arg []BatchUpsertExemplarTracesParams) *BatchUpsertExemplarTracesBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.ServiceIdentifierID,
			a.Fingerprint,
			a.Attributes,
			a.Exemplar,
			a.SpanName,
			a.SpanKind,
		}
		batch.Queue(batchUpsertExemplarTraces, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &BatchUpsertExemplarTracesBatchResults{br, len(arg), false}
}

func (b *BatchUpsertExemplarTracesBatchResults) QueryRow(f func(int, bool, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var is_new bool
		if b.closed {
			if f != nil {
				f(t, is_new, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&is_new)
		if f != nil {
			f(t, is_new, err)
		}
	}
}

func (b *BatchUpsertExemplarTracesBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const kafkaJournalBatchUpsert = `-- name: KafkaJournalBatchUpsert :batchexec
INSERT INTO kafka_offset_journal (consumer_group, topic, partition, last_processed_offset, organization_id, instance_num, updated_at)
VALUES ($1, $2, $3, $4, $5, $6, NOW())
ON CONFLICT (consumer_group, topic, partition, organization_id, instance_num)
DO UPDATE SET
    last_processed_offset = EXCLUDED.last_processed_offset,
    updated_at = NOW()
WHERE kafka_offset_journal.last_processed_offset < EXCLUDED.last_processed_offset
`

type KafkaJournalBatchUpsertBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type KafkaJournalBatchUpsertParams struct {
	ConsumerGroup       string    `json:"consumer_group"`
	Topic               string    `json:"topic"`
	Partition           int32     `json:"partition"`
	LastProcessedOffset int64     `json:"last_processed_offset"`
	OrganizationID      uuid.UUID `json:"organization_id"`
	InstanceNum         int16     `json:"instance_num"`
}

// Insert or update multiple Kafka journal entries in a single batch operation
// Only updates if the new offset is greater than the existing one
func (q *Queries) KafkaJournalBatchUpsert(ctx context.Context, arg []KafkaJournalBatchUpsertParams) *KafkaJournalBatchUpsertBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ConsumerGroup,
			a.Topic,
			a.Partition,
			a.LastProcessedOffset,
			a.OrganizationID,
			a.InstanceNum,
		}
		batch.Queue(kafkaJournalBatchUpsert, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &KafkaJournalBatchUpsertBatchResults{br, len(arg), false}
}

func (b *KafkaJournalBatchUpsertBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *KafkaJournalBatchUpsertBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const batchInsertLogSegsDirect = `-- name: batchInsertLogSegsDirect :batchexec
INSERT INTO log_seg (
  organization_id,
  dateint,
  ingest_dateint,
  segment_id,
  instance_num,
  slot_id,
  ts_range,
  record_count,
  file_size,
  created_by,
  fingerprints,
  published,
  compacted
)
VALUES (
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  int8range($7, $8, '[)'),
  $9,
  $10,
  $11,
  $12::bigint[],
  $13,
  $14
)
`

type batchInsertLogSegsDirectBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type batchInsertLogSegsDirectParams struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	Dateint        int32     `json:"dateint"`
	IngestDateint  int32     `json:"ingest_dateint"`
	SegmentID      int64     `json:"segment_id"`
	InstanceNum    int16     `json:"instance_num"`
	SlotID         int32     `json:"slot_id"`
	StartTs        int64     `json:"start_ts"`
	EndTs          int64     `json:"end_ts"`
	RecordCount    int64     `json:"record_count"`
	FileSize       int64     `json:"file_size"`
	CreatedBy      CreatedBy `json:"created_by"`
	Fingerprints   []int64   `json:"fingerprints"`
	Published      bool      `json:"published"`
	Compacted      bool      `json:"compacted"`
}

func (q *Queries) batchInsertLogSegsDirect(ctx context.Context, arg []batchInsertLogSegsDirectParams) *batchInsertLogSegsDirectBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.Dateint,
			a.IngestDateint,
			a.SegmentID,
			a.InstanceNum,
			a.SlotID,
			a.StartTs,
			a.EndTs,
			a.RecordCount,
			a.FileSize,
			a.CreatedBy,
			a.Fingerprints,
			a.Published,
			a.Compacted,
		}
		batch.Queue(batchInsertLogSegsDirect, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &batchInsertLogSegsDirectBatchResults{br, len(arg), false}
}

func (b *batchInsertLogSegsDirectBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *batchInsertLogSegsDirectBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const batchInsertTraceSegsDirect = `-- name: batchInsertTraceSegsDirect :batchexec
INSERT INTO trace_seg (
  organization_id,
  dateint,
  ingest_dateint,
  segment_id,
  instance_num,
  slot_id,
  ts_range,
  record_count,
  file_size,
  created_by,
  fingerprints
)
VALUES (
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  int8range($7, $8, '[)'),
  $9,
  $10,
  $11,
  $12::bigint[]
)
`

type batchInsertTraceSegsDirectBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type batchInsertTraceSegsDirectParams struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	Dateint        int32     `json:"dateint"`
	IngestDateint  int32     `json:"ingest_dateint"`
	SegmentID      int64     `json:"segment_id"`
	InstanceNum    int16     `json:"instance_num"`
	SlotID         int32     `json:"slot_id"`
	StartTs        int64     `json:"start_ts"`
	EndTs          int64     `json:"end_ts"`
	RecordCount    int64     `json:"record_count"`
	FileSize       int64     `json:"file_size"`
	CreatedBy      CreatedBy `json:"created_by"`
	Fingerprints   []int64   `json:"fingerprints"`
}

func (q *Queries) batchInsertTraceSegsDirect(ctx context.Context, arg []batchInsertTraceSegsDirectParams) *batchInsertTraceSegsDirectBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.Dateint,
			a.IngestDateint,
			a.SegmentID,
			a.InstanceNum,
			a.SlotID,
			a.StartTs,
			a.EndTs,
			a.RecordCount,
			a.FileSize,
			a.CreatedBy,
			a.Fingerprints,
		}
		batch.Queue(batchInsertTraceSegsDirect, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &batchInsertTraceSegsDirectBatchResults{br, len(arg), false}
}

func (b *batchInsertTraceSegsDirectBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *batchInsertTraceSegsDirectBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const insertMetricSegsDirect = `-- name: insertMetricSegsDirect :batchexec
INSERT INTO metric_seg (
  organization_id,
  dateint,
  ingest_dateint,
  frequency_ms,
  segment_id,
  instance_num,
  slot_id,
  ts_range,
  record_count,
  file_size,
  published,
  created_by,
  rolledup,
  fingerprints,
  sort_version,
  slot_count,
  compacted
)
VALUES (
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  $7,
  int8range($8, $9, '[)'),
  $10,
  $11,
  $12,
  $13,
  $14,
  $15::bigint[],
  $16,
  $17,
  $18
)
ON CONFLICT (organization_id, dateint, frequency_ms, segment_id, instance_num, slot_id, slot_count)
DO NOTHING
`

type insertMetricSegsDirectBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type InsertMetricSegsParams struct {
	OrganizationID uuid.UUID `json:"organization_id"`
	Dateint        int32     `json:"dateint"`
	IngestDateint  int32     `json:"ingest_dateint"`
	FrequencyMs    int32     `json:"frequency_ms"`
	SegmentID      int64     `json:"segment_id"`
	InstanceNum    int16     `json:"instance_num"`
	SlotID         int32     `json:"slot_id"`
	StartTs        int64     `json:"start_ts"`
	EndTs          int64     `json:"end_ts"`
	RecordCount    int64     `json:"record_count"`
	FileSize       int64     `json:"file_size"`
	Published      bool      `json:"published"`
	CreatedBy      CreatedBy `json:"created_by"`
	Rolledup       bool      `json:"rolledup"`
	Fingerprints   []int64   `json:"fingerprints"`
	SortVersion    int16     `json:"sort_version"`
	SlotCount      int32     `json:"slot_count"`
	Compacted      bool      `json:"compacted"`
}

func (q *Queries) insertMetricSegsDirect(ctx context.Context, arg []InsertMetricSegsParams) *insertMetricSegsDirectBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OrganizationID,
			a.Dateint,
			a.IngestDateint,
			a.FrequencyMs,
			a.SegmentID,
			a.InstanceNum,
			a.SlotID,
			a.StartTs,
			a.EndTs,
			a.RecordCount,
			a.FileSize,
			a.Published,
			a.CreatedBy,
			a.Rolledup,
			a.Fingerprints,
			a.SortVersion,
			a.SlotCount,
			a.Compacted,
		}
		batch.Queue(insertMetricSegsDirect, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &insertMetricSegsDirectBatchResults{br, len(arg), false}
}

func (b *insertMetricSegsDirectBatchResults) Exec(f func(int, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		if b.closed {
			if f != nil {
				f(t, ErrBatchAlreadyClosed)
			}
			continue
		}
		_, err := b.br.Exec()
		if f != nil {
			f(t, err)
		}
	}
}

func (b *insertMetricSegsDirectBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
