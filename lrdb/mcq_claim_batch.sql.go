// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: mcq_claim_batch.sql

package lrdb

import (
	"context"
	"time"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

const claimMetricCompactionWork = `-- name: ClaimMetricCompactionWork :many
WITH
params AS (
  SELECT
    $1::bigint         AS worker_id,
    COALESCE($2::timestamptz, now()) AS now_ts,
    $3::bigint    AS target_records,
    $4::integer  AS max_age_seconds,
    $5::integer      AS batch_count
),

big_single AS (
  SELECT q.id
  FROM metric_compaction_queue q
  JOIN params p ON TRUE
  WHERE q.claimed_at IS NULL
    AND q.record_count >= p.target_records
  ORDER BY q.priority DESC, q.queue_ts ASC
  LIMIT 1
),

seeds_per_group AS (
  SELECT DISTINCT ON (organization_id, instance_num, dateint)
         id AS seed_id, organization_id, instance_num, dateint,
         priority, queue_ts, record_count
  FROM metric_compaction_queue
  WHERE claimed_at IS NULL
  ORDER BY organization_id, instance_num, dateint, priority DESC, queue_ts ASC
),

ordered_groups AS (
  SELECT s.seed_id, s.organization_id, s.instance_num, s.dateint, s.priority, s.queue_ts, s.record_count,
         ROW_NUMBER() OVER (ORDER BY s.priority DESC, s.queue_ts ASC) AS seed_rank
  FROM seeds_per_group s
),

group_flags AS (
  SELECT
    og.organization_id, og.instance_num, og.dateint,
    og.priority, og.queue_ts, og.seed_rank,
    ((p.now_ts - og.queue_ts) > make_interval(secs => p.max_age_seconds)) AS is_old,
    p.target_records, p.batch_count, p.now_ts
  FROM ordered_groups og
  JOIN params p ON TRUE
),

grp_scope AS (
  SELECT
    q.id, q.organization_id, q.instance_num, q.dateint,
    q.priority, q.queue_ts, q.record_count,
    gf.seed_rank, gf.is_old, gf.target_records, gf.batch_count
  FROM metric_compaction_queue q
  JOIN group_flags gf
    ON q.claimed_at IS NULL
   AND q.organization_id = gf.organization_id
   AND q.instance_num    = gf.instance_num
   AND q.dateint         = gf.dateint
),

pack AS (
  SELECT
    g.id, g.organization_id, g.instance_num, g.dateint, g.priority, g.queue_ts, g.record_count, g.seed_rank, g.is_old, g.target_records, g.batch_count,
    SUM(g.record_count) OVER (
      PARTITION BY g.organization_id, g.instance_num, g.dateint
      ORDER BY g.priority DESC, g.queue_ts ASC
      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) AS cum_records,
    ROW_NUMBER() OVER (
      PARTITION BY g.organization_id, g.instance_num, g.dateint
      ORDER BY g.priority DESC, g.queue_ts ASC
    ) AS rn
  FROM grp_scope g
),

prelim AS (
  SELECT p.id, p.organization_id, p.instance_num, p.dateint, p.priority, p.queue_ts, p.record_count, p.seed_rank, p.is_old, p.target_records, p.batch_count, p.cum_records, p.rn
  FROM pack p
  WHERE p.cum_records <= p.target_records
    AND p.rn          <= p.batch_count
),

prelim_stats AS (
  SELECT
    organization_id, instance_num, dateint,
    MIN(seed_rank) AS seed_rank,
    COUNT(*) AS n_rows,
    COALESCE(SUM(record_count), 0) AS total_records
  FROM prelim
  GROUP BY organization_id, instance_num, dateint
),

eligible_groups AS (
  SELECT
    gf.organization_id, gf.instance_num, gf.dateint, gf.seed_rank
  FROM group_flags gf
  JOIN prelim_stats ps
    ON ps.organization_id = gf.organization_id
   AND ps.instance_num    = gf.instance_num
   AND ps.dateint         = gf.dateint
  WHERE (NOT gf.is_old AND ps.total_records = gf.target_records)
     OR (gf.is_old      AND ps.total_records > 0)
),

winner_group AS (
  SELECT eg.organization_id, eg.instance_num, eg.dateint, eg.seed_rank
  FROM eligible_groups eg
  WHERE eg.seed_rank = (SELECT MIN(seed_rank) FROM eligible_groups)
),

group_chosen AS (
  SELECT pr.id
  FROM prelim pr
  JOIN winner_group w
    ON w.organization_id = pr.organization_id
   AND w.instance_num    = pr.instance_num
   AND w.dateint         = pr.dateint
),

chosen AS (
  SELECT id FROM big_single
  UNION ALL
  SELECT id FROM group_chosen
  WHERE NOT EXISTS (SELECT 1 FROM big_single)
),

upd AS (
  UPDATE metric_compaction_queue q
  SET claimed_by = (SELECT worker_id FROM params),
      claimed_at = (SELECT now_ts FROM params)
  FROM chosen c
  WHERE q.id = c.id
    AND q.claimed_at IS NULL
  RETURNING q.id, q.queue_ts, q.priority, q.organization_id, q.dateint, q.frequency_ms, q.segment_id, q.instance_num, q.ts_range, q.record_count, q.tries, q.claimed_by, q.claimed_at
)
SELECT id, queue_ts, priority, organization_id, dateint, frequency_ms, segment_id, instance_num, ts_range, record_count, tries, claimed_by, claimed_at FROM upd
ORDER BY priority DESC, queue_ts ASC
`

type ClaimMetricCompactionWorkParams struct {
	WorkerID      int64      `json:"worker_id"`
	NowTs         *time.Time `json:"now_ts"`
	TargetRecords int64      `json:"target_records"`
	MaxAgeSeconds int32      `json:"max_age_seconds"`
	BatchCount    int32      `json:"batch_count"`
}

type ClaimMetricCompactionWorkRow struct {
	ID             int64                            `json:"id"`
	QueueTs        time.Time                        `json:"queue_ts"`
	Priority       int32                            `json:"priority"`
	OrganizationID uuid.UUID                        `json:"organization_id"`
	Dateint        int32                            `json:"dateint"`
	FrequencyMs    int64                            `json:"frequency_ms"`
	SegmentID      uuid.UUID                        `json:"segment_id"`
	InstanceNum    int16                            `json:"instance_num"`
	TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
	RecordCount    int64                            `json:"record_count"`
	Tries          int32                            `json:"tries"`
	ClaimedBy      int64                            `json:"claimed_by"`
	ClaimedAt      *time.Time                       `json:"claimed_at"`
}

// 1) Big single row safety-net (no locks in selection)
// 2) Seeds: oldest/highest-priority row per (org,instance,dateint)
// 3) Order groups globally by seed (priority DESC, queue_ts ASC)
// 4) Flags and parameters per group (based on the seed row)
// 5) All ready rows in each group (ordered). No locks; just compute packs.
// 6) Greedy pack within each group up to target_records and batch_count
// 7) Totals per group and eligibility:
//   - fresh: exact fill (total = target)
//   - old:   any positive total (already capped by target)
//
// 8) Pick earliest eligible group
// 9) Rows to claim if using the group path
// 10) Final chosen IDs: prefer big_single if exists
// 11) Optimistic claim (atomic per-row; guarded by claimed_at IS NULL)
func (q *Queries) ClaimMetricCompactionWork(ctx context.Context, arg ClaimMetricCompactionWorkParams) ([]ClaimMetricCompactionWorkRow, error) {
	rows, err := q.db.Query(ctx, claimMetricCompactionWork,
		arg.WorkerID,
		arg.NowTs,
		arg.TargetRecords,
		arg.MaxAgeSeconds,
		arg.BatchCount,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []ClaimMetricCompactionWorkRow
	for rows.Next() {
		var i ClaimMetricCompactionWorkRow
		if err := rows.Scan(
			&i.ID,
			&i.QueueTs,
			&i.Priority,
			&i.OrganizationID,
			&i.Dateint,
			&i.FrequencyMs,
			&i.SegmentID,
			&i.InstanceNum,
			&i.TsRange,
			&i.RecordCount,
			&i.Tries,
			&i.ClaimedBy,
			&i.ClaimedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
