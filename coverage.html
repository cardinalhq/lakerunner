
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>cmd: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">github.com/cardinalhq/lakerunner/cmd/compact_logs.go (22.9%)</option>
				
				<option value="file1">github.com/cardinalhq/lakerunner/cmd/compact_metrics.go (14.5%)</option>
				
				<option value="file2">github.com/cardinalhq/lakerunner/cmd/dbopen/dbopen.go (0.0%)</option>
				
				<option value="file3">github.com/cardinalhq/lakerunner/cmd/dbopen/dbopen_configdb.go (0.0%)</option>
				
				<option value="file4">github.com/cardinalhq/lakerunner/cmd/dbopen/dbopen_lrdb.go (0.0%)</option>
				
				<option value="file5">github.com/cardinalhq/lakerunner/cmd/debug.go (100.0%)</option>
				
				<option value="file6">github.com/cardinalhq/lakerunner/cmd/debug/ddb.go (0.0%)</option>
				
				<option value="file7">github.com/cardinalhq/lakerunner/cmd/debug/fileconv.go (0.0%)</option>
				
				<option value="file8">github.com/cardinalhq/lakerunner/cmd/debug/kubernetes_discovery.go (0.0%)</option>
				
				<option value="file9">github.com/cardinalhq/lakerunner/cmd/debug/parquet_schema.go (0.0%)</option>
				
				<option value="file10">github.com/cardinalhq/lakerunner/cmd/debug/s3cat.go (0.0%)</option>
				
				<option value="file11">github.com/cardinalhq/lakerunner/cmd/debug/s3ls.go (0.0%)</option>
				
				<option value="file12">github.com/cardinalhq/lakerunner/cmd/debug/sqlite.go (0.0%)</option>
				
				<option value="file13">github.com/cardinalhq/lakerunner/cmd/diskloop.go (0.0%)</option>
				
				<option value="file14">github.com/cardinalhq/lakerunner/cmd/ingest_logs_cmd.go (1.1%)</option>
				
				<option value="file15">github.com/cardinalhq/lakerunner/cmd/ingest_metrics.go (8.4%)</option>
				
				<option value="file16">github.com/cardinalhq/lakerunner/cmd/ingestlogs/raw_parquet.go (11.5%)</option>
				
				<option value="file17">github.com/cardinalhq/lakerunner/cmd/inqueue_handler.go (0.0%)</option>
				
				<option value="file18">github.com/cardinalhq/lakerunner/cmd/inqueue_ingest.go (0.0%)</option>
				
				<option value="file19">github.com/cardinalhq/lakerunner/cmd/metrics.go (77.5%)</option>
				
				<option value="file20">github.com/cardinalhq/lakerunner/cmd/migrate.go (10.0%)</option>
				
				<option value="file21">github.com/cardinalhq/lakerunner/cmd/otel/translator.go (0.0%)</option>
				
				<option value="file22">github.com/cardinalhq/lakerunner/cmd/pack_adapters.go (6.2%)</option>
				
				<option value="file23">github.com/cardinalhq/lakerunner/cmd/pack_segment.go (59.4%)</option>
				
				<option value="file24">github.com/cardinalhq/lakerunner/cmd/pubsub/pubsub.go (0.0%)</option>
				
				<option value="file25">github.com/cardinalhq/lakerunner/cmd/pubsub/s3_like.go (0.0%)</option>
				
				<option value="file26">github.com/cardinalhq/lakerunner/cmd/pubsub/sqs.go (0.0%)</option>
				
				<option value="file27">github.com/cardinalhq/lakerunner/cmd/pubsub_cmd.go (20.0%)</option>
				
				<option value="file28">github.com/cardinalhq/lakerunner/cmd/query_api_cmd.go (12.9%)</option>
				
				<option value="file29">github.com/cardinalhq/lakerunner/cmd/query_worker_cmd.go (13.3%)</option>
				
				<option value="file30">github.com/cardinalhq/lakerunner/cmd/rollup_metrics.go (7.2%)</option>
				
				<option value="file31">github.com/cardinalhq/lakerunner/cmd/root.go (25.0%)</option>
				
				<option value="file32">github.com/cardinalhq/lakerunner/cmd/signal.go (0.0%)</option>
				
				<option value="file33">github.com/cardinalhq/lakerunner/cmd/sketch.go (40.0%)</option>
				
				<option value="file34">github.com/cardinalhq/lakerunner/cmd/sweeper.go (16.7%)</option>
				
				<option value="file35">github.com/cardinalhq/lakerunner/cmd/sweeper/sweeper.go (0.0%)</option>
				
				<option value="file36">github.com/cardinalhq/lakerunner/cmd/sysinfo.go (2.9%)</option>
				
				<option value="file37">github.com/cardinalhq/lakerunner/cmd/telemetry.go (0.0%)</option>
				
				<option value="file38">github.com/cardinalhq/lakerunner/cmd/tid_accumulator.go (100.0%)</option>
				
				<option value="file39">github.com/cardinalhq/lakerunner/cmd/tidmerge.go (80.5%)</option>
				
				<option value="file40">github.com/cardinalhq/lakerunner/cmd/workqueue.go (0.0%)</option>
				
				<option value="file41">github.com/cardinalhq/lakerunner/cmd/workqueue_action.go (15.4%)</option>
				
				<option value="file42">github.com/cardinalhq/lakerunner/cmd/workqueue_handler.go (0.0%)</option>
				
				<option value="file43">github.com/cardinalhq/lakerunner/dbase/base36.go (100.0%)</option>
				
				<option value="file44">github.com/cardinalhq/lakerunner/fileconv/jsongz/jsongz.go (57.7%)</option>
				
				<option value="file45">github.com/cardinalhq/lakerunner/fileconv/proto/metrics_proto.go (79.5%)</option>
				
				<option value="file46">github.com/cardinalhq/lakerunner/fileconv/proto/proto.go (79.5%)</option>
				
				<option value="file47">github.com/cardinalhq/lakerunner/fileconv/rawparquet/rawparquet.go (77.6%)</option>
				
				<option value="file48">github.com/cardinalhq/lakerunner/fileconv/translate/log_map.go (98.1%)</option>
				
				<option value="file49">github.com/cardinalhq/lakerunner/fileconv/translate/mapper.go (0.0%)</option>
				
				<option value="file50">github.com/cardinalhq/lakerunner/internal/awsclient/manager.go (0.0%)</option>
				
				<option value="file51">github.com/cardinalhq/lakerunner/internal/awsclient/s3.go (0.0%)</option>
				
				<option value="file52">github.com/cardinalhq/lakerunner/internal/awsclient/s3helper/idgen.go (37.5%)</option>
				
				<option value="file53">github.com/cardinalhq/lakerunner/internal/awsclient/s3helper/s3.go (0.0%)</option>
				
				<option value="file54">github.com/cardinalhq/lakerunner/internal/awsclient/s3helper/time.go (100.0%)</option>
				
				<option value="file55">github.com/cardinalhq/lakerunner/internal/awsclient/sqs.go (0.0%)</option>
				
				<option value="file56">github.com/cardinalhq/lakerunner/internal/buffet/buffet.go (4.0%)</option>
				
				<option value="file57">github.com/cardinalhq/lakerunner/internal/buffet/nodemap_builder.go (71.4%)</option>
				
				<option value="file58">github.com/cardinalhq/lakerunner/internal/buffet/parquet.go (69.0%)</option>
				
				<option value="file59">github.com/cardinalhq/lakerunner/internal/configdb/c_tables.sql.go (0.0%)</option>
				
				<option value="file60">github.com/cardinalhq/lakerunner/internal/configdb/db.go (0.0%)</option>
				
				<option value="file61">github.com/cardinalhq/lakerunner/internal/configdb/pool.go (0.0%)</option>
				
				<option value="file62">github.com/cardinalhq/lakerunner/internal/configdb/storage_profile_cache.go (0.0%)</option>
				
				<option value="file63">github.com/cardinalhq/lakerunner/internal/configdb/store.go (0.0%)</option>
				
				<option value="file64">github.com/cardinalhq/lakerunner/internal/duckdbx/duckdbx.go (0.0%)</option>
				
				<option value="file65">github.com/cardinalhq/lakerunner/internal/duckdbx/memory.go (0.0%)</option>
				
				<option value="file66">github.com/cardinalhq/lakerunner/internal/duckdbx/metrics.go (0.0%)</option>
				
				<option value="file67">github.com/cardinalhq/lakerunner/internal/estimator/estimator.go (79.8%)</option>
				
				<option value="file68">github.com/cardinalhq/lakerunner/internal/filecrunch/filecrunch.go (73.5%)</option>
				
				<option value="file69">github.com/cardinalhq/lakerunner/internal/filecrunch/schema.go (0.0%)</option>
				
				<option value="file70">github.com/cardinalhq/lakerunner/internal/helpers/diskusage.go (0.0%)</option>
				
				<option value="file71">github.com/cardinalhq/lakerunner/internal/helpers/pathnames.go (50.0%)</option>
				
				<option value="file72">github.com/cardinalhq/lakerunner/internal/helpers/tempcleaner.go (0.0%)</option>
				
				<option value="file73">github.com/cardinalhq/lakerunner/internal/helpers/tid.go (25.0%)</option>
				
				<option value="file74">github.com/cardinalhq/lakerunner/internal/helpers/time.go (0.0%)</option>
				
				<option value="file75">github.com/cardinalhq/lakerunner/internal/idgen/flake.go (73.3%)</option>
				
				<option value="file76">github.com/cardinalhq/lakerunner/internal/idgen/ulid.go (0.0%)</option>
				
				<option value="file77">github.com/cardinalhq/lakerunner/internal/logcrunch/compaction.go (84.2%)</option>
				
				<option value="file78">github.com/cardinalhq/lakerunner/internal/logcrunch/fingerprint.go (100.0%)</option>
				
				<option value="file79">github.com/cardinalhq/lakerunner/internal/logcrunch/fingerprint_file.go (80.0%)</option>
				
				<option value="file80">github.com/cardinalhq/lakerunner/internal/storageprofile/db.go (33.3%)</option>
				
				<option value="file81">github.com/cardinalhq/lakerunner/internal/storageprofile/file.go (54.5%)</option>
				
				<option value="file82">github.com/cardinalhq/lakerunner/internal/storageprofile/storageprofile.go (0.0%)</option>
				
				<option value="file83">github.com/cardinalhq/lakerunner/lockmgr/options.go (100.0%)</option>
				
				<option value="file84">github.com/cardinalhq/lakerunner/lockmgr/work_item.go (0.0%)</option>
				
				<option value="file85">github.com/cardinalhq/lakerunner/lockmgr/workqueue.go (0.0%)</option>
				
				<option value="file86">github.com/cardinalhq/lakerunner/lrdb/batch.go (0.0%)</option>
				
				<option value="file87">github.com/cardinalhq/lakerunner/lrdb/db.go (0.0%)</option>
				
				<option value="file88">github.com/cardinalhq/lakerunner/lrdb/inqueue.sql.go (0.0%)</option>
				
				<option value="file89">github.com/cardinalhq/lakerunner/lrdb/inqueue_journal.sql.go (0.0%)</option>
				
				<option value="file90">github.com/cardinalhq/lakerunner/lrdb/log_seg.sql.go (0.0%)</option>
				
				<option value="file91">github.com/cardinalhq/lakerunner/lrdb/log_seq.go (0.0%)</option>
				
				<option value="file92">github.com/cardinalhq/lakerunner/lrdb/metric_seg.go (0.0%)</option>
				
				<option value="file93">github.com/cardinalhq/lakerunner/lrdb/metric_seg.sql.go (0.0%)</option>
				
				<option value="file94">github.com/cardinalhq/lakerunner/lrdb/migrations/migrate_up.go (0.0%)</option>
				
				<option value="file95">github.com/cardinalhq/lakerunner/lrdb/models.go (0.0%)</option>
				
				<option value="file96">github.com/cardinalhq/lakerunner/lrdb/obj_cleanup.sql.go (0.0%)</option>
				
				<option value="file97">github.com/cardinalhq/lakerunner/lrdb/parquet_estimator.sql.go (0.0%)</option>
				
				<option value="file98">github.com/cardinalhq/lakerunner/lrdb/partition_cache.go (0.0%)</option>
				
				<option value="file99">github.com/cardinalhq/lakerunner/lrdb/partitioning.go (0.0%)</option>
				
				<option value="file100">github.com/cardinalhq/lakerunner/lrdb/pool.go (0.0%)</option>
				
				<option value="file101">github.com/cardinalhq/lakerunner/lrdb/signal_locks.sql.go (0.0%)</option>
				
				<option value="file102">github.com/cardinalhq/lakerunner/lrdb/store.go (0.0%)</option>
				
				<option value="file103">github.com/cardinalhq/lakerunner/lrdb/work_queue.go (0.0%)</option>
				
				<option value="file104">github.com/cardinalhq/lakerunner/lrdb/work_queue.sql.go (0.0%)</option>
				
				<option value="file105">github.com/cardinalhq/lakerunner/lrdb/work_queue_claim.sql.go (0.0%)</option>
				
				<option value="file106">github.com/cardinalhq/lakerunner/main.go (0.0%)</option>
				
				<option value="file107">github.com/cardinalhq/lakerunner/promql/agg_node.go (0.0%)</option>
				
				<option value="file108">github.com/cardinalhq/lakerunner/promql/aggregator.go (0.0%)</option>
				
				<option value="file109">github.com/cardinalhq/lakerunner/promql/binary_node.go (0.0%)</option>
				
				<option value="file110">github.com/cardinalhq/lakerunner/promql/bottom_k_node.go (0.0%)</option>
				
				<option value="file111">github.com/cardinalhq/lakerunner/promql/clamp_max_node.go (0.0%)</option>
				
				<option value="file112">github.com/cardinalhq/lakerunner/promql/clamp_min_node.go (0.0%)</option>
				
				<option value="file113">github.com/cardinalhq/lakerunner/promql/dates.go (0.0%)</option>
				
				<option value="file114">github.com/cardinalhq/lakerunner/promql/discovery.go (0.0%)</option>
				
				<option value="file115">github.com/cardinalhq/lakerunner/promql/eval_flow.go (0.0%)</option>
				
				<option value="file116">github.com/cardinalhq/lakerunner/promql/eval_types.go (0.0%)</option>
				
				<option value="file117">github.com/cardinalhq/lakerunner/promql/evaluator.go (0.0%)</option>
				
				<option value="file118">github.com/cardinalhq/lakerunner/promql/exec_planner.go (74.4%)</option>
				
				<option value="file119">github.com/cardinalhq/lakerunner/promql/kubernetes_discovery.go (0.0%)</option>
				
				<option value="file120">github.com/cardinalhq/lakerunner/promql/leaf_node.go (0.0%)</option>
				
				<option value="file121">github.com/cardinalhq/lakerunner/promql/local_dev_discovery.go (0.0%)</option>
				
				<option value="file122">github.com/cardinalhq/lakerunner/promql/parser.go (61.8%)</option>
				
				<option value="file123">github.com/cardinalhq/lakerunner/promql/quantile_node.go (0.0%)</option>
				
				<option value="file124">github.com/cardinalhq/lakerunner/promql/querier.go (0.0%)</option>
				
				<option value="file125">github.com/cardinalhq/lakerunner/promql/scalar_node.go (0.0%)</option>
				
				<option value="file126">github.com/cardinalhq/lakerunner/promql/sql_builder.go (49.1%)</option>
				
				<option value="file127">github.com/cardinalhq/lakerunner/promql/stream_sort.go (84.4%)</option>
				
				<option value="file128">github.com/cardinalhq/lakerunner/promql/time_grouper.go (85.0%)</option>
				
				<option value="file129">github.com/cardinalhq/lakerunner/promql/top_k_node.go (0.0%)</option>
				
				<option value="file130">github.com/cardinalhq/lakerunner/promql/unary_node.go (0.0%)</option>
				
				<option value="file131">github.com/cardinalhq/lakerunner/queryworker/cache.go (0.0%)</option>
				
				<option value="file132">github.com/cardinalhq/lakerunner/queryworker/handlers.go (0.0%)</option>
				
				<option value="file133">github.com/cardinalhq/lakerunner/queryworker/processor.go (0.0%)</option>
				
				<option value="file134">github.com/cardinalhq/lakerunner/queryworker/service.go (0.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
        "time"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/logcrunch"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lockmgr"
        "github.com/cardinalhq/lakerunner/lrdb"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "compact-logs",
                Short: "Compact logs into optimally sized files",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        helpers.CleanTempDir()

                        servicename := "lakerunner-compact-logs"
                        addlAttrs := attribute.NewSet(
                                attribute.String("signal", "logs"),
                                attribute.String("action", "compact"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>
                        <span class="cov0" title="0">compactLogsDoneCtx = doneCtx

                        defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">go diskUsageLoop(doneCtx)

                        loop, err := NewRunqueueLoopContext(doneCtx, "logs", "compact", servicename)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create runqueue loop context: %w", err)
                        }</span>

                        <span class="cov0" title="0">return RunqueueLoop(loop, compactLogsFor)</span>
                },
        }
        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}

var compactLogsDoneCtx context.Context

func compactLogsFor(
        ctx context.Context,
        ll *slog.Logger,
        tmpdir string,
        awsmanager *awsclient.Manager,
        sp storageprofile.StorageProfileProvider,
        mdb lrdb.StoreFull,
        inf lockmgr.Workable,
        rpfEstimate int64,
) (WorkResult, error) <span class="cov0" title="0">{
        profile, err := sp.Get(ctx, inf.OrganizationID(), inf.InstanceNum())
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get storage profile", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Error("No role on non-hosted profile")
                        return WorkResultTryAgainLater, err
                }</span>
        }

        <span class="cov0" title="0">s3client, err := awsmanager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get S3 client", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">ll.Info("Processing log compression item", slog.Any("workItem", inf.AsMap()))
        return logCompactItemDo(ctx, ll, mdb, tmpdir, inf, profile, s3client, rpfEstimate)</span>
}

func logCompactItemDo(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        tmpdir string,
        inf lockmgr.Workable,
        sp storageprofile.StorageProfile,
        s3client *awsclient.S3Client,
        rpfEstimate int64,
) (WorkResult, error) <span class="cov0" title="0">{
        st, et, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                return WorkResultSuccess, errors.New("error getting range bounds")
        }</span>
        <span class="cov0" title="0">stdi := timeToDateint(st.Time)
        etdi := timeToDateint(et.Time.Add(-time.Millisecond)) // end dateint is inclusive, so subtract 1ms
        if stdi != etdi </span><span class="cov0" title="0">{
                ll.Error("Range bounds are not the same dateint",
                        slog.Int("startDateint", int(stdi)),
                        slog.Time("st", st.Time),
                        slog.Int("endDateint", int(etdi)),
                        slog.Time("et", et.Time),
                )
                return WorkResultTryAgainLater, errors.New("range bounds are not the same dateint")
        }</span>

        <span class="cov0" title="0">segments, err := mdb.GetLogSegmentsForCompaction(ctx, lrdb.GetLogSegmentsForCompactionParams{
                OrganizationID: sp.OrganizationID,
                Dateint:        stdi,
                InstanceNum:    sp.InstanceNum,
        })
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Error getting log segments for compaction", slog.String("error", err.Error()))
                return WorkResultTryAgainLater, err
        }</span>
        <span class="cov0" title="0">ll.Info("Got log segments for compaction",
                slog.Int("segmentCount", len(segments)))

        if len(segments) == 0 </span><span class="cov0" title="0">{
                ll.Info("No segments to compact")
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">packed, err := logcrunch.PackSegments(segments, rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Error packing segments", slog.String("error", err.Error()))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">lastGroupSmall := false
        if len(packed) &gt; 0 </span><span class="cov0" title="0">{
                // if the last packed segment is smaller than half our target size, drop it.
                bytecount := int64(0)
                lastGroup := packed[len(packed)-1]
                for _, segment := range lastGroup </span><span class="cov0" title="0">{
                        bytecount += segment.FileSize
                }</span>
                <span class="cov0" title="0">if bytecount &lt; targetFileSize/2 </span><span class="cov0" title="0">{
                        packed = packed[:len(packed)-1]
                        lastGroupSmall = true
                }</span>
        }

        <span class="cov0" title="0">if len(packed) == 0 </span><span class="cov0" title="0">{
                ll.Info("No segments to compact")
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">ll.Info("counts", slog.Int("currentSegments", len(segments)), slog.Int("packGroups", len(packed)), slog.Bool("lastGroupSmall", lastGroupSmall))

        for i, group := range packed </span><span class="cov0" title="0">{
                ll := ll.With(slog.Int("groupIndex", i))
                err = packSegment(ctx, ll, tmpdir, s3client, mdb, group, sp, stdi)
                if err != nil </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov0" title="0">select </span>{
                case &lt;-compactLogsDoneCtx.Done():<span class="cov0" title="0">
                        return WorkResultTryAgainLater, errors.New("Asked to shut down, will retry work")</span>
                default:<span class="cov0" title="0"></span>
                }
        }

        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                return WorkResultTryAgainLater, err
        }</span>
        <span class="cov0" title="0">ll.Info("Successfully packed segments", slog.Int("groupCount", len(packed)))
        return WorkResultSuccess, nil</span>
}

// timeToDateint computes the dateint for the current time.  This is YYYYMMDD as an int32.
func timeToDateint(t time.Time) int32 <span class="cov0" title="0">{
        return int32(t.Year()*10000 + int(t.Month())*100 + t.Day())
}</span>

var dropFieldNames = []string{
        "minute",
        "hour",
        "day",
        "month",
        "year",
}

func firstFromGroup(group []lrdb.GetLogSegmentsForCompactionRow) int64 <span class="cov8" title="1">{
        if len(group) == 0 </span><span class="cov8" title="1">{
                return 0
        }</span>
        <span class="cov8" title="1">first := group[0].StartTs
        for _, segment := range group </span><span class="cov8" title="1">{
                first = min(first, segment.StartTs)
        }</span>
        <span class="cov8" title="1">return first</span>
}

func lastFromGroup(group []lrdb.GetLogSegmentsForCompactionRow) int64 <span class="cov8" title="1">{
        last := int64(0)
        for _, segment := range group </span><span class="cov8" title="1">{
                last = max(last, segment.EndTs)
        }</span>
        <span class="cov8" title="1">return last</span>
}

func segmentIDsFrom(segments []lrdb.GetLogSegmentsForCompactionRow) []int64 <span class="cov8" title="1">{
        ids := make([]int64, len(segments))
        for i, segment := range segments </span><span class="cov8" title="1">{
                ids[i] = segment.SegmentID
        }</span>
        <span class="cov8" title="1">return ids</span>
}

func ingestDateintFromGroup(group []lrdb.GetLogSegmentsForCompactionRow) int32 <span class="cov8" title="1">{
        if len(group) == 0 </span><span class="cov8" title="1">{
                return 0
        }</span>
        <span class="cov8" title="1">first := int32(0)
        for _, segment := range group </span><span class="cov8" title="1">{
                first = max(first, segment.IngestDateint)
        }</span>
        <span class="cov8" title="1">return first</span>
}
</pre>
		
		<pre class="file" id="file1" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "fmt"
        "log/slog"
        "math"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lockmgr"
        "github.com/cardinalhq/lakerunner/lrdb"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "compact-metrics",
                Short: "Roll up metrics",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        helpers.CleanTempDir()

                        servicename := "lakerunner-compact-metrics"
                        addlAttrs := attribute.NewSet(
                                attribute.String("signal", "metrics"),
                                attribute.String("action", "compact"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">go diskUsageLoop(doneCtx)

                        loop, err := NewRunqueueLoopContext(doneCtx, "metrics", "compact", servicename)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create runqueue loop context: %w", err)
                        }</span>

                        <span class="cov0" title="0">return RunqueueLoop(loop, compactRollupItem)</span>
                },
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}

func compactRollupItem(
        ctx context.Context,
        ll *slog.Logger,
        tmpdir string,
        awsmanager *awsclient.Manager,
        sp storageprofile.StorageProfileProvider,
        mdb lrdb.StoreFull,
        inf lockmgr.Workable,
        rpfEstimate int64,
) (WorkResult, error) <span class="cov0" title="0">{
        if !isWantedFrequency(inf.FrequencyMs()) </span><span class="cov0" title="0">{
                ll.Info("Skipping compaction for unwanted frequency", slog.Int("frequencyMs", int(inf.FrequencyMs())))
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">profile, err := sp.Get(ctx, inf.OrganizationID(), inf.InstanceNum())
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get storage profile", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Error("No role on non-hosted profile")
                        return WorkResultTryAgainLater, err
                }</span>
        }

        <span class="cov0" title="0">s3client, err := awsmanager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get S3 client", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">ll.Info("Processing metric compression item", slog.Any("workItem", inf))
        return metricCompactItemDo(ctx, ll, mdb, tmpdir, inf, profile, s3client, rpfEstimate)</span>
}

func metricCompactItemDo(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        tmpdir string,
        inf lockmgr.Workable,
        profile storageprofile.StorageProfile,
        s3client *awsclient.S3Client,
        rpfEstimate int64,
) (WorkResult, error) <span class="cov0" title="0">{
        st, et, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                return WorkResultSuccess, fmt.Errorf("invalid time range in work item: %v", inf.TsRange())
        }</span>

        <span class="cov0" title="0">inRows, err := mdb.GetMetricSegs(ctx, lrdb.GetMetricSegsParams{
                OrganizationID: inf.OrganizationID(),
                InstanceNum:    inf.InstanceNum(),
                Dateint:        inf.Dateint(),
                FrequencyMs:    inf.FrequencyMs(),
                StartTs:        st.Time.UTC().UnixMilli(),
                EndTs:          et.Time.UTC().UnixMilli(),
        })
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get current metric segments", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">if len(inRows) == 0 </span><span class="cov0" title="0">{
                ll.Info("No input rows to compact, skipping work item")
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">if !shouldCompactMetrics(inRows) </span><span class="cov0" title="0">{
                ll.Info("No need to compact metrics, skipping work item", slog.Int("rowCount", len(inRows)))
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">err = compactInterval(ctx, ll, mdb, tmpdir, inf, profile, s3client, inRows, rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to compact interval", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">return WorkResultSuccess, nil</span>
}

func shouldCompactMetrics(rows []lrdb.MetricSeg) bool <span class="cov8" title="1">{
        if len(rows) &lt; 2 </span><span class="cov8" title="1">{
                return false
        }</span>

        <span class="cov8" title="1">const smallThreshold = int64(targetFileSize) * 3 / 10

        var totalSize int64
        for _, row := range rows </span><span class="cov8" title="1">{
                totalSize += row.FileSize
                if row.FileSize &gt; targetFileSize*2 || row.FileSize &lt; smallThreshold </span><span class="cov8" title="1">{
                        return true
                }</span>
        }

        <span class="cov8" title="1">estimatedFileCount := (totalSize + targetFileSize - 1) / targetFileSize
        compact := estimatedFileCount &lt; int64(len(rows))-3 // TODO this feels hacky
        return compact</span>
}

func getStartEndTimes(rows []lrdb.MetricSeg) (int64, int64) <span class="cov8" title="1">{
        startTs := int64(math.MaxInt64)
        endTs := int64(math.MinInt64)
        for _, row := range rows </span><span class="cov8" title="1">{
                rowStartTs := row.TsRange.Lower.Int64
                rowEndTs := row.TsRange.Upper.Int64
                startTs = min(startTs, rowStartTs)
                endTs = max(endTs, rowEndTs)
        }</span>
        <span class="cov8" title="1">return startTs, endTs</span>
}

func getIngestDateint(rows []lrdb.MetricSeg) int32 <span class="cov0" title="0">{
        if len(rows) == 0 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov0" title="0">ingest_dateint := int32(0)
        for _, row := range rows </span><span class="cov0" title="0">{
                ingest_dateint = max(ingest_dateint, row.IngestDateint)
        }</span>
        <span class="cov0" title="0">return ingest_dateint</span>
}

func compactInterval(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        tmpdir string,
        inf lockmgr.Workable,
        profile storageprofile.StorageProfile,
        s3client *awsclient.S3Client,
        rows []lrdb.MetricSeg,
        rpfEstimate int64) error <span class="cov0" title="0">{
        st, _, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                ll.Error("Invalid time range in work item", slog.Any("tsRange", inf.TsRange()))
                return fmt.Errorf("invalid time range in work item: %v", inf.TsRange())
        }</span>

        <span class="cov0" title="0">files := make([]string, 0, len(rows))
        for _, row := range rows </span><span class="cov0" title="0">{
                dateint, hour := helpers.MSToDateintHour(st.Time.UTC().UnixMilli())
                objectID := helpers.MakeDBObjectID(inf.OrganizationID(), profile.CollectorName, dateint, hour, row.SegmentID, "metrics")
                fn, downloadedSize, is404, err := s3helper.DownloadS3Object(ctx, tmpdir, s3client, profile.Bucket, objectID)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to download S3 object", slog.String("objectID", objectID), slog.Any("error", err))
                        return err
                }</span>
                <span class="cov0" title="0">if is404 </span><span class="cov0" title="0">{
                        ll.Info("S3 object not found, skipping", slog.String("bucket", profile.Bucket), slog.String("objectID", objectID))
                        continue</span>
                }

                <span class="cov0" title="0">ll.Info("Downloaded S3 SOURCE", slog.String("objectID", objectID), slog.String("bucket", profile.Bucket), slog.Int64("rowFileSize", row.FileSize), slog.Int64("s3FileSize", downloadedSize))
                files = append(files, fn)</span>
        }

        <span class="cov0" title="0">if len(files) == 0 </span><span class="cov0" title="0">{
                ll.Info("No files to compact, skipping work item")
                return nil
        }</span>

        <span class="cov0" title="0">startTS, endTS, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                ll.Error("Invalid time range in work item", slog.Any("tsRange", inf.TsRange()))
                return fmt.Errorf("invalid time range in work item: %v", inf.TsRange())
        }</span>

        <span class="cov0" title="0">merger, err := NewTIDMerger(tmpdir, files, inf.FrequencyMs(), rpfEstimate, startTS.Time.UTC().UnixMilli(), endTS.Time.UTC().UnixMilli())
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to create TIDMerger", slog.Any("error", err))
                return fmt.Errorf("creating TIDMerger: %w", err)
        }</span>

        <span class="cov0" title="0">mergeResult, stats, err := merger.Merge()
        if stats.DatapointsOutOfRange &gt; 0 </span><span class="cov0" title="0">{
                ll.Warn("Some datapoints were out of range", slog.Int64("count", stats.DatapointsOutOfRange))
        }</span>
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to merge files", slog.Any("error", err))
                return fmt.Errorf("merging files: %w", err)
        }</span>
        <span class="cov0" title="0">ll.Info("Merge results", slog.Any("sourceFiles", files), slog.Any("mergeResult", mergeResult), slog.Int64("estimatedRowCount", rpfEstimate))

        startingFileCount := len(files)
        endingFileCount := len(mergeResult)
        ll.Info("Compaction results",
                slog.Int("startingFileCount", startingFileCount),
                slog.Int("endingFileCount", endingFileCount),
                slog.Int("percentFileCountReduction", (startingFileCount-endingFileCount)*100/startingFileCount),
        )

        // Find the starTs and endTs of this new group of files.
        startTs, endTs := getStartEndTimes(rows)
        ingest_dateint := getIngestDateint(rows)

        // now we need to update the source items to mark them as having been rolled up,
        // add our new file to the database, and remove any previous files for this timebox.
        params := lrdb.ReplaceMetricSegsParams{
                OrganizationID: inf.OrganizationID(),
                Dateint:        inf.Dateint(),
                IngestDateint:  ingest_dateint,
                InstanceNum:    inf.InstanceNum(),
                FrequencyMs:    inf.FrequencyMs(),
                Published:      true,
                Rolledup:       allRolledUp(rows),
                CreatedBy:      lrdb.CreatedByCompact,
        }

        for _, row := range rows </span><span class="cov0" title="0">{
                ll.Info("removing old metric segment", slog.Int("tidPartition", int(row.TidPartition)), slog.Int64("segmentID", row.SegmentID))
                params.OldRecords = append(params.OldRecords, lrdb.ReplaceMetricSegsOld{
                        TidPartition: row.TidPartition,
                        SegmentID:    row.SegmentID,
                })
        }</span>

        <span class="cov0" title="0">dateint, hour := helpers.MSToDateintHour(startTs)
        for tidPartition, result := range mergeResult </span><span class="cov0" title="0">{
                segmentID := s3helper.GenerateID()
                newObjectID := helpers.MakeDBObjectID(inf.OrganizationID(), profile.CollectorName, dateint, hour, segmentID, "metrics")
                ll.Info("Uploading to S3", slog.String("objectID", newObjectID), slog.String("bucket", profile.Bucket))
                err = s3helper.UploadS3Object(ctx, s3client, profile.Bucket, newObjectID, result.FileName)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to upload new S3 object", slog.String("objectID", newObjectID), slog.Any("error", err))
                        return fmt.Errorf("uploading new S3 object: %w", err)
                }</span>
                <span class="cov0" title="0">ll.Info("adding new metric segment", slog.Int("tidPartition", int(tidPartition)), slog.Int64("segmentID", segmentID))
                params.NewRecords = append(params.NewRecords, lrdb.ReplaceMetricSegsNew{
                        TidPartition: int16(tidPartition),
                        SegmentID:    segmentID,
                        StartTs:      startTs,
                        EndTs:        endTs,
                        RecordCount:  result.RecordCount,
                        FileSize:     result.FileSize,
                        TidCount:     result.TidCount,
                })</span>
        }

        <span class="cov0" title="0">if err := mdb.ReplaceMetricSegs(ctx, params); err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to replace metric segments", slog.Any("error", err))
                return fmt.Errorf("replacing metric segments: %w", err)
        }</span>
        <span class="cov0" title="0">ll.Info("Replaced metric segments")

        for _, row := range rows </span><span class="cov0" title="0">{
                rst, _, ok := RangeBounds(row.TsRange)
                if !ok </span><span class="cov0" title="0">{
                        ll.Error("Invalid time range in row", slog.Any("tsRange", row.TsRange))
                        return fmt.Errorf("invalid time range in row: %v", row.TsRange)
                }</span>
                <span class="cov0" title="0">dateint, hour := helpers.MSToDateintHour(rst.Int64)
                oid := helpers.MakeDBObjectID(inf.OrganizationID(), profile.CollectorName, dateint, hour, row.SegmentID, "metrics")
                if err := s3helper.ScheduleS3Delete(ctx, mdb, profile.OrganizationID, profile.InstanceNum, profile.Bucket, oid); err != nil </span><span class="cov0" title="0">{
                        ll.Error("scheduleS3Delete", slog.String("error", err.Error()))
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file2" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package dbopen

import (
        "errors"
        "fmt"
        "net/url"
        "os"
        "strings"
)

// getDatabaseURLFromEnv constructs a PostgreSQL URL from environment
// variables named PREFIX_HOST, PREFIX_PORT, PREFIX_USER, PREFIX_PASSWORD,
// PREFIX_DBNAME, and optionally PREFIX_SSLMODE. If PREFIX does not end in
// "_", it will be added automatically.
//
// It requires at minimum HOST and DBNAME, and will default PORT to 5432.
// Returns an error listing any missing required variables.
func getDatabaseURLFromEnv(prefix string) (string, error) <span class="cov0" title="0">{
        if !strings.HasSuffix(prefix, "_") </span><span class="cov0" title="0">{
                prefix += "_"
        }</span>

        // First check to see if prefix_URL is set.  If so, return it directly.
        <span class="cov0" title="0">if urlStr := os.Getenv(prefix + "URL"); urlStr != "" </span><span class="cov0" title="0">{
                return urlStr, nil
        }</span>

        // required
        <span class="cov0" title="0">host := os.Getenv(prefix + "HOST")
        dbname := os.Getenv(prefix + "DBNAME")

        var missing []string
        if host == "" </span><span class="cov0" title="0">{
                missing = append(missing, prefix+"HOST")
        }</span>
        <span class="cov0" title="0">if dbname == "" </span><span class="cov0" title="0">{
                missing = append(missing, prefix+"DBNAME")
        }</span>
        <span class="cov0" title="0">if len(missing) &gt; 0 </span><span class="cov0" title="0">{
                return "", fmt.Errorf(
                        "missing required environment variable(s): %s",
                        strings.Join(missing, ", "),
                )
        }</span>

        // optional with defaults
        <span class="cov0" title="0">port := os.Getenv(prefix + "PORT")
        if port == "" </span><span class="cov0" title="0">{
                port = "5432"
        }</span>

        <span class="cov0" title="0">user := os.Getenv(prefix + "USER")
        pass := os.Getenv(prefix + "PASSWORD")

        sslmode := os.Getenv(prefix + "SSLMODE") // e.g. "require", "disable"

        u := &amp;url.URL{
                Scheme: "postgresql",
                Host:   host + ":" + port,
                Path:   dbname,
        }

        if user != "" </span><span class="cov0" title="0">{
                if pass != "" </span><span class="cov0" title="0">{
                        u.User = url.UserPassword(user, pass)
                }</span> else<span class="cov0" title="0"> {
                        u.User = url.User(user)
                }</span>
        }

        // add sslmode or any other query params
        <span class="cov0" title="0">q := u.Query()
        if sslmode != "" </span><span class="cov0" title="0">{
                q.Set("sslmode", sslmode)
        }</span>

        // if envar OTEL_SERVICE_NAME is set, add it as the application_name
        // query parameter unless it's already set.  We will ensure it has only
        // alphanumeric, -, and _ characters.
        <span class="cov0" title="0">if appName := os.Getenv("OTEL_SERVICE_NAME"); appName != "" </span><span class="cov0" title="0">{
                if q.Get("application_name") == "" </span><span class="cov0" title="0">{
                        appName = strings.Map(func(r rune) rune </span><span class="cov0" title="0">{
                                if (r &gt;= 'a' &amp;&amp; r &lt;= 'z') ||
                                        (r &gt;= 'A' &amp;&amp; r &lt;= 'Z') ||
                                        (r &gt;= '0' &amp;&amp; r &lt;= '9') ||
                                        r == '-' || r == '_' </span><span class="cov0" title="0">{
                                        return r
                                }</span>
                                <span class="cov0" title="0">return '_'</span>
                        }, appName)
                        <span class="cov0" title="0">if len(appName) &gt; 63 </span><span class="cov0" title="0">{
                                appName = appName[:63]
                        }</span>
                        <span class="cov0" title="0">q.Set("application_name", appName)</span>
                }
        }

        <span class="cov0" title="0">u.RawQuery = q.Encode()

        return u.String(), nil</span>
}

var ErrDatabaseNotConfigured = errors.New("database connection configuration is unavailable")
</pre>
		
		<pre class="file" id="file3" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package dbopen

import (
        "context"
        "errors"
        "fmt"

        "github.com/jackc/pgx/v5/pgxpool"

        "github.com/cardinalhq/lakerunner/internal/configdb"
)

func ConnectToConfigDB(ctx context.Context) (*pgxpool.Pool, error) <span class="cov0" title="0">{
        connectionString, err := getDatabaseURLFromEnv("CONFIGDB")
        if err != nil </span><span class="cov0" title="0">{
                return nil, errors.Join(ErrDatabaseNotConfigured, fmt.Errorf("failed to get CONFIGDB connection string: %w", err))
        }</span>
        <span class="cov0" title="0">return configdb.NewConnectionPool(ctx, connectionString)</span>
}

func ConfigDBStore(ctx context.Context) (configdb.QuerierFull, error) <span class="cov0" title="0">{
        pool, err := ConnectToConfigDB(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">configStore := configdb.NewStore(pool)
        return configStore, nil</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package dbopen

import (
        "context"
        "errors"
        "fmt"

        "github.com/jackc/pgx/v5/pgxpool"

        "github.com/cardinalhq/lakerunner/lrdb"
)

func ConnectTolrdb(ctx context.Context) (*pgxpool.Pool, error) <span class="cov0" title="0">{
        connectionString, err := getDatabaseURLFromEnv("LRDB")
        if err != nil </span><span class="cov0" title="0">{
                return nil, errors.Join(ErrDatabaseNotConfigured, fmt.Errorf("failed to get LRDB connection string: %w", err))
        }</span>
        <span class="cov0" title="0">return lrdb.NewConnectionPool(ctx, connectionString)</span>
}

func LRDBStore(ctx context.Context) (lrdb.StoreFull, error) <span class="cov0" title="0">{
        pool, err := ConnectTolrdb(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">lrStore := lrdb.NewStore(pool)
        return lrStore, nil</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "github.com/spf13/cobra"

        debugcmd "github.com/cardinalhq/lakerunner/cmd/debug"
)

var debugCmd = &amp;cobra.Command{
        Use:   "debug",
        Short: "Debug commands for troubleshooting",
        Long:  `Debug commands for troubleshooting various components of lakerunner.`,
}

func init() <span class="cov8" title="1">{
        debugCmd.AddCommand(debugcmd.GetKubernetesDiscoveryCmd())
        debugCmd.AddCommand(debugcmd.GetS3CatCmd())
        debugCmd.AddCommand(debugcmd.GetS3LSCmd())
        debugCmd.AddCommand(debugcmd.GetDDBCmd())
        debugCmd.AddCommand(debugcmd.GetParquetSchemaCmd())
        debugCmd.AddCommand(debugcmd.GetSQLiteCmd())
        debugCmd.AddCommand(debugcmd.GetFileConvCmd())
}</span>
</pre>
		
		<pre class="file" id="file6" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "context"

        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/internal/duckdbx"
)

func GetDDBCmd() *cobra.Command <span class="cov0" title="0">{
        ddbCmd := &amp;cobra.Command{
                Use:   "ddb",
                Short: "Run a DuckDB SQL test",
                RunE: func(cmd *cobra.Command, args []string) error </span><span class="cov0" title="0">{
                        return runDDB(cmd.Context(), args)
                }</span>,
        }

        <span class="cov0" title="0">return ddbCmd</span>
}

// runDDB runs a DuckDB SQL test.
func runDDB(ctx context.Context, _ []string) error <span class="cov0" title="0">{
        ddb, err := duckdbx.Open("",
                duckdbx.WithMemoryLimitMB(2048),
                duckdbx.WithExtension("httpfs", ""),
        )
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer ddb.Close()

        for range 10 </span><span class="cov0" title="0">{
                c, err := ddb.Conn(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">defer c.Close()

                rows, err := c.QueryContext(ctx, "SELECT 42;")
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov0" title="0">for rows.Next() </span><span class="cov0" title="0">{
                        var answer int
                        if err := rows.Scan(&amp;answer); err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                        <span class="cov0" title="0">println("The answer is", answer)</span>
                }
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "os"

        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/cmd/ingestlogs"
)

func GetFileConvCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "fileconv",
                Short: "File conversion utilities",
                Long:  `Utilities for converting files from various formats to a common format for processing.`,
                RunE:  runFileConv,
        }

        cmd.Flags().StringP("input", "i", "", "Input file path")
        _ = cmd.MarkFlagRequired("input")

        cmd.Flags().Int64("rows-per-file", 40_000, "Target number of rows per output file")

        return cmd
}</span>

func runFileConv(cmd *cobra.Command, args []string) error <span class="cov0" title="0">{
        input, _ := cmd.Flags().GetString("input")
        rpf, _ := cmd.Flags().GetInt64("rows-per-file")

        tmpdir, err := os.MkdirTemp("", "fileconv-*")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">files, err := ingestlogs.ConvertRawParquet(input, tmpdir, "default-bucket", "default-object-id", rpf)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">if len(files) == 0 </span><span class="cov0" title="0">{
                cmd.Println("Input contained no rows")
                return nil
        }</span>

        <span class="cov0" title="0">cmd.Printf("Conversion complete. Output files: %v\n", files)
        return nil</span>
}
</pre>
		
		<pre class="file" id="file8" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "context"
        "fmt"
        "strings"
        "time"

        "github.com/google/uuid"
        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/promql"
)

var kubernetesDiscoveryCmd = &amp;cobra.Command{
        Use:   "kubernetes-discovery",
        Short: "Debug Kubernetes worker discovery",
        Long:  `Debug the Kubernetes worker discovery system by showing what workers are found.`,
        RunE:  runKubernetesDiscovery,
}

var (
        podNamespace        string
        workerLabelSelector string
        queryWorkerPort     int
        organizationIDStr   string
        testSegments        string
)

func init() <span class="cov0" title="0">{
        kubernetesDiscoveryCmd.Flags().StringVar(&amp;podNamespace, "pod-namespace", "", "POD_NAMESPACE: Kubernetes namespace to search in (required)")
        kubernetesDiscoveryCmd.Flags().StringVar(&amp;workerLabelSelector, "worker-pod-label-selector", "", "WORKER_POD_LABEL_SELECTOR: Label selector for worker pods (required)")
        kubernetesDiscoveryCmd.Flags().IntVar(&amp;queryWorkerPort, "query-worker-port", 0, "QUERY_WORKER_PORT: Port to use for worker connections (required)")
        kubernetesDiscoveryCmd.Flags().StringVar(&amp;organizationIDStr, "organization-id", "550e8400-e29b-41d4-a716-446655440000", "Organization ID (UUID) for segment mapping")
        kubernetesDiscoveryCmd.Flags().StringVar(&amp;testSegments, "test-segments", "tbl_1,tbl_2,tbl_3,tbl_4,tbl_5", "Comma-separated list of segment IDs to test mapping")

        if err := kubernetesDiscoveryCmd.MarkFlagRequired("pod-namespace"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark pod-namespace as required: %w", err))</span>
        }
        <span class="cov0" title="0">if err := kubernetesDiscoveryCmd.MarkFlagRequired("worker-pod-label-selector"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark worker-pod-label-selector as required: %w", err))</span>
        }
        <span class="cov0" title="0">if err := kubernetesDiscoveryCmd.MarkFlagRequired("query-worker-port"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark query-worker-port as required: %w", err))</span>
        }
}

func runKubernetesDiscovery(cmd *cobra.Command, args []string) error <span class="cov0" title="0">{
        fmt.Printf("Debugging Kubernetes worker discovery...\n")
        fmt.Printf("POD_NAMESPACE: %s\n", podNamespace)
        fmt.Printf("WORKER_POD_LABEL_SELECTOR: %s\n", workerLabelSelector)
        fmt.Printf("QUERY_WORKER_PORT: %d\n", queryWorkerPort)
        fmt.Printf("Organization ID: %s\n", organizationIDStr)
        fmt.Printf("Test Segments: %s\n", testSegments)
        fmt.Printf("\n")

        // Parse organization ID
        organizationID, err := uuid.Parse(organizationIDStr)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid organization ID UUID: %w", err)
        }</span>

        // Parse segment IDs
        <span class="cov0" title="0">var segmentIDs []string
        if testSegments != "" </span><span class="cov0" title="0">{
                parts := strings.Split(testSegments, ",")
                for _, part := range parts </span><span class="cov0" title="0">{
                        segmentIDs = append(segmentIDs, strings.TrimSpace(part))
                }</span>
        }

        <span class="cov0" title="0">config := promql.KubernetesWorkerDiscoveryConfig{
                Namespace:           podNamespace,
                WorkerLabelSelector: workerLabelSelector,
                WorkerPort:          queryWorkerPort,
        }

        discovery, err := promql.NewKubernetesWorkerDiscovery(config)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create Kubernetes worker discovery: %w", err)
        }</span>

        // Start the discovery service
        <span class="cov0" title="0">ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()

        fmt.Printf("Starting worker discovery service...\n")
        if err := discovery.Start(ctx); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to start worker discovery: %w", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                if err := discovery.Stop(); err != nil </span><span class="cov0" title="0">{
                        fmt.Printf("⚠️  Error stopping discovery: %v\n", err)
                }</span>
        }()
        <span class="cov0" title="0">fmt.Printf("✅ Worker discovery service started successfully\n")

        // Give the informers a moment to settle
        fmt.Printf("Waiting for initial worker discovery...\n")
        time.Sleep(500 * time.Millisecond)
        fmt.Printf("✅ Ready to test\n")

        // Get all workers
        fmt.Printf("Discovering workers...\n")
        workers, err := discovery.GetAllWorkers()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get workers: %w", err)
        }</span>

        <span class="cov0" title="0">fmt.Printf("Found %d workers:\n", len(workers))
        for i, worker := range workers </span><span class="cov0" title="0">{
                fmt.Printf("  [%d] %s:%d\n", i+1, worker.IP, worker.Port)
        }</span>

        <span class="cov0" title="0">if len(workers) == 0 </span><span class="cov0" title="0">{
                fmt.Printf("\nNo workers found. Check:\n")
                fmt.Printf("- Label selector matches worker pods: %s\n", workerLabelSelector)
                fmt.Printf("- Namespace contains the worker pods: %s\n", podNamespace)
                fmt.Printf("- Worker pods are in Ready state\n")
                fmt.Printf("- EndpointSlices exist for the service\n")
                return nil
        }</span>

        // Test segment mapping
        <span class="cov0" title="0">if len(segmentIDs) &gt; 0 </span><span class="cov0" title="0">{
                fmt.Printf("\nTesting segment-to-worker mapping:\n")
                mappings, err := discovery.GetWorkersForSegments(organizationID, segmentIDs)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to get segment mappings: %w", err)
                }</span>

                <span class="cov0" title="0">for _, mapping := range mappings </span><span class="cov0" title="0">{
                        fmt.Printf("  Segment %s -&gt; %s:%d\n", mapping.SegmentID, mapping.Worker.IP, mapping.Worker.Port)
                }</span>

                // Test consistency - same segments should map to same workers
                <span class="cov0" title="0">fmt.Printf("\nTesting consistency (same mapping should be returned):\n")
                mappings2, err := discovery.GetWorkersForSegments(organizationID, segmentIDs)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to get segment mappings for consistency test: %w", err)
                }</span>

                <span class="cov0" title="0">consistent := true
                for i, mapping := range mappings </span><span class="cov0" title="0">{
                        if mapping.Worker.IP != mappings2[i].Worker.IP </span><span class="cov0" title="0">{
                                fmt.Printf("  ❌ Segment %s: %s != %s (INCONSISTENT)\n",
                                        mapping.SegmentID, mapping.Worker.IP, mappings2[i].Worker.IP)
                                consistent = false
                        }</span> else<span class="cov0" title="0"> {
                                fmt.Printf("  ✅ Segment %s: %s (consistent)\n", mapping.SegmentID, mapping.Worker.IP)
                        }</span>
                }

                <span class="cov0" title="0">if consistent </span><span class="cov0" title="0">{
                        fmt.Printf("\n✅ All segment mappings are consistent!\n")
                }</span> else<span class="cov0" title="0"> {
                        fmt.Printf("\n❌ Some segment mappings are inconsistent!\n")
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// GetKubernetesDiscoveryCmd returns the kubernetes-discovery command for registration
func GetKubernetesDiscoveryCmd() *cobra.Command <span class="cov0" title="0">{
        return kubernetesDiscoveryCmd
}</span>
</pre>
		
		<pre class="file" id="file9" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "fmt"

        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/internal/filecrunch"
)

func GetParquetSchemaCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "parquet-schema",
                Short: "Print out the schema of a Parquet file",
                RunE: func(c *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        filename, err := c.Flags().GetString("file")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get file flag: %w", err)
                        }</span>

                        <span class="cov0" title="0">return runParquetSchema(filename)</span>
                },
        }

        <span class="cov0" title="0">cmd.Flags().String("file", "", "Parquet file to read")
        if err := cmd.MarkFlagRequired("file"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark file flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">return cmd</span>
}

func runParquetSchema(filename string) error <span class="cov0" title="0">{

        fh, err := filecrunch.LoadSchemaForFile(filename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load schema for file %s: %w", filename, err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                _ = fh.Close()
        }</span>()

        <span class="cov0" title="0">fmt.Println(fh.Schema.String())

        return nil</span>
}
</pre>
		
		<pre class="file" id="file10" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "context"
        "encoding/base64"
        "fmt"
        "os"

        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
)

func GetS3CatCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "s3cat",
                Short: "return Base64 for an S3 file",
                RunE: func(c *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        bucketID, err := c.Flags().GetString("bucket")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get bucket flag: %w", err)
                        }</span>
                        <span class="cov0" title="0">objectID, err := c.Flags().GetString("objectid")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get objectid flag: %w", err)
                        }</span>
                        <span class="cov0" title="0">region, err := c.Flags().GetString("region")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get region flag: %w", err)
                        }</span>
                        <span class="cov0" title="0">role, err := c.Flags().GetString("role")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get role flag: %w", err)
                        }</span>

                        <span class="cov0" title="0">return runS3Cat(bucketID, objectID, region, role)</span>
                },
        }

        <span class="cov0" title="0">cmd.Flags().String("bucket", "", "S3 bucket")
        if err := cmd.MarkFlagRequired("bucket"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark bucket flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("objectid", "", "S3 objectid")
        if err := cmd.MarkFlagRequired("objectid"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark objectid flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("region", "us-east-2", "AWS region of the S3 bucket")
        if err := cmd.MarkFlagRequired("region"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark region flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("role", "", "AWS IAM role to assume for S3 access")

        return cmd</span>
}

func runS3Cat(bucketID string, objectID string, region string, role string) error <span class="cov0" title="0">{
        ctx := context.Background()

        // Initialize AWS S3 client
        mgr, err := awsclient.NewManager(ctx,
                awsclient.WithAssumeRoleSessionName("lakerunner-import"),
        )
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">var opts []awsclient.S3Option
        if role != "" </span><span class="cov0" title="0">{
                opts = append(opts, awsclient.WithRole(role))
        }</span>
        <span class="cov0" title="0">if region != "" </span><span class="cov0" title="0">{
                opts = append(opts, awsclient.WithRegion(region))
        }</span>
        <span class="cov0" title="0">s3client, err := mgr.GetS3(ctx, opts...)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get S3 client: %w", err)
        }</span>

        <span class="cov0" title="0">tmpdir, err := os.MkdirTemp("", "lakerunner-s3cat")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create temporary directory: %w", err)
        }</span>
        <span class="cov0" title="0">defer os.RemoveAll(tmpdir)

        fn, size, is404, err := s3helper.DownloadS3Object(ctx, tmpdir, s3client, bucketID, objectID)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to download S3 object: %w", err)
        }</span>
        <span class="cov0" title="0">if is404 </span><span class="cov0" title="0">{
                return fmt.Errorf("object %s/%s not found", bucketID, objectID)
        }</span>
        <span class="cov0" title="0">fmt.Printf("Downloaded %s (%d bytes) to %s\n", objectID, size, fn)

        // Convert to base64 so we can print it to stdout
        data, err := os.ReadFile(fn)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to read downloaded file: %w", err)
        }</span>
        <span class="cov0" title="0">b64 := base64.StdEncoding.EncodeToString(data)
        fmt.Println(b64)

        return nil</span>
}
</pre>
		
		<pre class="file" id="file11" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "context"
        "fmt"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/service/s3"
        "github.com/spf13/cobra"
        "golang.org/x/exp/slog"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
)

func GetS3LSCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "s3ls",
                Short: "List a bucket prefix in S3",
                RunE: func(c *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        bucketID, err := c.Flags().GetString("bucket")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get bucket flag: %w", err)
                        }</span>
                        <span class="cov0" title="0">prefix, err := c.Flags().GetString("prefix")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get prefix flag: %w", err)
                        }</span>
                        <span class="cov0" title="0">region, err := c.Flags().GetString("region")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get region flag: %w", err)
                        }</span>
                        <span class="cov0" title="0">role, err := c.Flags().GetString("role")
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to get role flag: %w", err)
                        }</span>

                        <span class="cov0" title="0">return runS3LS(bucketID, prefix, region, role)</span>
                },
        }

        <span class="cov0" title="0">cmd.Flags().String("bucket", "", "S3 bucket to list")
        if err := cmd.MarkFlagRequired("bucket"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark bucket flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("prefix", "", "S3 prefix to list")
        if err := cmd.MarkFlagRequired("prefix"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark prefix flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("region", "us-east-2", "AWS region of the S3 bucket")
        if err := cmd.MarkFlagRequired("region"); err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to mark region flag as required: %w", err))</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("role", "", "AWS IAM role to assume for S3 access")

        return cmd</span>
}

func runS3LS(bucketID string, prefix string, region string, role string) error <span class="cov0" title="0">{
        ctx := context.Background()

        // Initialize AWS S3 client
        mgr, err := awsclient.NewManager(ctx,
                awsclient.WithAssumeRoleSessionName("lakerunner-import"),
        )
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">var opts []awsclient.S3Option
        if role != "" </span><span class="cov0" title="0">{
                opts = append(opts, awsclient.WithRole(role))
        }</span>
        <span class="cov0" title="0">if region != "" </span><span class="cov0" title="0">{
                opts = append(opts, awsclient.WithRegion(region))
        }</span>
        <span class="cov0" title="0">s3client, err := mgr.GetS3(ctx, opts...)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get S3 client: %w", err)
        }</span>

        // List objects in the specified S3 bucket and prefix
        <span class="cov0" title="0">err = listS3Objects(ctx, s3client.Client, bucketID, prefix)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// listS3Objects returns all object keys under the given prefix.
// It logs any paging/list errors and bubbles them up.
func listS3Objects(ctx context.Context, s3client *s3.Client, bucketID, prefix string) error <span class="cov0" title="0">{
        paginator := s3.NewListObjectsV2Paginator(s3client, &amp;s3.ListObjectsV2Input{
                Bucket: aws.String(bucketID),
                Prefix: aws.String(prefix),
        })

        for paginator.HasMorePages() </span><span class="cov0" title="0">{
                page, err := paginator.NextPage(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to list S3 objects",
                                slog.String("bucket", bucketID),
                                slog.String("prefix", prefix),
                                slog.Any("error", err),
                        )
                        return err
                }</span>

                <span class="cov0" title="0">for _, obj := range page.Contents </span><span class="cov0" title="0">{
                        fmt.Println(aws.ToString(obj.Key))
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file12" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package debug

import (
        "database/sql"
        "encoding/json"
        "errors"
        "fmt"
        "io"
        "log/slog"
        "strings"

        "github.com/parquet-go/parquet-go"
        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/internal/filecrunch"

        _ "modernc.org/sqlite" // Import SQLite driver
)

func GetSQLiteCmd() *cobra.Command <span class="cov0" title="0">{
        cmd := &amp;cobra.Command{
                Use:   "sqlite",
                Short: "SQLite database management commands",
                Long:  `Commands for managing SQLite databases`,
                RunE:  runSqlite,
        }

        cmd.Flags().String("sqlite", "", "SQLite database filename")
        if err := cmd.MarkFlagRequired("sqlite"); err != nil </span><span class="cov0" title="0">{
                panic(err)</span>
        }

        <span class="cov0" title="0">cmd.Flags().String("parquet", "", "Parquet filename")
        if err := cmd.MarkFlagRequired("parquet"); err != nil </span><span class="cov0" title="0">{
                panic(err)</span>
        }

        <span class="cov0" title="0">return cmd</span>
}

type CardinalHQFields struct {
        MetricType    string // _cardinalhq.metric_type
        Tid           int64  // _cardinalhq.tid
        TelemetryType string // _cardinalhq.telemetry_type
        CustomerID    string // _cardinalhq.customer_id
        Name          string // _cardinalhq.name
        Timestamp     int64  // _cardinalhq.timestamp
        CollectorID   string // _cardinalhq.collector_id
}

type RollupFields struct {
        Avg   float64 // rollup_avg
        Count float64 // rollup_count
        Max   float64 // rollup_max
        Min   float64 // rollup_min
        P25   float64 // rollup_p25
        P50   float64 // rollup_p50
        P75   float64 // rollup_p75
        P90   float64 // rollup_p90
        P95   float64 // rollup_p95
        P99   float64 // rollup_p99
        Sum   float64 // rollup_sum
}

type Item struct {
        Cardinal CardinalHQFields
        Rollup   RollupFields
        Sketch   []byte
        Other    map[string]string
}

func itemFromParquet(rec map[string]any) (Item, error) <span class="cov0" title="0">{
        metricType, ok := rec["_cardinalhq.metric_type"].(string)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.metric_type as string, got %T", rec["_cardinalhq.metric_type"])
        }</span>

        <span class="cov0" title="0">tid, ok := rec["_cardinalhq.tid"].(int64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.tid as int64, got %T", rec["_cardinalhq.tid"])
        }</span>

        <span class="cov0" title="0">telemetryType, ok := rec["_cardinalhq.telemetry_type"].(string)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.telemetry_type as string, got %T", rec["_cardinalhq.telemetry_type"])
        }</span>

        <span class="cov0" title="0">customerID, ok := rec["_cardinalhq.customer_id"].(string)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.customer_id as string, got %T", rec["_cardinalhq.customer_id"])
        }</span>

        <span class="cov0" title="0">name, ok := rec["_cardinalhq.name"].(string)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.name as string, got %T", rec["_cardinalhq.name"])
        }</span>

        <span class="cov0" title="0">timestamp, ok := rec["_cardinalhq.timestamp"].(int64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.timestamp as int64, got %T", rec["_cardinalhq.timestamp"])
        }</span>

        <span class="cov0" title="0">collectorID, ok := rec["_cardinalhq.collector_id"].(string)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected _cardinalhq.collector_id as string, got %T", rec["_cardinalhq.collector_id"])
        }</span>

        <span class="cov0" title="0">rollupAvg, ok := rec["rollup_avg"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_avg as float64, got %T", rec["rollup_avg"])
        }</span>

        <span class="cov0" title="0">rollupCount, ok := rec["rollup_count"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_count as float64, got %T", rec["rollup_count"])
        }</span>

        <span class="cov0" title="0">rollupMax, ok := rec["rollup_max"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_max as float64, got %T", rec["rollup_max"])
        }</span>

        <span class="cov0" title="0">rollupMin, ok := rec["rollup_min"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_min as float64, got %T", rec["rollup_min"])
        }</span>

        <span class="cov0" title="0">rollupP25, ok := rec["rollup_p25"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_p25 as float64, got %T", rec["rollup_p25"])
        }</span>

        <span class="cov0" title="0">rollupP50, ok := rec["rollup_p50"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_p50 as float64, got %T", rec["rollup_p50"])
        }</span>

        <span class="cov0" title="0">rollupP75, ok := rec["rollup_p75"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_p75 as float64, got %T", rec["rollup_p75"])
        }</span>

        <span class="cov0" title="0">rollupP90, ok := rec["rollup_p90"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_p90 as float64, got %T", rec["rollup_p90"])
        }</span>

        <span class="cov0" title="0">rollupP95, ok := rec["rollup_p95"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_p95 as float64, got %T", rec["rollup_p95"])
        }</span>

        <span class="cov0" title="0">rollupP99, ok := rec["rollup_p99"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_p99 as float64, got %T", rec["rollup_p99"])
        }</span>

        <span class="cov0" title="0">rollupSum, ok := rec["rollup_sum"].(float64)
        if !ok </span><span class="cov0" title="0">{
                return Item{}, fmt.Errorf("expected rollup_sum as float64, got %T", rec["rollup_sum"])
        }</span>

        <span class="cov0" title="0">var sketch []byte
        switch v := rec["sketch"].(type) </span>{
        case []byte:<span class="cov0" title="0">
                sketch = v</span>
        case string:<span class="cov0" title="0">
                sketch = []byte(v)</span>
        default:<span class="cov0" title="0">
                return Item{}, fmt.Errorf("expected sketch as []byte or string, got %T", rec["sketch"])</span>
        }

        <span class="cov0" title="0">tagsMap := make(map[string]string)
        for k, v := range rec </span><span class="cov0" title="0">{
                if strings.HasPrefix(k, "resource.") ||
                        strings.HasPrefix(k, "metric.") ||
                        strings.HasPrefix(k, "scope.") ||
                        strings.HasPrefix(k, "datapoint.") </span><span class="cov0" title="0">{
                        if v == nil </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">if s, ok := v.(string); ok </span><span class="cov0" title="0">{
                                tagsMap[k] = s
                        }</span>
                }
        }

        <span class="cov0" title="0">item := Item{
                Cardinal: CardinalHQFields{
                        MetricType:    metricType,
                        Tid:           tid,
                        TelemetryType: telemetryType,
                        CustomerID:    customerID,
                        Name:          name,
                        Timestamp:     timestamp,
                        CollectorID:   collectorID,
                },
                Rollup: RollupFields{
                        Avg:   rollupAvg,
                        Count: rollupCount,
                        Max:   rollupMax,
                        Min:   rollupMin,
                        P25:   rollupP25,
                        P50:   rollupP50,
                        P75:   rollupP75,
                        P90:   rollupP90,
                        P95:   rollupP95,
                        P99:   rollupP99,
                        Sum:   rollupSum,
                },
                Sketch: sketch,
                Other:  tagsMap,
        }

        return item, nil</span>
}

func createTable(db *sql.DB) error <span class="cov0" title="0">{
        dropTableSQL := `DROP TABLE IF EXISTS items;`
        if _, err := db.Exec(dropTableSQL); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("dropping table: %w", err)
        }</span>

        <span class="cov0" title="0">createTableSQL := `
CREATE TABLE IF NOT EXISTS items (
  "_cardinalhq.metric_type"    TEXT    NOT NULL,
  "_cardinalhq.tid"            BIGINT  NOT NULL,
  "_cardinalhq.telemetry_type" TEXT    NOT NULL,
  "_cardinalhq.customer_id"    TEXT    NOT NULL,
  "_cardinalhq.name"           TEXT    NOT NULL,
  "_cardinalhq.timestamp"      BIGINT  NOT NULL,
  "_cardinalhq.collector_id"   TEXT    NOT NULL,

  "rollup_avg"   DOUBLE    NOT NULL,
  "rollup_count" DOUBLE    NOT NULL,
  "rollup_max"   DOUBLE    NOT NULL,
  "rollup_min"   DOUBLE    NOT NULL,
  "rollup_p25"   DOUBLE    NOT NULL,
  "rollup_p50"   DOUBLE    NOT NULL,
  "rollup_p75"   DOUBLE    NOT NULL,
        "rollup_p90"   DOUBLE    NOT NULL,
  "rollup_p95"   DOUBLE    NOT NULL,
  "rollup_p99"   DOUBLE    NOT NULL,
  "rollup_sum"   DOUBLE    NOT NULL,

  "sketch" BLOB    NOT NULL,
  "tags"   TEXT    NOT NULL
);
`
        if _, err := db.Exec(createTableSQL); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("creating table: %w", err)
        }</span>

        <span class="cov0" title="0">crateIndexSQL := `
CREATE INDEX IF NOT EXISTS idx_items_tid ON items("_cardinalhq.tid", "_cardinalhq.name", "_cardinalhq.timestamp");
`
        if _, err := db.Exec(crateIndexSQL); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("creating index: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

const insertSQL = `
INSERT INTO items (
  "_cardinalhq.metric_type",
  "_cardinalhq.tid",
  "_cardinalhq.telemetry_type",
  "_cardinalhq.customer_id",
  "_cardinalhq.name",
  "_cardinalhq.timestamp",
  "_cardinalhq.collector_id",
  "rollup_avg",
  "rollup_count",
  "rollup_max",
  "rollup_min",
  "rollup_p25",
  "rollup_p50",
  "rollup_p75",
        "rollup_p90",
  "rollup_p95",
  "rollup_p99",
  "rollup_sum",
  "sketch",
  "tags"
) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?);
`

func insertItem(db *sql.DB, item Item) error <span class="cov0" title="0">{
        tagsJSON, err := json.Marshal(item.Other)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal tags for insert: %w", err)
        }</span>

        <span class="cov0" title="0">_, err = db.Exec(insertSQL,
                item.Cardinal.MetricType,    // 1
                item.Cardinal.Tid,           // 2
                item.Cardinal.TelemetryType, // 3
                item.Cardinal.CustomerID,    // 4
                item.Cardinal.Name,          // 5
                item.Cardinal.Timestamp,     // 6
                item.Cardinal.CollectorID,   // 7
                item.Rollup.Avg,             // 8
                item.Rollup.Count,           // 9
                item.Rollup.Max,             //10
                item.Rollup.Min,             //11
                item.Rollup.P25,             //12
                item.Rollup.P50,             //13
                item.Rollup.P75,             //14
                item.Rollup.P90,             //15
                item.Rollup.P95,             //16
                item.Rollup.P99,             //17
                item.Rollup.Sum,             //18
                item.Sketch,                 //19
                string(tagsJSON),            //20
        )
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("inserting item: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func runSqlite(cmd *cobra.Command, args []string) error <span class="cov0" title="0">{
        parquetFilename, err := cmd.Flags().GetString("parquet")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get parquet flag: %w", err)
        }</span>

        <span class="cov0" title="0">sqliteFilename, err := cmd.Flags().GetString("sqlite")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get sqlite flag: %w", err)
        }</span>

        <span class="cov0" title="0">fh, err := filecrunch.LoadSchemaForFile(parquetFilename)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to load schema for file", slog.Any("error", err))
                return err
        }</span>
        <span class="cov0" title="0">slog.Info("Loaded schema for file", slog.String("file", parquetFilename))

        db, err := sql.Open("sqlite", ":memory:")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">if err := createTable(db); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("creating table: %w", err)
        }</span>

        <span class="cov0" title="0">reader := parquet.NewReader(fh.File, fh.Schema)
        defer reader.Close()

        for </span><span class="cov0" title="0">{
                rec := map[string]any{}
                if err := reader.Read(&amp;rec); err != nil </span><span class="cov0" title="0">{
                        if errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">return fmt.Errorf("reading parquet: %w", err)</span>
                }

                <span class="cov0" title="0">item, err := itemFromParquet(rec)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov0" title="0">if err := insertItem(db, item); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
        }

        <span class="cov0" title="0">rows, err := db.Query("SELECT * FROM items;")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("querying items: %w", err)
        }</span>
        <span class="cov0" title="0">defer rows.Close()

        for rows.Next() </span><span class="cov0" title="0">{
                var (
                        metricTypeIn    string
                        tidIn           int64
                        telemetryTypeIn string
                        customerIDIn    string
                        nameIn          string
                        timestampIn     int64
                        collectorIDIn   string
                        rollupAvgIn     float64
                        rollupCountIn   float64
                        rollupMaxIn     float64
                        rollupMinIn     float64
                        rollupP25In     float64
                        rollupP50In     float64
                        rollupP75In     float64
                        rollupP90In     float64
                        rollupP95In     float64
                        rollupP99In     float64
                        rollupSumIn     float64
                        sketchIn        []byte
                        tagsIn          string
                )

                if err := rows.Scan(
                        &amp;metricTypeIn,
                        &amp;tidIn,
                        &amp;telemetryTypeIn,
                        &amp;customerIDIn,
                        &amp;nameIn,
                        &amp;timestampIn,
                        &amp;collectorIDIn,
                        &amp;rollupAvgIn,
                        &amp;rollupCountIn,
                        &amp;rollupMaxIn,
                        &amp;rollupMinIn,
                        &amp;rollupP25In,
                        &amp;rollupP50In,
                        &amp;rollupP75In,
                        &amp;rollupP90In,
                        &amp;rollupP95In,
                        &amp;rollupP99In,
                        &amp;rollupSumIn,
                        &amp;sketchIn,
                        &amp;tagsIn,
                ); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("scanning row: %w", err)
                }</span>

                <span class="cov0" title="0">item := Item{
                        Cardinal: CardinalHQFields{
                                MetricType:    metricTypeIn,
                                Tid:           tidIn,
                                TelemetryType: telemetryTypeIn,
                                CustomerID:    customerIDIn,
                                Name:          nameIn,
                                Timestamp:     timestampIn,
                                CollectorID:   collectorIDIn,
                        },
                        Rollup: RollupFields{
                                Avg:   rollupAvgIn,
                                Count: rollupCountIn,
                                Max:   rollupMaxIn,
                                Min:   rollupMinIn,
                                P25:   rollupP25In,
                                P50:   rollupP50In,
                                P75:   rollupP75In,
                                P90:   rollupP90In,
                                P95:   rollupP95In,
                                P99:   rollupP99In,
                                Sum:   rollupSumIn,
                        },
                        Sketch: sketchIn,
                        Other:  make(map[string]string),
                }

                if err := json.Unmarshal([]byte(tagsIn), &amp;item.Other); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to unmarshal tags JSON: %w", err)
                }</span>
        }

        // copy the SQLite database to a file
        <span class="cov0" title="0">if sqliteFilename != "" </span><span class="cov0" title="0">{
                _, err := db.Exec("VACUUM INTO ?", sqliteFilename)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to vacuum into file %s: %w", sqliteFilename, err)
                }</span>
                <span class="cov0" title="0">slog.Info("SQLite database vacuumed into file", slog.String("filename", sqliteFilename))</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file13" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "log/slog"
        "os"
        "time"

        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/metric"

        "github.com/cardinalhq/lakerunner/internal/helpers"
)

var (
        spaceMeter = otel.Meter("github.com/cardinalhq/lakerunner/scratchspace")

        totalBytes metric.Int64Gauge
        freeBytes  metric.Int64Gauge
        usedBytes  metric.Int64Gauge

        failcount    = 0
        hasSucceeded = false
)

func diskUsageLoop(ctx context.Context) <span class="cov0" title="0">{
        m, err := spaceMeter.Int64Gauge("scratchspace.total_bytes",
                metric.WithDescription("Total bytes total in the scratch space"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to create available bytes gauge", slog.Any("error", err))
                return
        }</span>
        <span class="cov0" title="0">totalBytes = m

        m, err = spaceMeter.Int64Gauge("scratchspace.free_bytes",
                metric.WithDescription("Free bytes in the scratch space"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to create free bytes gauge", slog.Any("error", err))
                return
        }</span>
        <span class="cov0" title="0">freeBytes = m

        m, err = spaceMeter.Int64Gauge("scratchspace.used_bytes",
                metric.WithDescription("Used bytes in the scratch space"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to create used bytes gauge", slog.Any("error", err))
                return
        }</span>
        <span class="cov0" title="0">usedBytes = m

        diskUsage()
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-time.Tick(5 * time.Minute):<span class="cov0" title="0">
                        diskUsage()</span>
                }
        }
}

func diskUsage() <span class="cov0" title="0">{
        if !hasSucceeded &amp;&amp; failcount &gt; 10 </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">diskstats, err := helpers.DiskUsage(os.TempDir())
        if err != nil </span><span class="cov0" title="0">{
                failcount++
                if failcount &gt; 10 &amp;&amp; !hasSucceeded </span><span class="cov0" title="0">{
                        slog.Error("Failed to get disk usage stats multiple times, stopping further attempts", slog.Int("failcount", failcount))
                        return
                }</span>
                <span class="cov0" title="0">slog.Error("Failed to get disk usage stats", "error", err, "failcount", failcount)
                return</span>
        }
        <span class="cov0" title="0">hasSucceeded = true

        slog.Info("Disk usage stats",
                "totalBytes", diskstats.TotalBytes,
                "freeBytes", diskstats.FreeBytes,
                "usedBytes", diskstats.UsedBytes,
                "freePercent", float64(diskstats.FreeBytes)/float64(diskstats.TotalBytes)*100,
                "totalInodes", diskstats.TotalInodes,
                "freeInodes", diskstats.FreeInodes,
                "usedInodes", diskstats.UsedInodes,
                "freeInodesPercent", float64(diskstats.FreeInodes)/float64(diskstats.TotalInodes)*100,
        )

        totalBytes.Record(context.Background(), int64(diskstats.TotalBytes))
        freeBytes.Record(context.Background(), int64(diskstats.FreeBytes))
        usedBytes.Record(context.Background(), int64(diskstats.UsedBytes))</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
        "os"
        "strings"
        "time"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/metric"

        "github.com/cardinalhq/lakerunner/cmd/ingestlogs"
        "github.com/cardinalhq/lakerunner/fileconv/jsongz"
        protoconv "github.com/cardinalhq/lakerunner/fileconv/proto"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/buffet"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/logcrunch"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lrdb"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "ingest-logs",
                Short: "Ingest logs from the inqueue table",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        helpers.CleanTempDir()

                        servicename := "lakerunner-ingest-logs"
                        addlAttrs := attribute.NewSet(
                                attribute.String("signal", "logs"),
                                attribute.String("action", "ingest"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">go diskUsageLoop(doneCtx)

                        loop, err := NewIngestLoopContext(doneCtx, "logs", servicename)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create ingest loop context: %w", err)
                        }</span>

                        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                                select </span>{
                                case &lt;-doneCtx.Done():<span class="cov0" title="0">
                                        slog.Info("Ingest logs command done")
                                        return nil</span>
                                default:<span class="cov0" title="0"></span>
                                }

                                <span class="cov0" title="0">err := IngestLoop(loop, logIngestItem)
                                if err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error in ingest loop", slog.Any("error", err))
                                }</span>
                        }
                },
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}

func logIngestItem(ctx context.Context, ll *slog.Logger, tmpdir string, sp storageprofile.StorageProfileProvider, mdb lrdb.StoreFull,
        awsmanager *awsclient.Manager, inf lrdb.Inqueue, ingest_dateint int32, rpfEstimate int64) error <span class="cov0" title="0">{
        profile, err := sp.Get(ctx, inf.OrganizationID, inf.InstanceNum)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get storage profile", slog.Any("error", err))
                return err
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Error("No role on non-hosted profile")
                        return err
                }</span>
        }
        <span class="cov0" title="0">if profile.Bucket != inf.Bucket </span><span class="cov0" title="0">{
                ll.Error("Bucket ID mismatch", slog.String("expected", profile.Bucket), slog.String("actual", inf.Bucket))
                return errors.New("bucket ID mismatch")
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Info("No role on non-hosted profile")
                        return err
                }</span>
        }

        <span class="cov0" title="0">s3client, err := awsmanager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get S3 client", slog.Any("error", err))
                return err
        }</span>

        <span class="cov0" title="0">tmpfilename, _, is404, err := s3helper.DownloadS3Object(ctx, tmpdir, s3client, inf.Bucket, inf.ObjectID)
        if err != nil </span><span class="cov0" title="0">{
                // TODO add counter for download errors
                ll.Error("Failed to download S3 object", slog.Any("error", err))
                return err
        }</span>
        <span class="cov0" title="0">if is404 </span><span class="cov0" title="0">{
                // TODO add counter for missing files
                ll.Info("S3 object not found, deleting inqueue work item", slog.String("bucket", inf.Bucket), slog.String("objectID", inf.ObjectID))
                return nil
        }</span>

        <span class="cov0" title="0">ll.Info("Downloaded source file")

        filenames := []string{tmpfilename}

        // If the file is not in our `otel-raw` prefix, check if we can convert it
        if !strings.HasPrefix(inf.ObjectID, "otel-raw/") </span><span class="cov0" title="0">{
                // Skip database files (these are processed outputs, not inputs)
                if strings.HasPrefix(inf.ObjectID, "db/") </span><span class="cov0" title="0">{
                        // TODO add counter for skipped files in the db prefix
                        return nil
                }</span>

                // Check file type and convert if supported
                <span class="cov0" title="0">if fnames, err := convertFileIfSupported(ll, tmpfilename, tmpdir, inf.Bucket, inf.ObjectID, rpfEstimate); err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to convert file", slog.Any("error", err))
                        // TODO add counter for failure to convert, probably in each convert function
                        return err
                }</span> else<span class="cov0" title="0"> if len(fnames) == 0 </span><span class="cov0" title="0">{
                        ll.Info("Empty source file, skipping", slog.String("objectID", inf.ObjectID))
                        return nil
                }</span> else<span class="cov0" title="0"> if fnames != nil </span><span class="cov0" title="0">{
                        filenames = fnames
                        ll.Info("Converted file", slog.String("filename", tmpfilename), slog.String("objectID", inf.ObjectID))
                }</span>
        }

        <span class="cov0" title="0">for _, fname := range filenames </span><span class="cov0" title="0">{
                fh, err := filecrunch.LoadSchemaForFile(fname)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to load schema for file", slog.Any("error", err))
                        return err
                }</span>
                <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                        _ = fh.Close()
                }</span>()
                <span class="cov0" title="0">splitResults, err := logcrunch.ProcessAndSplit(ll, fh, tmpdir, ingest_dateint, rpfEstimate)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to fingerprint file", slog.Any("error", err))
                        return err
                }</span>

                <span class="cov0" title="0">for key, split := range splitResults </span><span class="cov0" title="0">{
                        segmentID := s3helper.GenerateID()
                        dbObjectID := helpers.MakeDBObjectID(inf.OrganizationID, inf.CollectorName, key.DateInt, s3helper.HourFromMillis(split.FirstTS), segmentID, "logs")

                        if err := s3helper.UploadS3Object(ctx, s3client, inf.Bucket, dbObjectID, split.FileName); err != nil </span><span class="cov0" title="0">{
                                ll.Error("Failed to upload S3 object", slog.Any("error", err))
                                return err
                        }</span>
                        <span class="cov0" title="0">ll.Info("Uploaded log segment",
                                slog.String("bucket", inf.Bucket),
                                slog.String("objectID", dbObjectID),
                                slog.Int64("segmentID", segmentID),
                                slog.Any("key", key),
                                slog.Int64("firstTS", split.FirstTS),
                                slog.Int64("lastTS", split.LastTS),
                                slog.Int64("recordCount", split.RecordCount),
                                slog.Int64("fileSize", split.FileSize))
                        _ = os.Remove(split.FileName)

                        fps := split.Fingerprints.ToSlice()
                        t0 := time.Now()
                        split.LastTS++ // end is exclusive, so we need to increment it by 1ms
                        err = mdb.InsertLogSegment(ctx, lrdb.InsertLogSegmentParams{
                                OrganizationID: inf.OrganizationID,
                                Dateint:        key.DateInt,
                                IngestDateint:  ingest_dateint,
                                SegmentID:      segmentID,
                                InstanceNum:    inf.InstanceNum,
                                StartTs:        split.FirstTS,
                                EndTs:          split.LastTS,
                                RecordCount:    split.RecordCount,
                                FileSize:       split.FileSize,
                                CreatedBy:      lrdb.CreatedByIngest,
                                Fingerprints:   fps,
                        })
                        dbExecDuration.Record(ctx, time.Since(t0).Seconds(),
                                metric.WithAttributeSet(commonAttributes),
                                metric.WithAttributes(
                                        attribute.Bool("hasError", err != nil),
                                        attribute.String("queryName", "InsertLogSegment"),
                                ))
                        if err != nil </span><span class="cov0" title="0">{
                                ll.Error("Failed to insert log segments", slog.Any("error", err))
                                return err
                        }</span>

                        <span class="cov0" title="0">ll.Info("Inserted log segment",
                                slog.Int64("segmentID", segmentID),
                                slog.Any("key", key),
                                slog.Int("fingerprintCount", split.Fingerprints.Cardinality()),
                                slog.Int64("recordCount", split.RecordCount),
                                slog.Int64("fileSize", split.FileSize))

                        // TODO this can be done just once per dateint.
                        if err := queueLogCompaction(ctx, mdb, qmcFromInqueue(inf, -1, split.FirstTS)); err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                }
        }

        <span class="cov0" title="0">return nil</span>
}

// convertFileIfSupported checks the file type and converts it if supported.
// Returns nil if the file type is not supported (file will be skipped).
func convertFileIfSupported(ll *slog.Logger, tmpfilename, tmpdir, bucket, objectID string, rpfEstimate int64) ([]string, error) <span class="cov0" title="0">{
        // TODO add a counter for each type we process, and a counter for unsupported types
        // Include the signal type in the attributes, as well as the converter used, and the extension found.
        switch </span>{
        case strings.HasSuffix(objectID, ".parquet"):<span class="cov0" title="0">
                return ingestlogs.ConvertRawParquet(tmpfilename, tmpdir, bucket, objectID, rpfEstimate)</span>
        case strings.HasSuffix(objectID, ".json.gz"):<span class="cov0" title="0">
                return convertJSONGzFile(tmpfilename, tmpdir, bucket, objectID, rpfEstimate)</span>
        case strings.HasSuffix(objectID, ".binpb"):<span class="cov0" title="0">
                return convertProtoFile(tmpfilename, tmpdir, bucket, objectID, rpfEstimate)</span>
        default:<span class="cov0" title="0">
                ll.Warn("Unsupported file type, skipping", slog.String("objectID", objectID))
                return nil, nil</span>
        }
}

// convertJSONGzFile converts a JSON.gz file to the standardized format
func convertJSONGzFile(tmpfilename, tmpdir, bucket, objectID string, rpfEstimate int64) ([]string, error) <span class="cov0" title="0">{
        // Create a mapper that recognizes "date" as a timestamp field
        mapper := translate.NewMapper(
                translate.WithTimestampColumn("date"),
                translate.WithTimeFormat(time.RFC3339Nano),
        )

        r, err := jsongz.NewJSONGzReader(tmpfilename, mapper, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer r.Close()

        nmb := buffet.NewNodeMapBuilder()

        baseitems := map[string]string{
                "resource.bucket.name": bucket,
                "resource.file.name":   "./" + objectID,
                "resource.file.type":   ingestlogs.GetFileType(objectID),
        }

        // First pass: read all rows to build complete schema
        allRows := make([]map[string]any, 0)
        for </span><span class="cov0" title="0">{
                row, done, err := r.GetRow()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">if done </span><span class="cov0" title="0">{
                        break</span>
                }

                // Add base items to the row
                <span class="cov0" title="0">for k, v := range baseitems </span><span class="cov0" title="0">{
                        row[k] = v
                }</span>

                // Add row to schema builder
                <span class="cov0" title="0">if err := nmb.Add(row); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to add row to schema: %w", err)
                }</span>

                <span class="cov0" title="0">allRows = append(allRows, row)</span>
        }

        <span class="cov0" title="0">if len(allRows) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no rows processed")
        }</span>

        // Create writer with complete schema
        <span class="cov0" title="0">w, err := buffet.NewWriter("fileconv", tmpdir, nmb.Build(), rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">var closed bool
        defer func() </span><span class="cov0" title="0">{
                if !closed </span><span class="cov0" title="0">{
                        _, err := w.Close()
                        if err != buffet.ErrAlreadyClosed &amp;&amp; err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to close writer", slog.Any("error", err))
                        }</span>
                }
        }()

        // Second pass: write all rows
        <span class="cov0" title="0">for _, row := range allRows </span><span class="cov0" title="0">{
                if err := w.Write(row); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to write row: %w", err)
                }</span>
        }

        <span class="cov0" title="0">result, err := w.Close()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to close writer: %w", err)
        }</span>
        <span class="cov0" title="0">closed = true
        if len(result) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no records written to file")
        }</span>

        <span class="cov0" title="0">var fnames []string
        for _, res := range result </span><span class="cov0" title="0">{
                fnames = append(fnames, res.FileName)
        }</span>
        <span class="cov0" title="0">return fnames, nil</span>
}

// convertProtoFile converts a protobuf file to the standardized format
func convertProtoFile(tmpfilename, tmpdir, bucket, objectID string, rpfEstimate int64) ([]string, error) <span class="cov0" title="0">{
        // Create a mapper for protobuf files
        mapper := translate.NewMapper()

        r, err := protoconv.NewProtoReader(tmpfilename, mapper, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer r.Close()

        nmb := buffet.NewNodeMapBuilder()

        baseitems := map[string]string{
                "resource.bucket.name": bucket,
                "resource.file.name":   "./" + objectID,
                "resource.file.type":   ingestlogs.GetFileType(objectID),
        }

        // First pass: read all rows to build complete schema
        allRows := make([]map[string]any, 0)
        for </span><span class="cov0" title="0">{
                row, done, err := r.GetRow()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">if done </span><span class="cov0" title="0">{
                        break</span>
                }

                // Add base items to the row
                <span class="cov0" title="0">for k, v := range baseitems </span><span class="cov0" title="0">{
                        row[k] = v
                }</span>

                // Add row to schema builder
                <span class="cov0" title="0">if err := nmb.Add(row); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to add row to schema: %w", err)
                }</span>

                <span class="cov0" title="0">allRows = append(allRows, row)</span>
        }

        <span class="cov0" title="0">if len(allRows) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no rows processed")
        }</span>

        // Create writer with complete schema
        <span class="cov0" title="0">w, err := buffet.NewWriter("fileconv", tmpdir, nmb.Build(), rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                _, err := w.Close()
                if err != buffet.ErrAlreadyClosed &amp;&amp; err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to close writer", slog.Any("error", err))
                }</span>
        }()

        // Second pass: write all rows
        <span class="cov0" title="0">for _, row := range allRows </span><span class="cov0" title="0">{
                if err := w.Write(row); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to write row: %w", err)
                }</span>
        }

        <span class="cov0" title="0">result, err := w.Close()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to close writer: %w", err)
        }</span>
        <span class="cov0" title="0">if len(result) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no records written to file")
        }</span>

        <span class="cov0" title="0">var fnames []string
        for _, res := range result </span><span class="cov0" title="0">{
                fnames = append(fnames, res.FileName)
        }</span>
        <span class="cov0" title="0">return fnames, nil</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "errors"
        "fmt"
        "io"
        "log/slog"
        "maps"
        "slices"
        "strings"
        "time"

        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/parquet-go/parquet-go"
        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/metric"

        "github.com/cardinalhq/lakerunner/cmd/ingestlogs"
        "github.com/cardinalhq/lakerunner/fileconv/proto"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/buffet"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lrdb"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "ingest-metrics",
                Short: "Ingest metrics from the inqueue table",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        helpers.CleanTempDir()

                        servicename := "lakerunner-ingest-metrics"
                        addlAttrs := attribute.NewSet(
                                attribute.String("signal", "metrics"),
                                attribute.String("action", "ingest"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">go diskUsageLoop(doneCtx)

                        loop, err := NewIngestLoopContext(doneCtx, "metrics", servicename)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create ingest loop context: %w", err)
                        }</span>

                        <span class="cov0" title="0">return IngestLoop(loop, metricIngestItem)</span>
                },
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}

func metricIngestItem(ctx context.Context, ll *slog.Logger, tmpdir string, sp storageprofile.StorageProfileProvider, mdb lrdb.StoreFull,
        awsmanager *awsclient.Manager, inf lrdb.Inqueue, ingest_dateint int32, rpfEstimate int64) error <span class="cov0" title="0">{
        profile, err := sp.Get(ctx, inf.OrganizationID, inf.InstanceNum)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get storage profile", slog.Any("error", err))
                return err
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Error("No role on non-hosted profile")
                        return err
                }</span>
        }
        <span class="cov0" title="0">if profile.Bucket != inf.Bucket </span><span class="cov0" title="0">{
                ll.Error("Bucket ID mismatch", slog.String("expected", profile.Bucket), slog.String("actual", inf.Bucket))
                return errors.New("bucket ID mismatch")
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Info("No role on non-hosted profile")
                        return err
                }</span>
        }

        <span class="cov0" title="0">s3client, err := awsmanager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get S3 client", slog.Any("error", err))
                return err
        }</span>

        <span class="cov0" title="0">tmpfilename, _, is404, err := s3helper.DownloadS3Object(ctx, tmpdir, s3client, inf.Bucket, inf.ObjectID)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to download S3 object", slog.Any("error", err))
                return err
        }</span>
        <span class="cov0" title="0">if is404 </span><span class="cov0" title="0">{
                ll.Info("S3 object not found, skipping", slog.String("bucket", inf.Bucket), slog.String("objectID", inf.ObjectID))
                return nil
        }</span>

        <span class="cov0" title="0">filenames := []string{tmpfilename}

        // If the file is not in our `otel-raw` prefix, check if we can convert it
        if !strings.HasPrefix(inf.ObjectID, "otel-raw/") </span><span class="cov0" title="0">{
                // Skip database files (these are processed outputs, not inputs)
                if strings.HasPrefix(inf.ObjectID, "db/") </span><span class="cov0" title="0">{
                        return nil
                }</span>

                // Check file type and convert if supported
                <span class="cov0" title="0">if fnames, err := convertMetricsFileIfSupported(ll, tmpfilename, tmpdir, inf.Bucket, inf.ObjectID, rpfEstimate); err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to convert file", slog.Any("error", err))
                        return err
                }</span> else<span class="cov0" title="0"> if fnames != nil </span><span class="cov0" title="0">{
                        filenames = fnames
                        ll.Info("Converted file", slog.String("filename", tmpfilename), slog.String("objectID", inf.ObjectID))
                }</span>
        }

        <span class="cov0" title="0">for _, fname := range filenames </span><span class="cov0" title="0">{
                fh, err := filecrunch.LoadSchemaForFile(fname)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to load schema for file", slog.Any("error", err))
                        return err
                }</span>
                <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                        _ = fh.Close()
                }</span>()

                <span class="cov0" title="0">if err := crunchMetricFile(ctx, ll, tmpdir, fh, inf, s3client, mdb, ingest_dateint, rpfEstimate); err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to crunch metric file", slog.Any("error", err), slog.String("file", fname))
                        return err
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

type TimeBlock struct {
        Block       int64
        FrequencyMS int32
        Sketches    *map[int64]TagSketch
        nodebuilder *buffet.NodeMapBuilder
}

type TagSketch struct {
        MetricName string
        MetricType string
        Tags       map[string]any
        Sketch     *ddsketch.DDSketch
}

// crunchMetricFile processes the metric file and generates sketches or other
func crunchMetricFile(ctx context.Context, ll *slog.Logger, tmpdir string, fh *filecrunch.FileHandle, inf lrdb.Inqueue, s3client *awsclient.S3Client, mdb lrdb.StoreFull, ingest_dateint int32, rpfEstimate int64) error <span class="cov0" title="0">{
        reader := parquet.NewReader(fh.File, fh.Schema)
        defer reader.Close()

        blocks := map[int64]*TimeBlock{}

        for </span><span class="cov0" title="0">{
                rec := map[string]any{}
                if err := reader.Read(&amp;rec); err != nil </span><span class="cov0" title="0">{
                        if errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">return fmt.Errorf("reading parquet: %w", err)</span>
                }
                <span class="cov0" title="0">delete(rec, "_cardinalhq.id")

                ts, ok := helpers.GetInt64Value(rec, "_cardinalhq.timestamp")
                if !ok </span><span class="cov0" title="0">{
                        ll.Warn("Skipping record without timestamp", slog.Any("record", rec))
                        continue</span>
                }
                <span class="cov0" title="0">delete(rec, "_cardinalhq.timestamp")

                metricType, ok := helpers.GetStringValue(rec, "_cardinalhq.metric_type")
                if !ok </span><span class="cov0" title="0">{
                        ll.Warn("Skipping record without metric type", slog.Any("record", rec))
                        continue</span>
                }
                <span class="cov0" title="0">if metricType == "count" || metricType == "gauge" </span><span class="cov0" title="0">{
                        delete(rec, "_cardinalhq.bucket_bounds")
                        delete(rec, "_cardinalhq.counts")
                        delete(rec, "_cardinalhq.negative_counts")
                        delete(rec, "_cardinalhq.positive_counts")
                }</span> else<span class="cov0" title="0"> {
                        delete(rec, "_cardinalhq.value")
                }</span>

                <span class="cov0" title="0">metricName, ok := helpers.GetStringValue(rec, "_cardinalhq.name")
                if !ok </span><span class="cov0" title="0">{
                        ll.Warn("Skipping record without metric name", slog.Any("record", rec))
                        continue</span>
                }

                <span class="cov0" title="0">const frequencyMS = 10000 // 10 seconds

                blocknum := ts / frequencyMS
                rec["_cardinalhq.timestamp"] = blocknum * frequencyMS

                block, exists := blocks[blocknum]
                if !exists </span><span class="cov0" title="0">{
                        block = &amp;TimeBlock{
                                Block:       blocknum,
                                FrequencyMS: frequencyMS,
                                Sketches:    &amp;map[int64]TagSketch{},
                                nodebuilder: buffet.NewNodeMapBuilder(),
                        }
                        blocks[blocknum] = block
                }</span>

                <span class="cov0" title="0">tags := helpers.MakeTags(rec)
                if err := block.nodebuilder.Add(tags); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("adding tags to node builder: %w", err)
                }</span>

                <span class="cov0" title="0">tid := helpers.ComputeTID(metricName, tags)
                tags["_cardinalhq.tid"] = fmt.Sprintf("%d", tid)

                sketch, exists := (*block.Sketches)[tid]
                if !exists </span><span class="cov0" title="0">{
                        sketch = TagSketch{
                                MetricName: metricName,
                                MetricType: metricType,
                                Tags:       tags,
                                Sketch:     nil,
                        }
                        s, err := ddsketch.NewDefaultDDSketch(0.01)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("creating sketch: %w", err)
                        }</span>
                        <span class="cov0" title="0">sketch.Sketch = s
                        (*block.Sketches)[tid] = sketch</span>
                } else<span class="cov0" title="0"> {
                        if sketch.MetricName != metricName </span><span class="cov0" title="0">{
                                return fmt.Errorf("metric name mismatch for TID %d: existing %s, new %s", tid, sketch.MetricName, metricName)
                        }</span>
                        <span class="cov0" title="0">if sketch.MetricType != metricType </span><span class="cov0" title="0">{
                                return fmt.Errorf("metric type mismatch for TID %d: existing %s, new %s", tid, sketch.MetricType, metricType)
                        }</span>
                        <span class="cov0" title="0">diff := helpers.MatchTags(sketch.Tags, tags)
                        if len(diff) &gt; 0 </span><span class="cov0" title="0">{
                                return fmt.Errorf("tag mismatch for TID %d: diff %v", tid, diff)
                        }</span>
                }

                <span class="cov0" title="0">switch metricType </span>{
                case "count", "gauge":<span class="cov0" title="0">
                        value, ok := helpers.GetFloat64Value(rec, "_cardinalhq.value")
                        if !ok </span><span class="cov0" title="0">{
                                ll.Warn("Skipping record without value", slog.Any("record", rec))
                                continue</span>
                        }
                        <span class="cov0" title="0">rec["_cardinalhq.value"] = -1
                        if err := sketch.Sketch.Add(value); err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("adding value to sketch: %w", err)
                        }</span>
                case "histogram":<span class="cov0" title="0">
                        bucketCounts, ok := helpers.GetFloat64SliceJSON(rec, "_cardinalhq.counts")
                        if !ok </span><span class="cov0" title="0">{
                                ll.Warn("Skipping histogram record without counts", slog.Any("record", rec))
                                continue</span>
                        }
                        <span class="cov0" title="0">delete(rec, "_cardinalhq.counts")
                        bucketBounds, ok := helpers.GetFloat64SliceJSON(rec, "_cardinalhq.bucket_bounds")
                        if !ok </span><span class="cov0" title="0">{
                                ll.Warn("Skipping histogram record without bucket bounds", slog.Any("record", rec))
                                continue</span>
                        }
                        <span class="cov0" title="0">delete(rec, "_cardinalhq.bucket_bounds")
                        counts, values := handleHistogram(bucketCounts, bucketBounds)
                        if len(counts) == 0 </span><span class="cov0" title="0">{
                                // if err := sketch.Sketch.Add(0); err != nil {
                                //         return fmt.Errorf("adding zero to sketch: %w", err)
                                // }
                                continue</span>
                        }
                        <span class="cov0" title="0">for i, count := range counts </span><span class="cov0" title="0">{
                                if err := sketch.Sketch.AddWithCount(values[i], count); err != nil </span><span class="cov0" title="0">{
                                        return fmt.Errorf("adding histogram value to sketch: %w", err)
                                }</span>
                        }

                default:<span class="cov0" title="0">
                        ll.Info("Skipping unsupported metric type", slog.String("metricType", metricType))
                        continue</span>
                }
        }

        <span class="cov0" title="0">ll.Info("Finished processing metric file", slog.String("file", fh.File.Name()), slog.Int("blocks", len(blocks)))

        // print out all blocks, and the metric names and sketch value
        for blocknum, block := range blocks </span><span class="cov0" title="0">{
                if len(*block.Sketches) == 0 </span><span class="cov0" title="0">{
                        ll.Info("Skipping empty block", slog.Int64("blocknum", blocknum))
                        continue</span>
                }

                <span class="cov0" title="0">ll.Info("Processing block",
                        slog.Int64("blocknum", blocknum),
                        slog.Int("nSketches", len(*block.Sketches)),
                        slog.Int64("frequencyMS", int64(block.FrequencyMS)),
                        slog.Int64("startTS", block.Block*int64(block.FrequencyMS)),
                        slog.Int64("endTS", (block.Block+1)*int64(block.FrequencyMS)-1),
                )

                err := writeMetricSketchParquet(ctx, tmpdir, blocknum, block, inf, s3client, ll, mdb, ingest_dateint, rpfEstimate)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("writing metric sketch parquet: %w", err)
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

func writeMetricSketchParquet(ctx context.Context, tmpdir string, blocknum int64, block *TimeBlock, inf lrdb.Inqueue, s3client *awsclient.S3Client, ll *slog.Logger, mdb lrdb.StoreFull, ingest_dateint int32, rpfEstimate int64) error <span class="cov0" title="0">{
        addedNodes := map[string]any{
                "_cardinalhq.timestamp":      int64(1),
                "_cardinalhq.name":           "x",
                "_cardinalhq.customer_id":    "x",
                "_cardinalhq.collector_id":   "x",
                "_cardinalhq.metric_type":    "x",
                "_cardinalhq.tid":            int64(1),
                "_cardinalhq.value":          float64(1),
                "_cardinalhq.telemetry_type": "metrics",
                "sketch":                     []byte{},
                "rollup_avg":                 float64(1),
                "rollup_max":                 float64(1),
                "rollup_min":                 float64(1),
                "rollup_count":               float64(1),
                "rollup_sum":                 float64(1),
                "rollup_p25":                 float64(1),
                "rollup_p50":                 float64(1),
                "rollup_p75":                 float64(1),
                "rollup_p90":                 float64(1),
                "rollup_p95":                 float64(1),
                "rollup_p99":                 float64(1),
        }
        if err := block.nodebuilder.Add(addedNodes); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("adding nodes to node builder: %w", err)
        }</span>
        <span class="cov0" title="0">nodes := block.nodebuilder.Build()
        pw, err := buffet.NewWriter("metrics", tmpdir, nodes, rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("creating buffet writer: %w", err)
        }</span>

        <span class="cov0" title="0">startTS := block.Block * int64(block.FrequencyMS)
        endTS := startTS + int64(block.FrequencyMS)

        sortedTIDs := make([]int64, 0, len(*block.Sketches))
        for tid := range *block.Sketches </span><span class="cov0" title="0">{
                sortedTIDs = append(sortedTIDs, tid)
        }</span>
        <span class="cov0" title="0">slices.Sort(sortedTIDs)

        for _, tid := range sortedTIDs </span><span class="cov0" title="0">{
                sketch := (*block.Sketches)[tid]
                if sketch.Sketch == nil || sketch.Sketch.GetCount() == 0 </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">maxvalue, err := sketch.Sketch.GetMaxValue()
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("getting max value from sketch: %w", err)
                }</span>

                <span class="cov0" title="0">minvalue, err := sketch.Sketch.GetMinValue()
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("getting min value from sketch: %w", err)
                }</span>

                <span class="cov0" title="0">quantiles, err := sketch.Sketch.GetValuesAtQuantiles([]float64{0.25, 0.5, 0.75, 0.90, 0.95, 0.99})
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("getting quantiles from sketch: %w", err)
                }</span>

                <span class="cov0" title="0">count := sketch.Sketch.GetCount()
                sum := sketch.Sketch.GetSum()
                avg := sum / count

                addToRec := map[string]any{
                        "_cardinalhq.timestamp":      startTS,
                        "_cardinalhq.name":           sketch.MetricName,
                        "_cardinalhq.customer_id":    inf.OrganizationID.String(),
                        "_cardinalhq.collector_id":   inf.CollectorName,
                        "_cardinalhq.metric_type":    sketch.MetricType,
                        "_cardinalhq.tid":            tid,
                        "_cardinalhq.value":          float64(-1),
                        "_cardinalhq.telemetry_type": "metrics",
                        "sketch":                     EncodeSketch(sketch.Sketch),
                        "rollup_avg":                 avg,
                        "rollup_max":                 maxvalue,
                        "rollup_min":                 minvalue,
                        "rollup_count":               count,
                        "rollup_sum":                 sum,
                        "rollup_p25":                 quantiles[0],
                        "rollup_p50":                 quantiles[1],
                        "rollup_p75":                 quantiles[2],
                        "rollup_p90":                 quantiles[3],
                        "rollup_p95":                 quantiles[4],
                        "rollup_p99":                 quantiles[5],
                }
                rec := map[string]any{}
                maps.Copy(rec, sketch.Tags)
                maps.Copy(rec, addToRec)

                if err := pw.Write(rec); err != nil </span><span class="cov0" title="0">{
                        _, _ = pw.Close()
                        return fmt.Errorf("writing record to parquet: %w", err)
                }</span>
        }

        <span class="cov0" title="0">stats, err := pw.Close()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("closing parquet writer: %w", err)
        }</span>
        <span class="cov0" title="0">if stats == nil </span><span class="cov0" title="0">{
                ll.Info("No records written for block", slog.Int64("blocknum", blocknum))
                return nil
        }</span>

        <span class="cov0" title="0">dateint, hour := helpers.MSToDateintHour(startTS)

        for _, stat := range stats </span><span class="cov0" title="0">{
                ll.Info("Wrote metric sketch parquet",
                        slog.String("organizationID", inf.OrganizationID.String()),
                        slog.String("collectorName", inf.CollectorName),
                        slog.Int64("blocknum", blocknum),
                        slog.String("file", stat.FileName),
                        slog.Int64("recordcount", stat.RecordCount),
                        slog.Int64("filesize", stat.FileSize),
                )

                // Upload the file to S3
                segmentID := s3helper.GenerateID()
                objID := helpers.MakeDBObjectID(inf.OrganizationID, inf.CollectorName, dateint, hour, segmentID, "metrics")
                if err := s3helper.UploadS3Object(ctx, s3client, inf.Bucket, objID, stat.FileName); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("uploading file to S3: %w", err)
                }</span>

                <span class="cov0" title="0">t0 := time.Now()
                err = mdb.InsertMetricSegment(ctx, lrdb.InsertMetricSegmentParams{
                        OrganizationID: inf.OrganizationID,
                        FrequencyMs:    block.FrequencyMS,
                        Dateint:        dateint,
                        IngestDateint:  ingest_dateint,
                        TidPartition:   0,
                        SegmentID:      segmentID,
                        InstanceNum:    inf.InstanceNum,
                        StartTs:        startTS,
                        EndTs:          endTS,
                        RecordCount:    stat.RecordCount,
                        FileSize:       stat.FileSize,
                        Published:      true,
                        CreatedBy:      lrdb.CreatedByIngest,
                })
                dbExecDuration.Record(ctx, time.Since(t0).Seconds(),
                        metric.WithAttributeSet(commonAttributes),
                        metric.WithAttributes(
                                attribute.Bool("hasError", err != nil),
                                attribute.String("queryName", "InsertMetricSegment"),
                        ))
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to insert metric segment", slog.Any("error", err))
                        // Clean up the uploaded file if insertion fails
                        if err2 := s3helper.DeleteS3Object(ctx, s3client, inf.Bucket, objID); err2 != nil </span><span class="cov0" title="0">{
                                ll.Error("Failed to delete S3 object after insertion failure", slog.Any("error", err2), slog.String("objectID", objID))
                                return fmt.Errorf("failed to delete S3 object after insertion failure: %w", err2)
                        }</span>
                        <span class="cov0" title="0">ll.Info("Deleted S3 object after insertion failure", slog.String("objectID", objID))
                        return fmt.Errorf("inserting metric segment: %w", err)</span>
                }

                <span class="cov0" title="0">ll.Info("Inserted metric segment and uploaded to S3",
                        slog.String("organizationID", inf.OrganizationID.String()),
                        slog.String("collectorName", inf.CollectorName),
                        slog.Int64("blocknum", blocknum),
                        slog.String("objectID", objID),
                        slog.Int64("segmentID", segmentID),
                        slog.Int64("recordCount", stat.RecordCount),
                        slog.Int64("fileSize", stat.FileSize),
                        slog.String("bucket", inf.Bucket),
                        slog.Int64("startTs", startTS),
                        slog.Int64("endTs", endTS),
                )</span>
        }

        <span class="cov0" title="0">if err := queueMetricCompaction(ctx, mdb, qmcFromInqueue(inf, block.FrequencyMS, startTS)); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("queueing metric compaction: %w", err)
        }</span>
        <span class="cov0" title="0">if err := queueMetricRollup(ctx, mdb, qmcFromInqueue(inf, block.FrequencyMS, startTS)); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("queueing metric rollup: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// handleHistogram fills the sketch with representative values for each bucket count.
// If bucketCounts[i] &gt; 0, it inserts the midpoint of the bucket that bucketCounts[i] represents.
func handleHistogram(bucketCounts []float64, bucketBounds []float64) (counts, values []float64) <span class="cov8" title="1">{
        const maxTrackableValue = 1e9

        counts = []float64{}
        values = []float64{}

        if len(bucketCounts) == 0 || len(bucketBounds) == 0 </span><span class="cov8" title="1">{
                return counts, values
        }</span>
        <span class="cov8" title="1">if len(bucketCounts) &gt; len(bucketBounds)+1 </span><span class="cov0" title="0">{
                return counts, values
        }</span>

        <span class="cov8" title="1">for i, count := range bucketCounts </span><span class="cov8" title="1">{
                if count &lt;= 0 </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">var value float64
                if i &lt; len(bucketBounds) </span><span class="cov8" title="1">{
                        var lowerBound float64
                        if i == 0 </span><span class="cov8" title="1">{
                                lowerBound = 1e-10 // very small lower bound
                        }</span> else<span class="cov8" title="1"> {
                                lowerBound = bucketBounds[i-1]
                        }</span>
                        <span class="cov8" title="1">upperBound := bucketBounds[i]
                        value = (lowerBound + upperBound) / 2.0</span>
                } else<span class="cov8" title="1"> {
                        value = min(bucketBounds[len(bucketBounds)-1]+1, maxTrackableValue)
                }</span>

                <span class="cov8" title="1">if value &lt;= maxTrackableValue </span><span class="cov8" title="1">{
                        counts = append(counts, count)
                        values = append(values, value)
                }</span>
        }
        <span class="cov8" title="1">return counts, values</span>
}

// convertMetricsFileIfSupported checks the file type and converts it if supported.
// Returns nil if the file type is not supported (file will be skipped).
func convertMetricsFileIfSupported(ll *slog.Logger, tmpfilename, tmpdir, bucket, objectID string, rpfEstimate int64) ([]string, error) <span class="cov0" title="0">{
        switch </span>{
        case strings.HasSuffix(objectID, ".binpb"):<span class="cov0" title="0">
                return convertMetricsProtoFile(tmpfilename, tmpdir, bucket, objectID, rpfEstimate)</span>
        default:<span class="cov0" title="0">
                ll.Warn("Unsupported file type for metrics, skipping", slog.String("objectID", objectID))
                return nil, nil</span>
        }
}

// convertMetricsProtoFile converts a protobuf file to the standardized format
func convertMetricsProtoFile(tmpfilename, tmpdir, bucket, objectID string, rpfEstimate int64) ([]string, error) <span class="cov0" title="0">{
        // Create a mapper for protobuf files
        mapper := translate.NewMapper()

        r, err := proto.NewMetricsProtoReader(tmpfilename, mapper, nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer r.Close()

        nmb := buffet.NewNodeMapBuilder()

        baseitems := map[string]string{
                "resource.bucket.name": bucket,
                "resource.file.name":   "./" + objectID,
                "resource.file.type":   ingestlogs.GetFileType(objectID),
        }

        // First pass: read all rows to build complete schema
        allRows := make([]map[string]any, 0)
        for </span><span class="cov0" title="0">{
                row, done, err := r.GetRow()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">if done </span><span class="cov0" title="0">{
                        break</span>
                }

                // Add base items to the row
                <span class="cov0" title="0">for k, v := range baseitems </span><span class="cov0" title="0">{
                        row[k] = v
                }</span>

                // Add row to schema builder
                <span class="cov0" title="0">if err := nmb.Add(row); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to add row to schema: %w", err)
                }</span>

                <span class="cov0" title="0">allRows = append(allRows, row)</span>
        }

        <span class="cov0" title="0">if len(allRows) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no rows processed")
        }</span>

        // Create writer with complete schema
        <span class="cov0" title="0">w, err := buffet.NewWriter("fileconv", tmpdir, nmb.Build(), rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                _, err := w.Close()
                if err != buffet.ErrAlreadyClosed &amp;&amp; err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to close writer", slog.Any("error", err))
                }</span>
        }()

        // Second pass: write all rows
        <span class="cov0" title="0">for _, row := range allRows </span><span class="cov0" title="0">{
                if err := w.Write(row); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to write row: %w", err)
                }</span>
        }

        <span class="cov0" title="0">result, err := w.Close()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to close writer: %w", err)
        }</span>
        <span class="cov0" title="0">if len(result) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no records written to file")
        }</span>

        <span class="cov0" title="0">var fnames []string
        for _, res := range result </span><span class="cov0" title="0">{
                fnames = append(fnames, res.FileName)
        }</span>
        <span class="cov0" title="0">return fnames, nil</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package ingestlogs

import (
        "errors"
        "fmt"
        "log/slog"
        "maps"
        "path"
        "reflect"
        "regexp"
        "strings"

        "github.com/cardinalhq/lakerunner/fileconv/rawparquet"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
        "github.com/cardinalhq/lakerunner/internal/buffet"
)

// getSchema scans a raw Parquet file and infers a flattened schema.
//
// It returns a map from fully-qualified field names to a representative sample
// value (used only to convey the field’s Go type), along with the total number
// of rows in the file.
//
// Why this is needed: nested/complex Parquet fields (maps, structs, arrays) are
// flattened into multiple dynamically named columns by the translator, so we
// must discover the *actual* emitted column set before building the writer.
//
// Behavior:
//   - If the file has zero rows, it returns (nil, 0, nil).
//   - If the same flattened column appears with conflicting Go types across rows,
//     the function returns an error.
//   - Only one representative value per column is stored; callers should rely on
//     its dynamic type, not its contents.
//
// Returns:
//
//        schema: map[columnName]sampleValue
//        nRows : total number of rows in the file
//        err   : non-nil on I/O or schema conflicts
func getSchema(sourcefile string) (map[string]any, int64, error) <span class="cov0" title="0">{
        schema := make(map[string]any)
        types := make(map[string]reflect.Type)

        r, err := rawparquet.NewRawParquetReader(sourcefile, translate.NewMapper(), nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, 0, err
        }</span>
        <span class="cov0" title="0">defer r.Close()

        nRows := r.NumRows()
        if nRows == 0 </span><span class="cov0" title="0">{
                return nil, 0, nil
        }</span>

        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                row, done, err := r.GetRow()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, 0, err
                }</span>
                <span class="cov0" title="0">if done </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov0" title="0">for k, v := range row </span><span class="cov0" title="0">{
                        t := reflect.TypeOf(v)
                        if prev, ok := types[k]; !ok </span><span class="cov0" title="0">{
                                types[k] = t
                                schema[k] = v
                        }</span> else<span class="cov0" title="0"> if t != prev </span><span class="cov0" title="0">{
                                // TODO: coerce numeric types here instead of failing
                                return nil, 0, fmt.Errorf("type mismatch for key %q: %v vs %v", k, prev, t)
                        }</span>
                }
        }

        <span class="cov0" title="0">return schema, nRows, nil</span>
}

func ConvertRawParquet(sourcefile, tmpdir, bucket, objectID string, rpfEstimate int64) ([]string, error) <span class="cov0" title="0">{
        schemanodes, nRows, err := getSchema(sourcefile)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get schema: %w", err)
        }</span>
        <span class="cov0" title="0">if nRows == 0 </span><span class="cov0" title="0">{
                return nil, nil
        }</span>

        <span class="cov0" title="0">r, err := rawparquet.NewRawParquetReader(sourcefile, translate.NewMapper(), nil)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer r.Close()

        // add our new nodes to the list of nodes we will write out
        schemanodes["resource.bucket.name"] = "bucket"
        schemanodes["resource.file.name"] = "object"
        schemanodes["resource.file.type"] = "filename"
        schemanodes["resource.file"] = "file"

        nmb := buffet.NewNodeMapBuilder()
        if err := nmb.Add(schemanodes); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to add resource nodes: %w", err)
        }</span>

        <span class="cov0" title="0">w, err := buffet.NewWriter("fileconv", tmpdir, nmb.Build(), rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("Failed to create writer: %w", err)
        }</span>

        <span class="cov0" title="0">closed := false
        defer func() </span><span class="cov0" title="0">{
                if !closed </span><span class="cov0" title="0">{
                        if _, err := w.Close(); err != nil &amp;&amp; !errors.Is(err, buffet.ErrAlreadyClosed) </span><span class="cov0" title="0">{
                                slog.Error("failed to close writer", slog.Any("error", err))
                        }</span>
                }
        }()

        <span class="cov0" title="0">baseitems := map[string]any{
                "resource.bucket.name": bucket,
                "resource.file.name":   "./" + objectID,
                "resource.file.type":   GetFileType(objectID),
                "resource.file":        getResourceFile(objectID),
        }

        for </span><span class="cov0" title="0">{
                row, done, err := r.GetRow()
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">if done </span><span class="cov0" title="0">{
                        break</span>
                }
                <span class="cov0" title="0">rowCopy := make(map[string]any, len(row)+len(baseitems))
                maps.Copy(rowCopy, row)
                maps.Copy(rowCopy, baseitems) // will overwrite any existing keys
                if err := w.Write(rowCopy); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to write row: %w", err)
                }</span>
        }

        <span class="cov0" title="0">result, err := w.Close()
        closed = true
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to close writer: %w", err)
        }</span>
        <span class="cov0" title="0">if len(result) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no records written to file")
        }</span>

        <span class="cov0" title="0">var fnames []string
        for _, res := range result </span><span class="cov0" title="0">{
                fnames = append(fnames, res.FileName)
        }</span>
        <span class="cov0" title="0">return fnames, nil</span>
}

func getResourceFile(objectID string) string <span class="cov8" title="1">{
        // find the /Support path element, and return the next element
        parts := strings.Split(objectID, "/")
        for i, part := range parts </span><span class="cov8" title="1">{
                if part == "Support" &amp;&amp; i+1 &lt; len(parts) </span><span class="cov8" title="1">{
                        return parts[i+1]
                }</span>
        }
        <span class="cov8" title="1">return ""</span>
}

var nonLetter = regexp.MustCompile(`[^a-zA-Z]`)

// getFileType extracts the “base” of the filename (everything before the last dot),
// then strips out any non‑letter characters.
func GetFileType(p string) string <span class="cov8" title="1">{
        fileName := path.Base(p)

        // find last “.”; if none, use whole filename
        if idx := strings.LastIndex(fileName, "."); idx != -1 </span><span class="cov8" title="1">{
                fileName = fileName[:idx]
        }</span>

        // strip out anything that isn’t A–Z or a–z
        <span class="cov8" title="1">return nonLetter.ReplaceAllString(fileName, "")</span>
}
</pre>
		
		<pre class="file" id="file17" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "fmt"
        "log/slog"

        "github.com/cardinalhq/lakerunner/lrdb"
)

type InqueueHandler struct {
        ctx context.Context
        ll  *slog.Logger
        mdb lrdb.StoreFull
        inf lrdb.Inqueue
}

func NewInqueueHandler(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        inf lrdb.Inqueue,
) *InqueueHandler <span class="cov0" title="0">{
        return &amp;InqueueHandler{ctx, ll, mdb, inf}
}</span>

func (h *InqueueHandler) retryWork() <span class="cov0" title="0">{
        if err := h.mdb.ReleaseInqueueWork(h.ctx, lrdb.ReleaseInqueueWorkParams{
                ID:        h.inf.ID,
                ClaimedBy: h.inf.ClaimedBy,
        }); err != nil </span><span class="cov0" title="0">{
                h.ll.Error("release failed", slog.Any("error", err))
        }</span>
}

func (h *InqueueHandler) deleteWork() <span class="cov0" title="0">{
        if err := h.mdb.DeleteInqueueWork(h.ctx, lrdb.DeleteInqueueWorkParams{
                ID:        h.inf.ID,
                ClaimedBy: h.inf.ClaimedBy,
        }); err != nil </span><span class="cov0" title="0">{
                h.ll.Error("delete failed", slog.Any("error", err))
        }</span>
}

func (h *InqueueHandler) CompleteWork() <span class="cov0" title="0">{
        h.deleteWork()
}</span>

func (h *InqueueHandler) RetryWork() <span class="cov0" title="0">{
        h.deleteJournal()
        if h.inf.Tries+1 &gt; maxWorkRetries </span><span class="cov0" title="0">{
                h.ll.Info("too many retries, deleting", slog.Int("newTries", int(h.inf.Tries+1)))
                h.deleteWork()
        }</span> else<span class="cov0" title="0"> {
                h.retryWork()
        }</span>
}

func (h *InqueueHandler) deleteJournal() <span class="cov0" title="0">{
        if err := h.mdb.InqueueJournalDelete(h.ctx, lrdb.InqueueJournalDeleteParams{
                OrganizationID: h.inf.OrganizationID,
                Bucket:         h.inf.Bucket,
                ObjectID:       h.inf.ObjectID,
        }); err != nil </span><span class="cov0" title="0">{
                h.ll.Error("journal delete failed", slog.Any("error", err))
        }</span>
}

// IsNewWork returns true if the row is new.
func (h *InqueueHandler) IsNewWork() (isNew bool, err error) <span class="cov0" title="0">{
        isNew, err = h.mdb.InqueueJournalUpsert(h.ctx, lrdb.InqueueJournalUpsertParams{
                OrganizationID: h.inf.OrganizationID,
                Bucket:         h.inf.Bucket,
                ObjectID:       h.inf.ObjectID,
        })
        if err != nil </span><span class="cov0" title="0">{
                return false, fmt.Errorf("upsert journal failed: %w", err)
        }</span>
        <span class="cov0" title="0">return isNew, nil</span>
}
</pre>
		
		<pre class="file" id="file18" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
        "os"
        "time"

        "github.com/jackc/pgx/v5"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/metric"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/estimator"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lrdb"
)

type InqueueProcessingFunction func(
        ctx context.Context,
        ll *slog.Logger,
        tmpdir string,
        sp storageprofile.StorageProfileProvider,
        mdb lrdb.StoreFull,
        awsmanager *awsclient.Manager,
        inf lrdb.Inqueue,
        ingest_dateint int32,
        rpfEstimate int64) error

type IngestLoopContext struct {
        ctx        context.Context
        mdb        lrdb.StoreFull
        sp         storageprofile.StorageProfileProvider
        awsmanager *awsclient.Manager
        estimator  estimator.Estimator
        signal     string
        ll         *slog.Logger
}

func NewIngestLoopContext(ctx context.Context, signal string, assumeRoleSessionName string) (*IngestLoopContext, error) <span class="cov0" title="0">{
        ll := slog.Default().With(
                slog.String("signal", signal),
                slog.String("action", "ingest"),
        )

        mdb, err := dbopen.LRDBStore(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to open LRDB store: %w", err)
        }</span>

        <span class="cov0" title="0">awsmanager, err := awsclient.NewManager(ctx, awsclient.WithAssumeRoleSessionName(assumeRoleSessionName))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create AWS manager: %w", err)
        }</span>

        <span class="cov0" title="0">est, err := estimator.NewEstimator(ctx, mdb)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create estimator: %w", err)
        }</span>

        <span class="cov0" title="0">sp, err := storageprofile.SetupStorageProfiles()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to setup storage profiles: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;IngestLoopContext{
                ctx:        ctx,
                mdb:        mdb,
                sp:         sp,
                awsmanager: awsmanager,
                estimator:  est,
                signal:     signal,
                ll:         ll,
        }, nil</span>
}

func IngestLoop(loop *IngestLoopContext, processingFx InqueueProcessingFunction) error <span class="cov0" title="0">{
        ctx := context.Background()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-loop.ctx.Done():<span class="cov0" title="0">
                        return loop.ctx.Err()</span>
                default:<span class="cov0" title="0"></span>
                }

                <span class="cov0" title="0">t0 := time.Now()
                shouldBackoff, didWork, err := ingestFiles(ctx, loop, processingFx)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov0" title="0">if didWork </span><span class="cov0" title="0">{
                        loop.ll.Info("Ingested file", slog.Duration("elapsed", time.Since(t0)))
                }</span>

                <span class="cov0" title="0">if shouldBackoff </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-loop.ctx.Done():<span class="cov0" title="0">
                                return nil</span>
                        case &lt;-time.After(workSleepTime):<span class="cov0" title="0"></span>
                        }
                }

                <span class="cov0" title="0">gc()</span>
        }
}

func ingestFiles(
        ctx context.Context,
        loop *IngestLoopContext,
        processFx InqueueProcessingFunction,
) (bool, bool, error) <span class="cov0" title="0">{
        ctx, span := tracer.Start(ctx, "ingest", trace.WithAttributes(commonAttributes.ToSlice()...))
        defer span.End()

        t0 := time.Now()
        inf, err := loop.mdb.ClaimInqueueWork(ctx, lrdb.ClaimInqueueWorkParams{
                ClaimedBy:     myInstanceID,
                TelemetryType: loop.signal,
        })
        inqueueFetchDuration.Record(ctx, time.Since(t0).Seconds(),
                metric.WithAttributeSet(commonAttributes),
                metric.WithAttributes(
                        attribute.Bool("hasError", err != nil &amp;&amp; !errors.Is(err, pgx.ErrNoRows)),
                        attribute.Bool("noRows", errors.Is(err, pgx.ErrNoRows)),
                ))
        if err != nil </span><span class="cov0" title="0">{
                if errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                        return true, false, nil
                }</span>
                <span class="cov0" title="0">return true, false, fmt.Errorf("failed to claim inqueue work: %w", err)</span>
        }

        <span class="cov0" title="0">ll := loop.ll.With(
                slog.String("id", inf.ID.String()),
                slog.Int("tries", int(inf.Tries)),
                slog.String("collectorName", inf.CollectorName),
                slog.String("organizationID", inf.OrganizationID.String()),
                slog.Int("instanceNum", int(inf.InstanceNum)),
                slog.String("bucket", inf.Bucket),
                slog.String("objectID", inf.ObjectID))

        h := NewInqueueHandler(ctx, ll, loop.mdb, inf)

        if inf.Tries &gt; 10 </span><span class="cov0" title="0">{
                ll.Warn("Too many tries, deleting")
                h.CompleteWork()
                return false, true, nil
        }</span>

        <span class="cov0" title="0">isNew, err := h.IsNewWork()
        if err != nil </span><span class="cov0" title="0">{
                h.RetryWork()
                return true, false, err
        }</span>
        <span class="cov0" title="0">if !isNew </span><span class="cov0" title="0">{
                ll.Warn("already processed, releasing")
                h.CompleteWork()
                return true, true, nil
        }</span>

        <span class="cov0" title="0">ll.Info("Processing")

        ingestDateint, _ := helpers.MSToDateintHour(time.Now().UTC().UnixMilli())

        // Create a temporary directory for processing
        tmpdir, err := os.MkdirTemp("", "lakerunner-ingest-*")
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to create temporary directory", slog.Any("error", err))
                h.RetryWork()
                return true, false, fmt.Errorf("failed to create temporary directory: %w", err)
        }</span>
        <span class="cov0" title="0">ll.Info("Created temporary directory", slog.String("path", tmpdir))
        defer func() </span><span class="cov0" title="0">{
                if err := os.RemoveAll(tmpdir); err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to remove temporary directory", slog.String("path", tmpdir), slog.Any("error", err))
                }</span> else<span class="cov0" title="0"> {
                        ll.Info("Removed temporary directory", slog.String("path", tmpdir))
                }</span>
        }()

        <span class="cov0" title="0">rpfEstimate := loop.estimator.Get(inf.OrganizationID, inf.InstanceNum, lrdb.SignalEnum(inf.TelemetryType)).EstimatedRecordCount
        t0 = time.Now()
        err = processFx(ctx, ll, tmpdir, loop.sp, loop.mdb, loop.awsmanager, inf, ingestDateint, rpfEstimate)
        inqueueDuration.Record(ctx, time.Since(t0).Seconds(),
                metric.WithAttributeSet(commonAttributes),
                metric.WithAttributes(
                        attribute.String("organizationID", inf.OrganizationID.String()),
                        attribute.String("collectorName", inf.CollectorName),
                        attribute.Int("instanceNum", int(inf.InstanceNum)),
                        attribute.String("bucket", inf.Bucket),
                ))
        if err != nil </span><span class="cov0" title="0">{
                h.RetryWork()
                return true, false, fmt.Errorf("Processing failed: %w", err)
        }</span>

        <span class="cov0" title="0">h.CompleteWork()
        return false, true, nil</span>
}
</pre>
		
		<pre class="file" id="file19" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "slices"
        "time"

        "github.com/jackc/pgx/v5/pgtype"

        "github.com/cardinalhq/lakerunner/lrdb"
)

var (
        // Map the current frequency into the ones we feed to.
        rollupNotifications = map[int32]int32{
                10_000:    60_000,    // 10 seconds feeds 1m
                60_000:    300_000,   // 1 minute feeds 5m
                300_000:   1_200_000, // 5 minutes feeds 15m
                1_200_000: 3_600_000, // 20 minutes feeds 1h
        }

        // Map our current frequency into the one we feed from.
        rollupSources = map[int32]int32{
                60_000:    10_000,    // 1 minute is from 10 seconds
                300_000:   60_000,    // 5 minutes is from 1 minute
                1_200_000: 300_000,   // 20 minutes is from 5 minutes
                3_600_000: 1_200_000, // 1 hour is from 20 minutes
        }

        acceptedMetricFrequencies = []int32{
                10_000,    // 10 seconds
                60_000,    // 1 minute
                300_000,   // 5 minutes
                1_200_000, // 20 minutes
                3_600_000, // 1 hour
        }
)

func isWantedFrequency(frequency int32) bool <span class="cov0" title="0">{
        return slices.Contains(acceptedMetricFrequencies, frequency)
}</span>

// allRolledUp returns true all rows are rolledup.
// If the slice is empty, the return value is junk.
func allRolledUp(rows []lrdb.MetricSeg) bool <span class="cov8" title="1">{
        for _, row := range rows </span><span class="cov8" title="1">{
                if !row.Rolledup </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov8" title="1">return true</span>
}

// Return the bounds of the given range.  The returned start time is inclusive
// and the end time is exclusive.  If the range is unbounded, or cannot be converted
// to concrete bounds, the function returns ok=false and the bounds are invalid.
func RangeBounds[T int | int16 | int32 | int64 | pgtype.Int8 | time.Time | pgtype.Timestamptz](r pgtype.Range[T]) (lower, upper T, ok bool) <span class="cov8" title="1">{
        if r.LowerType != pgtype.Inclusive &amp;&amp; r.LowerType != pgtype.Exclusive </span><span class="cov8" title="1">{
                return lower, upper, false
        }</span>
        <span class="cov8" title="1">if r.UpperType != pgtype.Inclusive &amp;&amp; r.UpperType != pgtype.Exclusive </span><span class="cov8" title="1">{
                return lower, upper, false
        }</span>

        <span class="cov8" title="1">lower = r.Lower
        upper = r.Upper

        // Always return inclusive lower and exclusive upper.
        // Only accept inclusive or exclusive lower, and inclusive or exclusive upper.
        if r.LowerType != pgtype.Inclusive &amp;&amp; r.LowerType != pgtype.Exclusive </span><span class="cov0" title="0">{
                return lower, upper, false
        }</span>
        <span class="cov8" title="1">if r.UpperType != pgtype.Inclusive &amp;&amp; r.UpperType != pgtype.Exclusive </span><span class="cov0" title="0">{
                return lower, upper, false
        }</span>

        // If the input lower is exclusive, increment lower by 1ns or 1 (for ints).
        <span class="cov8" title="1">if r.LowerType == pgtype.Exclusive </span><span class="cov8" title="1">{
                switch v := any(lower).(type) </span>{
                case time.Time:<span class="cov8" title="1">
                        lower = any(v.Add(time.Nanosecond)).(T)</span>
                case pgtype.Timestamptz:<span class="cov8" title="1">
                        shifted := pgtype.Timestamptz{
                                Time:  v.Time.Add(time.Nanosecond),
                                Valid: true,
                        }
                        lower = any(shifted).(T)</span>
                case pgtype.Int8:<span class="cov8" title="1">
                        shifted := pgtype.Int8{
                                Int64: v.Int64 + 1,
                                Valid: true,
                        }
                        lower = any(shifted).(T)</span>
                case int:<span class="cov8" title="1">
                        lower = any(v + 1).(T)</span>
                case int16:<span class="cov0" title="0">
                        lower = any(v + 1).(T)</span>
                case int32:<span class="cov0" title="0">
                        lower = any(v + 1).(T)</span>
                case int64:<span class="cov8" title="1">
                        lower = any(v + 1).(T)</span>
                default:<span class="cov0" title="0">
                        return lower, upper, false</span>
                }
        }

        // If the input upper is inclusive, increment upper by 1ns or 1 (for ints) to make it exclusive.
        <span class="cov8" title="1">if r.UpperType == pgtype.Inclusive </span><span class="cov8" title="1">{
                switch v := any(upper).(type) </span>{
                case time.Time:<span class="cov8" title="1">
                        upper = any(v.Add(time.Nanosecond)).(T)</span>
                case pgtype.Timestamptz:<span class="cov8" title="1">
                        shifted := pgtype.Timestamptz{
                                Time:  v.Time.Add(time.Nanosecond),
                                Valid: true,
                        }
                        upper = any(shifted).(T)</span>
                case pgtype.Int8:<span class="cov8" title="1">
                        shifted := pgtype.Int8{
                                Int64: v.Int64 + 1,
                                Valid: true,
                        }
                        upper = any(shifted).(T)</span>
                case int:<span class="cov8" title="1">
                        upper = any(v + 1).(T)</span>
                case int16:<span class="cov0" title="0">
                        upper = any(v + 1).(T)</span>
                case int32:<span class="cov0" title="0">
                        upper = any(v + 1).(T)</span>
                case int64:<span class="cov8" title="1">
                        upper = any(v + 1).(T)</span>
                default:<span class="cov0" title="0">
                        return lower, upper, false</span>
                }
        }

        <span class="cov8" title="1">return lower, upper, true</span>
}
</pre>
		
		<pre class="file" id="file20" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "fmt"
        "time"

        "github.com/spf13/cobra"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        mdbmigrations "github.com/cardinalhq/lakerunner/lrdb/migrations"
)

func init() <span class="cov8" title="1">{
        rootCmd.AddCommand(MigrateCmd)
}</span>

var MigrateCmd = &amp;cobra.Command{
        Use:   "migrate",
        Short: "Run database migrations",
        Long:  "Run database migrations",
        RunE:  migrate,
}

func migrate(_ *cobra.Command, _ []string) error <span class="cov0" title="0">{
        if err := migratelrdb(); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to migrate lrdb db: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

func migratelrdb() error <span class="cov0" title="0">{
        ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(5*time.Minute))
        defer cancel()
        pool, err := dbopen.ConnectTolrdb(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return mdbmigrations.RunMigrationsUp(context.Background(), pool)</span>
}
</pre>
		
		<pre class="file" id="file21" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package otel

import (
        "encoding/json"
        "maps"

        "github.com/DataDog/sketches-go/ddsketch"
        "go.opentelemetry.io/collector/pdata/pcommon"
        "go.opentelemetry.io/collector/pdata/plog"
        "go.opentelemetry.io/collector/pdata/pmetric"

        "github.com/cardinalhq/lakerunner/internal/idgen"

        "log/slog"
        "math"
        "strings"
        "time"

        "github.com/cardinalhq/oteltools/pkg/authenv"
        "github.com/cardinalhq/oteltools/pkg/translate"
)

type TableTranslator struct {
        idg idgen.IDGenerator
}

func NewTableTranslator() *TableTranslator <span class="cov0" title="0">{
        return &amp;TableTranslator{
                idg: idgen.NewULIDGenerator(),
        }
}</span>

func SeverityNumberToText(severityNumber plog.SeverityNumber) string <span class="cov0" title="0">{
        switch </span>{
        case severityNumber &gt;= 1 &amp;&amp; severityNumber &lt;= 4:<span class="cov0" title="0">
                return "TRACE"</span>
        case severityNumber &gt;= 5 &amp;&amp; severityNumber &lt;= 8:<span class="cov0" title="0">
                return "DEBUG"</span>
        case severityNumber &gt;= 9 &amp;&amp; severityNumber &lt;= 12:<span class="cov0" title="0">
                return "INFO"</span>
        case severityNumber &gt;= 13 &amp;&amp; severityNumber &lt;= 16:<span class="cov0" title="0">
                return "WARN"</span>
        case severityNumber &gt;= 17 &amp;&amp; severityNumber &lt;= 20:<span class="cov0" title="0">
                return "ERROR"</span>
        case severityNumber &gt;= 21 &amp;&amp; severityNumber &lt;= 24:<span class="cov0" title="0">
                return "FATAL"</span>
        default:<span class="cov0" title="0">
                return "UNSPECIFIED"</span>
        }
}

func (l *TableTranslator) LogsFromOtel(ol *plog.Logs, environment authenv.Environment) ([]map[string]any, error) <span class="cov0" title="0">{
        var rets []map[string]any

        for i := 0; i &lt; ol.ResourceLogs().Len(); i++ </span><span class="cov0" title="0">{
                rl := ol.ResourceLogs().At(i)
                for j := 0; j &lt; rl.ScopeLogs().Len(); j++ </span><span class="cov0" title="0">{
                        ill := rl.ScopeLogs().At(j)
                        for k := 0; k &lt; ill.LogRecords().Len(); k++ </span><span class="cov0" title="0">{
                                log := ill.LogRecords().At(k)
                                ret := map[string]any{translate.CardinalFieldTelemetryType: "logs"}
                                addAttributes(ret, rl.Resource().Attributes(), "resource")
                                addAttributes(ret, ill.Scope().Attributes(), "scope")
                                addAttributes(ret, log.Attributes(), "log")
                                ret[translate.CardinalFieldMessage] = log.Body().AsString()
                                ts := log.Timestamp().AsTime().UnixMilli()
                                if ts == 0 </span><span class="cov0" title="0">{
                                        ts = log.ObservedTimestamp().AsTime().UnixMilli()
                                }</span>
                                <span class="cov0" title="0">ret[translate.CardinalFieldTimestamp] = ts
                                ret[translate.CardinalFieldID] = l.idg.Make(time.Now())
                                if environment != nil </span><span class="cov0" title="0">{
                                        for k, v := range environment.Tags() </span><span class="cov0" title="0">{
                                                ret["env."+k] = v
                                        }</span>
                                }

                                // If severity number is set, use it to set log level
                                <span class="cov0" title="0">if log.SeverityNumber() != plog.SeverityNumberUnspecified </span><span class="cov0" title="0">{
                                        log.SetSeverityText(SeverityNumberToText(log.SeverityNumber()))
                                }</span> else<span class="cov0" title="0"> if log.SeverityText() == "" || log.SeverityText() == plog.SeverityNumberUnspecified.String() </span><span class="cov0" title="0">{
                                        log.SetSeverityText("INFO")
                                }</span>
                                <span class="cov0" title="0">ret[translate.CardinalFieldLevel] = log.SeverityText()
                                log.Attributes().PutStr(translate.CardinalFieldLevel, log.SeverityText())
                                ensureExpectedKeysLogs(ret)
                                rets = append(rets, ret)</span>
                        }
                }
        }

        <span class="cov0" title="0">return rets, nil</span>
}

func ensureExpectedKeysLogs(m map[string]any) <span class="cov0" title="0">{
        keys := map[string]any{
                translate.CardinalFieldFingerprint: int64(0),
                translate.CardinalFieldMessage:     "",
                translate.CardinalFieldValue:       float64(1),
                translate.CardinalFieldName:        "log.events",
        }

        for key, val := range keys </span><span class="cov0" title="0">{
                if _, ok := m[key]; !ok </span><span class="cov0" title="0">{
                        m[key] = val
                }</span>
        }
}

func addAttributes(m map[string]any, attrs pcommon.Map, prefix string) <span class="cov0" title="0">{
        attrs.Range(func(name string, v pcommon.Value) bool </span><span class="cov0" title="0">{
                if strings.HasPrefix(name, translate.CardinalFieldPrefixDot) </span><span class="cov0" title="0">{
                        m[name] = handleValue(v.AsRaw())
                }</span> else<span class="cov0" title="0"> {
                        m[prefix+"."+name] = v.AsString()
                }</span>

                <span class="cov0" title="0">return true</span>
        })
}

func handleValue(v any) any <span class="cov0" title="0">{
        switch v.(type) </span>{
        case string, int, int8, int16, int32, int64,
                uint, uint8, uint16, uint32, uint64,
                float32, float64, bool:<span class="cov0" title="0">
                return v</span>
        default:<span class="cov0" title="0">
                bytes, err := json.Marshal(v)
                if err != nil </span><span class="cov0" title="0">{
                        return "[]"
                }</span>
                <span class="cov0" title="0">return string(bytes)</span>
        }
}

func (l *TableTranslator) MetricsFromOtel(om *pmetric.Metrics, environment authenv.Environment) ([]map[string]any, error) <span class="cov0" title="0">{
        rets := []map[string]any{}

        for i := 0; i &lt; om.ResourceMetrics().Len(); i++ </span><span class="cov0" title="0">{
                rm := om.ResourceMetrics().At(i)
                for j := 0; j &lt; rm.ScopeMetrics().Len(); j++ </span><span class="cov0" title="0">{
                        imm := rm.ScopeMetrics().At(j)
                        for k := 0; k &lt; imm.Metrics().Len(); k++ </span><span class="cov0" title="0">{
                                baseret := map[string]any{translate.CardinalFieldTelemetryType: translate.CardinalTelemetryTypeMetrics}
                                if environment != nil </span><span class="cov0" title="0">{
                                        for k, v := range environment.Tags() </span><span class="cov0" title="0">{
                                                baseret["env."+k] = v
                                        }</span>
                                }
                                <span class="cov0" title="0">addAttributes(baseret, rm.Resource().Attributes(), "resource")
                                addAttributes(baseret, imm.Scope().Attributes(), "scope")
                                metric := imm.Metrics().At(k)
                                rets = append(rets, l.toddmetric(metric, baseret)...)</span>
                        }
                }
        }

        <span class="cov0" title="0">return rets, nil</span>
}

func (l *TableTranslator) toddmetric(metric pmetric.Metric, baseattrs map[string]any) []map[string]any <span class="cov0" title="0">{
        switch metric.Type() </span>{
        case pmetric.MetricTypeGauge:<span class="cov0" title="0">
                return l.toddGauge(metric, baseattrs)</span>
        case pmetric.MetricTypeSum:<span class="cov0" title="0">
                return l.toddSum(metric, baseattrs)</span>
        case pmetric.MetricTypeHistogram:<span class="cov0" title="0">
                return l.toddHistogram(metric, baseattrs)</span>
        case pmetric.MetricTypeExponentialHistogram:<span class="cov0" title="0">
                return l.toddExponentialHistogram(metric, baseattrs)</span>
        case pmetric.MetricTypeSummary:<span class="cov0" title="0">
                return nil</span>
        case pmetric.MetricTypeEmpty:<span class="cov0" title="0">
                return nil</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func (l *TableTranslator) toddGauge(metric pmetric.Metric, baseattrs map[string]any) []map[string]any <span class="cov0" title="0">{
        rets := []map[string]any{}

        for i := 0; i &lt; metric.Gauge().DataPoints().Len(); i++ </span><span class="cov0" title="0">{
                dp := metric.Gauge().DataPoints().At(i)
                ret := maps.Clone(baseattrs)
                addAttributes(ret, dp.Attributes(), "metric")
                ret[translate.CardinalFieldMetricType] = translate.CardinalMetricTypeGauge
                ret[translate.CardinalFieldTimestamp] = dp.Timestamp().AsTime().UnixMilli()
                switch dp.ValueType() </span>{
                case pmetric.NumberDataPointValueTypeDouble:<span class="cov0" title="0">
                        val, safe := safeFloat(dp.DoubleValue())
                        if !safe </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">ret[translate.CardinalFieldValue] = val</span>
                case pmetric.NumberDataPointValueTypeInt:<span class="cov0" title="0">
                        ret[translate.CardinalFieldValue] = float64(dp.IntValue())</span>
                case pmetric.NumberDataPointValueTypeEmpty:<span class="cov0" title="0">
                        continue</span>
                default:<span class="cov0" title="0">
                        continue</span>
                }
                <span class="cov0" title="0">ret[translate.CardinalFieldName] = metric.Name()
                ret[translate.CardinalFieldID] = l.idg.Make(time.Now())
                ok := ensureExpectedKeysMetrics(ret)
                if !ok </span><span class="cov0" title="0">{
                        slog.Info("missing critical key", slog.String("metric", metric.Name()))
                        continue</span>
                }
                <span class="cov0" title="0">rets = append(rets, ret)</span>
        }

        <span class="cov0" title="0">return rets</span>
}

func (l *TableTranslator) toddSum(metric pmetric.Metric, baseattrs map[string]any) []map[string]any <span class="cov0" title="0">{
        rets := []map[string]any{}

        for i := 0; i &lt; metric.Sum().DataPoints().Len(); i++ </span><span class="cov0" title="0">{
                dp := metric.Sum().DataPoints().At(i)
                ret := maps.Clone(baseattrs)
                addAttributes(ret, dp.Attributes(), "metric")
                if metric.Sum().AggregationTemporality() == pmetric.AggregationTemporalityCumulative &amp;&amp; !metric.Sum().IsMonotonic() </span><span class="cov0" title="0">{
                        ret[translate.CardinalFieldMetricType] = translate.CardinalMetricTypeGauge
                }</span> else<span class="cov0" title="0"> {
                        ret[translate.CardinalFieldMetricType] = translate.CardinalMetricTypeCount
                }</span>
                <span class="cov0" title="0">ret[translate.CardinalFieldMetricType] = translate.CardinalMetricTypeCount
                ret[translate.CardinalFieldTimestamp] = dp.Timestamp().AsTime().UnixMilli()
                switch dp.ValueType() </span>{
                case pmetric.NumberDataPointValueTypeDouble:<span class="cov0" title="0">
                        val, safe := safeFloat(dp.DoubleValue())
                        if !safe </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">ret[translate.CardinalFieldValue] = val</span>
                case pmetric.NumberDataPointValueTypeInt:<span class="cov0" title="0">
                        ret[translate.CardinalFieldValue] = float64(dp.IntValue())</span>
                case pmetric.NumberDataPointValueTypeEmpty:<span class="cov0" title="0">
                        continue</span>
                default:<span class="cov0" title="0">
                        continue</span>
                }
                <span class="cov0" title="0">ret[translate.CardinalFieldName] = metric.Name()
                ret[translate.CardinalFieldID] = l.idg.Make(time.Now())
                ok := ensureExpectedKeysMetrics(ret)
                if !ok </span><span class="cov0" title="0">{
                        slog.Info("missing critical key", slog.String("metric", metric.Name()))
                        continue</span>
                }
                <span class="cov0" title="0">rets = append(rets, ret)</span>
        }

        <span class="cov0" title="0">return rets</span>
}

func safeFloat(v float64) (float64, bool) <span class="cov0" title="0">{
        if math.IsInf(v, 0) || math.IsNaN(v) </span><span class="cov0" title="0">{
                return 0, false
        }</span>
        <span class="cov0" title="0">return v, true</span>
}

func (l *TableTranslator) toddHistogram(metric pmetric.Metric, baseattrs map[string]any) []map[string]any <span class="cov0" title="0">{
        var rets []map[string]any

        for i := 0; i &lt; metric.Histogram().DataPoints().Len(); i++ </span><span class="cov0" title="0">{
                dp := metric.Histogram().DataPoints().At(i)
                ret := maps.Clone(baseattrs)
                addAttributes(ret, dp.Attributes(), "metric")
                ret[translate.CardinalFieldMetricType] = translate.CardinalMetricTypeHistogram
                ret[translate.CardinalFieldTimestamp] = dp.Timestamp().AsTime().UnixMilli()
                ret[translate.CardinalFieldCounts] = asJson(dp.BucketCounts().AsRaw())
                ret[translate.CardinalFieldBucketBounds] = asJson(dp.ExplicitBounds().AsRaw())
                ret[translate.CardinalFieldName] = metric.Name()
                ret[translate.CardinalFieldID] = l.idg.Make(time.Now())
                ret[translate.CardinalFieldValue] = float64(-1)
                ok := ensureExpectedKeysMetrics(ret)
                if !ok </span><span class="cov0" title="0">{
                        slog.Info("missing critical key", slog.String("metric", metric.Name()))
                        continue</span>
                }
                <span class="cov0" title="0">rets = append(rets, ret)</span>
        }

        <span class="cov0" title="0">return rets</span>
}

func (l *TableTranslator) toddExponentialHistogram(metric pmetric.Metric, baseattrs map[string]any) []map[string]any <span class="cov0" title="0">{
        rets := []map[string]any{}

        for i := 0; i &lt; metric.ExponentialHistogram().DataPoints().Len(); i++ </span><span class="cov0" title="0">{
                dp := metric.ExponentialHistogram().DataPoints().At(i)
                ret := maps.Clone(baseattrs)
                addAttributes(ret, dp.Attributes(), "metric")
                ret[translate.CardinalFieldMetricType] = translate.CardinalMetricTypeExponentialHistogram
                ret[translate.CardinalFieldTimestamp] = dp.Timestamp().AsTime().UnixMilli()
                ret[translate.CardinalFieldScale] = dp.Scale()
                ret[translate.CardinalFieldNegativeCounts] = asJson(dp.Negative().BucketCounts().AsRaw())
                ret[translate.CardinalFieldPositiveCounts] = asJson(dp.Positive().BucketCounts().AsRaw())
                ret[translate.CardinalFieldZeroCount] = dp.ZeroCount()
                ret[translate.CardinalFieldName] = metric.Name()
                ret[translate.CardinalFieldID] = l.idg.Make(time.Now())
                ret[translate.CardinalFieldValue] = float64(-1)
                ok := ensureExpectedKeysMetrics(ret)
                if !ok </span><span class="cov0" title="0">{
                        slog.Info("missing critical key", slog.String("metric", metric.Name()))
                        continue</span>
                }
                <span class="cov0" title="0">rets = append(rets, ret)</span>
        }

        <span class="cov0" title="0">return rets</span>
}

func asJson[T uint64 | float64](s []T) string <span class="cov0" title="0">{
        ret, _ := json.Marshal(s)
        return string(ret)
}</span>

func ensureExpectedKeysMetrics(m map[string]any) bool <span class="cov0" title="0">{
        keys := map[string]any{
                translate.CardinalFieldMetricType:     translate.CardinalMetricTypeGauge,
                translate.CardinalFieldBucketBounds:   "[]",
                translate.CardinalFieldCounts:         "[]",
                translate.CardinalFieldNegativeCounts: "[]",
                translate.CardinalFieldPositiveCounts: "[]",
        }

        for key, val := range keys </span><span class="cov0" title="0">{
                if _, ok := m[key]; !ok </span><span class="cov0" title="0">{
                        m[key] = val
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}

type DDWrapper struct {
        Sketch         *ddsketch.DDSketch
        StartTimestamp time.Time
        Timestamp      time.Time
        Attributes     map[string]any
}
</pre>
		
		<pre class="file" id="file22" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "os"
        "sync"

        "github.com/parquet-go/parquet-go"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/buffet"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
)

type objectFetcherAdapter struct {
        s3Client *awsclient.S3Client
}

var _ ObjectFetcher = (*objectFetcherAdapter)(nil)

func (a objectFetcherAdapter) Download(ctx context.Context, bucket, key, tmpdir string) (string, int64, bool, error) <span class="cov0" title="0">{
        return s3helper.DownloadS3Object(ctx, tmpdir, a.s3Client, bucket, key)
}</span>

// In pack_adapters.go

type fileOpenerAdapter struct{}

var _ FileOpener = (*fileOpenerAdapter)(nil)

func (fileOpenerAdapter) LoadSchemaForFile(path string) (*filecrunch.FileHandle, error) <span class="cov0" title="0">{
        return filecrunch.LoadSchemaForFile(path)
}</span>

type genericMapReaderAdapter struct {
        r *parquet.GenericReader[map[string]any]
}

var mapPool = sync.Pool{New: func() any <span class="cov8" title="1">{ return make(map[string]any) }</span>}

func (g genericMapReaderAdapter) Read(batch []map[string]any) (int, error) <span class="cov0" title="0">{
        if len(batch) &gt; 0 &amp;&amp; batch[0] == nil </span><span class="cov0" title="0">{
                for i := range batch </span><span class="cov0" title="0">{
                        batch[i] = mapPool.Get().(map[string]any)
                }</span>
        }
        <span class="cov0" title="0">return g.r.Read(batch)</span>
}

func (g genericMapReaderAdapter) Close() error <span class="cov0" title="0">{ return g.r.Close() }</span>

func (fileOpenerAdapter) NewGenericMapReader(f *os.File, schema *parquet.Schema) (GenericMapReader, error) <span class="cov0" title="0">{
        // If your parquet-go requires options/schema here, thread them in as needed.
        gr := parquet.NewGenericReader[map[string]any](f, schema)
        return genericMapReaderAdapter{r: gr}, nil
}</span>

type writerFactoryAdapter struct{}

var _ WriterFactory = (*writerFactoryAdapter)(nil)

func (writerFactoryAdapter) NewWriter(kind, tmpdir string, nodes map[string]parquet.Node, targetRowGroup int64) (Writer, error) <span class="cov0" title="0">{
        bw, err := buffet.NewWriter(kind, tmpdir, nodes, targetRowGroup)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return writerAdapter{bw}, nil</span>
}

type writerAdapter struct {
        inner *buffet.Writer
}

var _ Writer = (*writerAdapter)(nil)

func (w writerAdapter) Write(rec map[string]any) error <span class="cov0" title="0">{
        return w.inner.Write(rec)
}</span>

func (w writerAdapter) Close() ([]buffet.Result, error) <span class="cov0" title="0">{
        return w.inner.Close()
}</span>
</pre>
		
		<pre class="file" id="file23" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "errors"
        "fmt"
        "io"
        "log/slog"
        "os"

        "github.com/parquet-go/parquet-go"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lrdb"
)

// chooseObjectID returns the preferred object key (good or bad) that exists, or "" if neither.
func chooseObjectID(ctx context.Context, fetcher ObjectFetcher, bucket, good, bad, tmpdir string) (string, string, int64, error) <span class="cov8" title="1">{
        if tmp, sz, nf, err := fetcher.Download(ctx, bucket, good, tmpdir); err != nil </span><span class="cov8" title="1">{
                return "", "", 0, err
        }</span> else<span class="cov8" title="1"> if !nf </span><span class="cov8" title="1">{
                return good, tmp, sz, nil
        }</span>
        <span class="cov8" title="1">if tmp, sz, nf, err := fetcher.Download(ctx, bucket, bad, tmpdir); err != nil </span><span class="cov8" title="1">{
                return "", "", 0, err
        }</span> else<span class="cov8" title="1"> if !nf </span><span class="cov8" title="1">{
                return bad, tmp, sz, nil
        }</span>
        <span class="cov8" title="1">return "", "", 0, nil</span>
}

type openedSegment struct {
        Seg      lrdb.GetLogSegmentsForCompactionRow
        Handle   *filecrunch.FileHandle
        ObjectID string
}

// downloadAndOpen segments; returns only those that exist and opened successfully.
func downloadAndOpen(
        ctx context.Context,
        sp storageprofile.StorageProfile,
        dateint int32,
        group []lrdb.GetLogSegmentsForCompactionRow,
        tmpdir string,
        bucket string,
        fetcher ObjectFetcher,
        open FileOpener,
) ([]openedSegment, error) <span class="cov8" title="1">{
        out := make([]openedSegment, 0, len(group))
        for _, seg := range group </span><span class="cov8" title="1">{
                if err := ctx.Err(); err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>

                <span class="cov8" title="1">good := helpers.MakeDBObjectID(sp.OrganizationID, sp.CollectorName, dateint, s3helper.HourFromMillis(seg.StartTs), seg.SegmentID, "logs")
                bad := helpers.MakeDBObjectIDbad(sp.OrganizationID, sp.CollectorName, dateint, s3helper.HourFromMillis(seg.StartTs), seg.SegmentID, "logs")

                objectID, tmpfile, _, err := chooseObjectID(ctx, fetcher, bucket, good, bad, tmpdir)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("download: %w", err)
                }</span>
                <span class="cov8" title="1">if objectID == "" </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">fh, err := open.LoadSchemaForFile(tmpfile)
                if err != nil </span><span class="cov8" title="1">{
                        return nil, fmt.Errorf("open schema: %w", err)
                }</span>
                // Normalize timestamp
                <span class="cov8" title="1">fh.Nodes["_cardinalhq.timestamp"] = filecrunch.NodeTypeMap["INT64"]
                for _, fn := range dropFieldNames </span><span class="cov8" title="1">{
                        delete(fh.Nodes, fn)
                }</span>

                <span class="cov8" title="1">out = append(out, openedSegment{Seg: seg, Handle: fh, ObjectID: objectID})</span>
        }
        <span class="cov8" title="1">return out, nil</span>
}

// mergeNodes merges schemas from opened handles.
func mergeNodes(handles []*filecrunch.FileHandle) (map[string]parquet.Node, error) <span class="cov8" title="1">{
        cap := 0
        for _, h := range handles </span><span class="cov8" title="1">{
                if h != nil </span><span class="cov8" title="1">{
                        cap += len(h.Nodes)
                }</span>
        }
        <span class="cov8" title="1">nodes := make(map[string]parquet.Node, cap)
        for _, h := range handles </span><span class="cov8" title="1">{
                if h == nil || h.Nodes == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">if err := filecrunch.MergeNodes(h, nodes); err != nil </span><span class="cov8" title="1">{
                        return nil, err
                }</span>
        }
        <span class="cov8" title="1">return nodes, nil</span>
}

func computeDropSet(nodes map[string]parquet.Node) map[string]struct{} <span class="cov8" title="1">{
        drop := map[string]struct{}{}
        for _, name := range dropFieldNames </span><span class="cov8" title="1">{
                if _, ok := nodes[name]; ok </span><span class="cov8" title="1">{
                        drop[name] = struct{}{}
                }</span>
        }
        <span class="cov8" title="1">return drop</span>
}

// normalizeRecord drops fields and coerces _cardinalhq.timestamp to int64.
func normalizeRecord(rec map[string]any, drop map[string]struct{}) (map[string]any, error) <span class="cov8" title="1">{
        if len(drop) != 0 </span><span class="cov8" title="1">{
                for k := range drop </span><span class="cov8" title="1">{
                        delete(rec, k)
                }</span>
        }
        <span class="cov8" title="1">v, ok := rec["_cardinalhq.timestamp"]
        if !ok </span><span class="cov8" title="1">{
                return nil, errors.New("missing _cardinalhq.timestamp")
        }</span>
        <span class="cov8" title="1">switch t := v.(type) </span>{
        case int64:<span class="cov8" title="1"></span>
                // ok
        case int32:<span class="cov8" title="1">
                rec["_cardinalhq.timestamp"] = int64(t)</span>
        case float64:<span class="cov8" title="1">
                rec["_cardinalhq.timestamp"] = int64(t)</span>
        default:<span class="cov8" title="1">
                return nil, fmt.Errorf("unexpected _cardinalhq.timestamp type %T", v)</span>
        }
        <span class="cov8" title="1">return rec, nil</span>
}

// copyAll writes all rows from each handle to writer; returns total written rows.
func copyAll(
        ctx context.Context,
        open FileOpener,
        writer Writer,
        handles []*filecrunch.FileHandle,
) (int64, error) <span class="cov8" title="1">{
        var total int64
        const batchSize = 4096
        batch := make([]map[string]any, batchSize)
        for i := range batch </span><span class="cov8" title="1">{
                batch[i] = mapPool.Get().(map[string]any)
        }</span>
        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{
                for i := range batch </span><span class="cov8" title="1">{
                        mapPool.Put(batch[i])
                }</span>
        }()

        <span class="cov8" title="1">for _, h := range handles </span><span class="cov8" title="1">{
                if err := ctx.Err(); err != nil </span><span class="cov8" title="1">{
                        return total, err
                }</span>

                <span class="cov8" title="1">dropSet := computeDropSet(h.Nodes)

                r, err := open.NewGenericMapReader(h.File, h.Schema)
                if err != nil </span><span class="cov0" title="0">{
                        return total, err
                }</span>

                <span class="cov8" title="1">for </span><span class="cov8" title="1">{
                        if err := ctx.Err(); err != nil </span><span class="cov0" title="0">{
                                _ = r.Close()
                                return total, err
                        }</span>
                        <span class="cov8" title="1">n, err := r.Read(batch)
                        if n &gt; 0 </span><span class="cov8" title="1">{
                                // Normalize and write each record in the batch.
                                for i := range n </span><span class="cov8" title="1">{
                                        rec, nerr := normalizeRecord(batch[i], dropSet)
                                        if nerr != nil </span><span class="cov0" title="0">{
                                                _ = r.Close()
                                                return total, nerr
                                        }</span>
                                        <span class="cov8" title="1">if werr := writer.Write(rec); werr != nil </span><span class="cov0" title="0">{
                                                _ = r.Close()
                                                return total, werr
                                        }</span>
                                        <span class="cov8" title="1">for k := range batch[i] </span><span class="cov8" title="1">{
                                                delete(batch[i], k)
                                        }</span>
                                }
                                <span class="cov8" title="1">total += int64(n)</span>
                        }
                        <span class="cov8" title="1">if err == io.EOF </span><span class="cov8" title="1">{
                                break</span>
                        }
                        <span class="cov8" title="1">if err != nil </span><span class="cov8" title="1">{
                                _ = r.Close()
                                return total, err
                        }</span>
                }
                // non-fatal close
                <span class="cov8" title="1">_ = r.Close()</span>
        }
        <span class="cov8" title="1">return total, nil</span>
}

// basic stats from used segments
type usedStats struct {
        CountRecords int64
        SizeBytes    int64
        FirstTS      int64
        LastTS       int64
        IngestDate   int32
}

func statsFor(used []lrdb.GetLogSegmentsForCompactionRow) usedStats <span class="cov8" title="1">{
        var s usedStats
        if len(used) == 0 </span><span class="cov8" title="1">{
                return s
        }</span>
        <span class="cov8" title="1">s.FirstTS = used[0].StartTs
        for _, seg := range used </span><span class="cov8" title="1">{
                s.CountRecords += seg.RecordCount
                s.SizeBytes += seg.FileSize
                if seg.StartTs &lt; s.FirstTS </span><span class="cov8" title="1">{
                        s.FirstTS = seg.StartTs
                }</span>
                <span class="cov8" title="1">if seg.EndTs &gt; s.LastTS </span><span class="cov8" title="1">{
                        s.LastTS = seg.EndTs
                }</span>
                <span class="cov8" title="1">if seg.IngestDateint &gt; s.IngestDate </span><span class="cov8" title="1">{
                        s.IngestDate = seg.IngestDateint
                }</span>
        }
        <span class="cov8" title="1">return s</span>
}

func packSegment(
        ctx context.Context,
        ll *slog.Logger,
        tmpdir string,
        s3Client *awsclient.S3Client,
        mdb lrdb.StoreFull,
        group []lrdb.GetLogSegmentsForCompactionRow,
        sp storageprofile.StorageProfile,
        dateint int32,
) error <span class="cov0" title="0">{
        if len(group) &lt; 2 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">fetcher := objectFetcherAdapter{s3Client: s3Client}
        open := fileOpenerAdapter{}
        wf := writerFactoryAdapter{}

        opened, err := downloadAndOpen(ctx, sp, dateint, group, tmpdir, sp.Bucket, fetcher, open)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">if len(opened) &lt; 2 </span><span class="cov0" title="0">{
                ll.Info("Group has fewer than 2 usable segments; skipping",
                        slog.Int("requestedGroupSize", len(group)),
                        slog.Int("usableSegments", len(opened)))
                return nil
        }</span>

        <span class="cov0" title="0">handles := make([]*filecrunch.FileHandle, 0, len(opened))
        usedSegs := make([]lrdb.GetLogSegmentsForCompactionRow, 0, len(opened))
        objectIDs := make([]string, 0, len(opened))
        for _, o := range opened </span><span class="cov0" title="0">{
                handles = append(handles, o.Handle)
                usedSegs = append(usedSegs, o.Seg)
                objectIDs = append(objectIDs, o.ObjectID)
        }</span>

        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                for _, h := range handles </span><span class="cov0" title="0">{
                        _ = h.Close()
                        _ = os.Remove(h.File.Name())
                }</span>
        }()

        <span class="cov0" title="0">nodes, err := mergeNodes(handles)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Error merging nodes", slog.String("error", err.Error()))
                return err
        }</span>

        <span class="cov0" title="0">w, err := wf.NewWriter("logcompact", tmpdir, nodes, 0)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">writerClosed := false
        defer func() </span><span class="cov0" title="0">{
                if !writerClosed </span><span class="cov0" title="0">{
                        _, _ = w.Close()
                }</span>
        }()

        <span class="cov0" title="0">_, err = copyAll(ctx, open, w, handles)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">writeResults, err := w.Close()
        writerClosed = true
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">if len(writeResults) == 0 </span><span class="cov0" title="0">{
                ll.Info("No records written, skipping upload")
                return nil
        }</span>
        <span class="cov0" title="0">writeResult := writeResults[0]

        stats := statsFor(usedSegs)
        if writeResult.RecordCount != stats.CountRecords </span><span class="cov0" title="0">{
                return fmt.Errorf("record count mismatch: expected=%d actual=%d", stats.CountRecords, writeResult.RecordCount)
        }</span>

        <span class="cov0" title="0">fi, err := os.Stat(writeResult.FileName)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">newSegmentID := s3helper.GenerateID()
        newObjectID := helpers.MakeDBObjectID(
                sp.OrganizationID, sp.CollectorName, dateint, s3helper.HourFromMillis(stats.FirstTS), newSegmentID, "logs",
        )

        ll.Info("Uploading new file to S3",
                slog.Int64("size", fi.Size()),
                slog.String("objectID", newObjectID),
                slog.Int64("segmentID", newSegmentID),
                slog.Int64("firstTS", stats.FirstTS),
                slog.Int64("lastTS", stats.LastTS),
                slog.Int64("recordCount", writeResult.RecordCount),
                slog.Int64("fileSize", fi.Size()),
        )

        if err := s3helper.UploadS3Object(ctx, s3Client, sp.Bucket, newObjectID, writeResult.FileName); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">if err := mdb.CompactLogSegments(ctx, lrdb.CompactLogSegmentsParams{
                OrganizationID: sp.OrganizationID,
                Dateint:        dateint,
                IngestDateint:  stats.IngestDate,
                InstanceNum:    sp.InstanceNum,
                NewStartTs:     stats.FirstTS,
                NewEndTs:       stats.LastTS, // already half-open
                NewSegmentID:   newSegmentID,
                NewFileSize:    fi.Size(),
                NewRecordCount: writeResult.RecordCount,
                OldSegmentIds:  segmentIDsFrom(usedSegs),
                CreatedBy:      lrdb.CreatedByCompact,
        }); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">for _, oid := range objectIDs </span><span class="cov0" title="0">{
                if err := s3helper.ScheduleS3Delete(ctx, mdb, sp.OrganizationID, sp.InstanceNum, sp.Bucket, oid); err != nil </span><span class="cov0" title="0">{
                        ll.Error("scheduleS3Delete", slog.String("error", err.Error()))
                }</span>
        }
        <span class="cov0" title="0">ll.Info("Scheduled old segments for deletion", slog.Int("count", len(objectIDs)))
        return nil</span>
}
</pre>
		
		<pre class="file" id="file24" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package pubsub

import (
        "context"
        "errors"
        "fmt"
        "io"
        "log/slog"
        "net/http"
        "strings"

        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lrdb"
)

type pubsubCmd struct {
        sp       storageprofile.StorageProfileProvider
        workChan chan []byte
        tracer   trace.Tracer
        mdb      InqueueInserter
}

type InqueueInserter interface {
        PutInqueueWork(ctx context.Context, arg lrdb.PutInqueueWorkParams) error
}

func NewHTTPListener() (*pubsubCmd, error) <span class="cov0" title="0">{
        sp, err := storageprofile.SetupStorageProfiles()
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to setup storage profiles", slog.Any("error", err))
                return nil, fmt.Errorf("failed to setup storage profiles: %w", err)
        }</span>

        <span class="cov0" title="0">mdb, err := dbopen.LRDBStore(context.Background())
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to connect to lr database", slog.Any("error", err))
                return nil, fmt.Errorf("failed to connect to lr database: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;pubsubCmd{
                sp:       sp,
                mdb:      mdb,
                workChan: make(chan []byte, 100), // Buffered channel to handle incoming requests
                tracer:   otel.Tracer("github.com/cardinalhq/lakerunner/cmd/pubsub"),
        }, nil</span>
}

func (ps *pubsubCmd) Run(doneCtx context.Context) error <span class="cov0" title="0">{
        slog.Info("Starting pubsub service")

        srv := &amp;http.Server{
                Addr:    ":8080",
                Handler: ps,
        }

        go ps.Process(context.Background())

        go func() </span><span class="cov0" title="0">{
                if err := srv.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed </span><span class="cov0" title="0">{
                        slog.Error("Failed to start HTTP server", slog.Any("error", err))
                }</span>
        }()

        <span class="cov0" title="0">&lt;-doneCtx.Done()

        slog.Info("Shutting down pubsub service")
        if err := srv.Shutdown(context.Background()); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to shutdown HTTP server", slog.Any("error", err))
                return fmt.Errorf("failed to shutdown HTTP server: %w", err)
        }</span>

        <span class="cov0" title="0">close(ps.workChan)

        return nil</span>
}

func (ps *pubsubCmd) ServeHTTP(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        if r.Method != http.MethodPost </span><span class="cov0" title="0">{
                http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
                return
        }</span>

        <span class="cov0" title="0">r.Body = http.MaxBytesReader(w, r.Body, 1024*1024)
        body, err := io.ReadAll(r.Body)
        if err != nil </span><span class="cov0" title="0">{
                var maxBytesError *http.MaxBytesError
                if errors.As(err, &amp;maxBytesError) </span><span class="cov0" title="0">{
                        http.Error(w, "Request body too large", http.StatusRequestEntityTooLarge)
                        return
                }</span>
                <span class="cov0" title="0">http.Error(w, "Error reading request body", http.StatusInternalServerError)
                return</span>
        }

        <span class="cov0" title="0">if len(body) &gt; 0 </span><span class="cov0" title="0">{
                ps.workChan &lt;- body
        }</span>
        <span class="cov0" title="0">w.WriteHeader(http.StatusOK)</span>
}

func (ps *pubsubCmd) Process(ctx context.Context) <span class="cov0" title="0">{
        slog.Info("Starting worker to process incoming messages")

        for msg := range ps.workChan </span><span class="cov0" title="0">{
                func() </span><span class="cov0" title="0">{ // Use a closure to ensure the span is closed
                        var span trace.Span
                        ctx, span = ps.tracer.Start(ctx, "pubsubCmd.Process")
                        defer span.End()

                        if err := handleMessage(ctx, msg, ps.sp, ps.mdb); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to handle message", slog.Any("error", err))
                        }</span>
                }()
        }
}

func handleMessage(ctx context.Context, msg []byte, sp storageprofile.StorageProfileProvider, mdb InqueueInserter) error <span class="cov0" title="0">{
        if len(msg) == 0 </span><span class="cov0" title="0">{
                return fmt.Errorf("empty message received")
        }</span>

        <span class="cov0" title="0">items, err := parseS3LikeEvents(msg)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse S3-like events: %w", err)
        }</span>

        <span class="cov0" title="0">for _, item := range items </span><span class="cov0" title="0">{
                var profile storageprofile.StorageProfile
                var err error
                if strings.HasPrefix(item.ObjectID, "otel-raw/") </span><span class="cov0" title="0">{
                        profile, err = sp.GetByCollectorName(ctx, item.OrganizationID, item.CollectorName)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to get storage profile", slog.Any("error", err), slog.Any("organization_id", item.OrganizationID), slog.Int("instance_num", int(item.InstanceNum)))
                                continue</span>
                        }
                } else<span class="cov0" title="0"> if strings.HasPrefix(item.ObjectID, "db/") </span><span class="cov0" title="0">{
                        // Skip database files
                        slog.Info("Skipping database file", slog.String("objectID", item.ObjectID))
                        continue</span>
                } else<span class="cov0" title="0"> {
                        profiles, err := sp.GetStorageProfilesByBucketName(ctx, item.Bucket)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to get storage profile", slog.Any("error", err), slog.String("bucket", item.Bucket))
                                continue</span>
                        }
                        <span class="cov0" title="0">if len(profiles) != 1 </span><span class="cov0" title="0">{
                                slog.Error("Expected exactly one storage profile for bucket", slog.String("bucket", item.Bucket), slog.Int("found", len(profiles)))
                                continue</span>
                        }
                        <span class="cov0" title="0">profile = profiles[0]
                        item.OrganizationID = profile.OrganizationID
                        item.CollectorName = profile.CollectorName</span>
                }
                <span class="cov0" title="0">item.InstanceNum = profile.InstanceNum
                slog.Info("Processing item", slog.String("bucket", profile.Bucket), slog.String("object_id", item.ObjectID), slog.String("telemetry_type", item.TelemetryType))

                err = mdb.PutInqueueWork(ctx, lrdb.PutInqueueWorkParams{
                        OrganizationID: item.OrganizationID,
                        CollectorName:  item.CollectorName,
                        InstanceNum:    item.InstanceNum,
                        Bucket:         profile.Bucket,
                        ObjectID:       item.ObjectID,
                        TelemetryType:  item.TelemetryType,
                        Priority:       0,
                })
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to insert inqueue work: %w", err)
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file25" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package pubsub

import (
        "encoding/json"
        "fmt"
        "log/slog"
        "net/url"
        "strings"

        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/lrdb"
)

// s3Event is a minimal model of the incoming JSON
type s3Event struct {
        Records []struct {
                S3 struct {
                        Bucket struct {
                                Name string `json:"name"`
                        } `json:"bucket"`
                        Object struct {
                                Key string `json:"key"`
                        } `json:"object"`
                } `json:"s3"`
        } `json:"Records"`
}

func parseS3LikeEvents(raw []byte) ([]lrdb.Inqueue, error) <span class="cov0" title="0">{
        var evt s3Event
        if err := json.Unmarshal(raw, &amp;evt); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("unmarshal event: %w", err)
        }</span>

        <span class="cov0" title="0">out := make([]lrdb.Inqueue, 0, len(evt.Records))
        for _, rec := range evt.Records </span><span class="cov0" title="0">{
                key := rec.S3.Object.Key
                key, err := url.QueryUnescape(key)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to unescape key", slog.Any("error", err))
                        continue</span>
                }

                <span class="cov0" title="0">if strings.HasSuffix(key, "/") </span><span class="cov0" title="0">{
                        continue</span> // Skip "directory" keys
                }

                <span class="cov0" title="0">parts := strings.Split(key, "/")
                if parts[0] == "db" </span><span class="cov0" title="0">{
                        continue</span> // Skip database files
                }
                <span class="cov0" title="0">var orgID uuid.UUID
                var telem, collector string
                if parts[0] == "otel-raw" </span><span class="cov0" title="0">{
                        if len(parts) &lt; 4 </span><span class="cov0" title="0">{
                                slog.Error("Unexpected key format", slog.String("key", key))
                                continue</span>
                        }

                        <span class="cov0" title="0">orgID, err = uuid.Parse(parts[1])
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("invalid organization_id %q (key=%q): %w", parts[1], key, err)
                        }</span>
                        <span class="cov0" title="0">collector = parts[2]

                        fname := parts[len(parts)-1]
                        telem = fname
                        if idx := strings.Index(fname, "_"); idx != -1 </span><span class="cov0" title="0">{
                                telem = fname[:idx]
                        }</span>
                } else<span class="cov0" title="0"> if parts[0] == "logs-raw" </span><span class="cov0" title="0">{
                        telem = "logs"
                }</span> else<span class="cov0" title="0"> if parts[0] == "metrics-raw" </span><span class="cov0" title="0">{
                        telem = "metrics"
                }</span> else<span class="cov0" title="0"> if parts[0] == "traces-raw" </span><span class="cov0" title="0">{
                        telem = "traces"
                }</span> else<span class="cov0" title="0"> {
                        telem = "logs" // Default to logs for unknown prefixes
                }</span>

                <span class="cov0" title="0">iq := lrdb.Inqueue{
                        OrganizationID: orgID,
                        InstanceNum:    -1,
                        Bucket:         rec.S3.Bucket.Name,
                        ObjectID:       key,
                        TelemetryType:  telem,
                        CollectorName:  collector,
                }
                out = append(out, iq)</span>
        }
        <span class="cov0" title="0">return out, nil</span>
}
</pre>
		
		<pre class="file" id="file26" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package pubsub

import (
        "context"
        "fmt"
        "log/slog"
        "os"
        "time"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/service/sqs"
        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
)

type sqsPubsubCmd struct {
        tracer trace.Tracer
        awsMgr *awsclient.Manager
        sp     storageprofile.StorageProfileProvider
        mdb    InqueueInserter
}

func NewSQS() (*sqsPubsubCmd, error) <span class="cov0" title="0">{
        awsMgr, err := awsclient.NewManager(context.Background(),
                awsclient.WithAssumeRoleSessionName("pubsub-sqs"),
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to create AWS manager", slog.Any("error", err))
                return nil, fmt.Errorf("failed to create AWS manager: %w", err)
        }</span>

        <span class="cov0" title="0">sp, err := storageprofile.SetupStorageProfiles()
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to setup storage profiles", slog.Any("error", err))
                return nil, fmt.Errorf("failed to setup storage profiles: %w", err)
        }</span>

        <span class="cov0" title="0">mdb, err := dbopen.LRDBStore(context.Background())
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to connect to lr database", slog.Any("error", err))
                return nil, fmt.Errorf("failed to connect to lr database: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;sqsPubsubCmd{
                tracer: otel.Tracer("github.com/cardinalhq/lakerunner/cmd/pubsub/sqs"),
                awsMgr: awsMgr,
                sp:     sp,
                mdb:    mdb,
        }, nil</span>
}

func (ps *sqsPubsubCmd) Run(doneCtx context.Context) error <span class="cov0" title="0">{
        slog.Info("Starting SQS pubsub service for S3 events")

        queueURL := os.Getenv("SQS_QUEUE_URL")
        if queueURL == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("SQS_QUEUE_URL environment variable is required")
        }</span>

        <span class="cov0" title="0">region := os.Getenv("SQS_REGION")
        if region == "" </span><span class="cov0" title="0">{
                region = os.Getenv("AWS_REGION")
                if region == "" </span><span class="cov0" title="0">{
                        region = "us-west-2"
                }</span>
        }

        // Get role ARN from environment (optional)
        <span class="cov0" title="0">roleARN := os.Getenv("SQS_ROLE_ARN")

        sqsClient, err := ps.awsMgr.GetSQS(context.Background(),
                awsclient.WithSQSRole(roleARN),
                awsclient.WithSQSRegion(region),
        )
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to create SQS client", slog.Any("error", err))
                return fmt.Errorf("failed to create SQS client: %w", err)
        }</span>

        <span class="cov0" title="0">go ps.pollSQS(doneCtx, sqsClient, queueURL)

        &lt;-doneCtx.Done()

        slog.Info("Shutting down SQS pubsub service")
        return nil</span>
}

func (ps *sqsPubsubCmd) pollSQS(doneCtx context.Context, sqsClient *awsclient.SQSClient, queueURL string) <span class="cov0" title="0">{
        slog.Info("Starting SQS polling loop", slog.String("queueURL", queueURL))

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-doneCtx.Done():<span class="cov0" title="0">
                        slog.Info("SQS polling loop stopped")
                        return</span>
                default:<span class="cov0" title="0"></span>
                }

                <span class="cov0" title="0">result, err := sqsClient.Client.ReceiveMessage(doneCtx, &amp;sqs.ReceiveMessageInput{
                        QueueUrl:            aws.String(queueURL),
                        MaxNumberOfMessages: 10,
                        WaitTimeSeconds:     20,
                })
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to receive messages from SQS", slog.Any("error", err))
                        time.Sleep(5 * time.Second)
                        continue</span>
                }

                <span class="cov0" title="0">for _, message := range result.Messages </span><span class="cov0" title="0">{
                        if message.Body != nil </span><span class="cov0" title="0">{
                                err := handleMessage(context.Background(), []byte(*message.Body), ps.sp, ps.mdb)
                                if err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Failed to handle S3 event", slog.Any("error", err))
                                }</span>
                        }
                        <span class="cov0" title="0">_, err := sqsClient.Client.DeleteMessage(context.Background(), &amp;sqs.DeleteMessageInput{
                                QueueUrl:      aws.String(queueURL),
                                ReceiptHandle: message.ReceiptHandle,
                        })
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to delete SQS message", slog.Any("error", err))
                        }</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file27" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "fmt"
        "log/slog"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"

        "github.com/cardinalhq/lakerunner/cmd/pubsub"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "pubsub",
                Short: "handle pubsub events",
        }

        rootCmd.AddCommand(cmd)

        httpListenCmd := &amp;cobra.Command{
                Use:   "http",
                Short: "listen on one or more http pubsub sources",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        servicename := "pubsub-http"
                        addlAttrs := attribute.NewSet(
                                attribute.String("action", "pubsub-http"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">cmd, err := pubsub.NewHTTPListener()
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create pubsub command: %w", err)
                        }</span>

                        <span class="cov0" title="0">return cmd.Run(doneCtx)</span>
                },
        }
        <span class="cov8" title="1">cmd.AddCommand(httpListenCmd)

        sqsListenCmd := &amp;cobra.Command{
                Use:   "sqs",
                Short: "listen on one or more SQS pubsub sources",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        servicename := "pubsub-sqs"
                        addlAttrs := attribute.NewSet(
                                attribute.String("action", "pubsub-sqs"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">cmd, err := pubsub.NewSQS()
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create SQS pubsub command: %w", err)
                        }</span>
                        <span class="cov0" title="0">return cmd.Run(doneCtx)</span>
                },
        }
        <span class="cov8" title="1">cmd.AddCommand(sqsListenCmd)</span>
}
</pre>
		
		<pre class="file" id="file28" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "fmt"
        "log/slog"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        "github.com/cardinalhq/lakerunner/promql"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "query-api",
                Short: "start query-api server",
        }

        rootCmd.AddCommand(cmd)

        queryApiCmd := &amp;cobra.Command{
                Use:   "http",
                Short: "listen on one or more http endpoints",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        servicename := "query-api"
                        addlAttrs := attribute.NewSet()
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">mdb, err := dbopen.LRDBStore(context.Background())
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to connect to lr database", slog.Any("error", err))
                                return fmt.Errorf("failed to connect to lr database: %w", err)
                        }</span>

                        // Create and start worker discovery
                        <span class="cov0" title="0">workerDiscovery, err := promql.CreateWorkerDiscovery()
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to create worker discovery", slog.Any("error", err))
                                return fmt.Errorf("failed to create worker discovery: %w", err)
                        }</span>

                        <span class="cov0" title="0">if err := workerDiscovery.Start(doneCtx); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to start worker discovery", slog.Any("error", err))
                                return fmt.Errorf("failed to start worker discovery: %w", err)
                        }</span>
                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := workerDiscovery.Stop(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Failed to stop worker discovery", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">querier, err := promql.NewQuerierService(mdb, workerDiscovery)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to create querier service", slog.Any("error", err))
                                return fmt.Errorf("failed to create querier service: %w", err)
                        }</span>

                        <span class="cov0" title="0">return querier.Run(doneCtx)</span>
                },
        }
        <span class="cov8" title="1">cmd.AddCommand(queryApiCmd)</span>
}
</pre>
		
		<pre class="file" id="file29" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "fmt"
        "log/slog"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"

        "github.com/cardinalhq/lakerunner/queryworker"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "query-worker",
                Short: "start query-worker service",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        servicename := "query-worker"
                        addlAttrs := attribute.NewSet()
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">service, err := queryworker.NewService()
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to create query worker service", slog.Any("error", err))
                                return fmt.Errorf("failed to create query worker service: %w", err)
                        }</span>

                        <span class="cov0" title="0">return service.Run(doneCtx)</span>
                },
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}
</pre>
		
		<pre class="file" id="file30" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "fmt"
        "log/slog"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"
        _ "modernc.org/sqlite"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lockmgr"
        "github.com/cardinalhq/lakerunner/lrdb"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "rollup-metrics",
                Short: "Roll up metrics",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        helpers.CleanTempDir()

                        servicename := "lakerunner-rollup-metrics"
                        addlAttrs := attribute.NewSet(
                                attribute.String("signal", "metrics"),
                                attribute.String("action", "rollup"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">go diskUsageLoop(doneCtx)

                        loop, err := NewRunqueueLoopContext(doneCtx, "metrics", "rollup", servicename)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to create runqueue loop context: %w", err)
                        }</span>

                        <span class="cov0" title="0">return RunqueueLoop(loop, metricRollupItem)</span>
                },
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}

func metricRollupItem(
        ctx context.Context,
        ll *slog.Logger,
        tmpdir string,
        awsmanager *awsclient.Manager,
        sp storageprofile.StorageProfileProvider,
        mdb lrdb.StoreFull,
        inf lockmgr.Workable,
        rpfEstimate int64,
) (WorkResult, error) <span class="cov0" title="0">{
        previousFrequency, ok := rollupSources[inf.FrequencyMs()]
        if !ok </span><span class="cov0" title="0">{
                ll.Error("Unknown parent frequency, dropping rollup request", slog.Int("frequencyMs", int(inf.FrequencyMs())))
                return WorkResultSuccess, nil
        }</span>
        <span class="cov0" title="0">if !isWantedFrequency(inf.FrequencyMs()) || !isWantedFrequency(previousFrequency) </span><span class="cov0" title="0">{
                ll.Info("Skipping rollup for unwanted frequency", slog.Int("frequencyMs", int(inf.FrequencyMs())), slog.Int("previousFrequency", int(previousFrequency)))
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">profile, err := sp.Get(ctx, inf.OrganizationID(), inf.InstanceNum())
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get storage profile", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>
        <span class="cov0" title="0">if profile.Role == "" </span><span class="cov0" title="0">{
                if !profile.Hosted </span><span class="cov0" title="0">{
                        ll.Error("No role on non-hosted profile")
                        return WorkResultTryAgainLater, err
                }</span>
        }

        <span class="cov0" title="0">s3client, err := awsmanager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get S3 client", slog.Any("error", err))
                return 0, err
        }</span>

        <span class="cov0" title="0">ll.Info("Processing rollup item", slog.Int("previousFrequency", int(previousFrequency)), slog.Any("workItem", inf.AsMap()), slog.Int64("estimatedRowsPerFile", rpfEstimate))
        return metricRollupItemDo(ctx, ll, mdb, tmpdir, inf, profile, s3client, previousFrequency, rpfEstimate)</span>
}

func metricRollupItemDo(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        tmpdir string,
        inf lockmgr.Workable,
        profile storageprofile.StorageProfile,
        s3client *awsclient.S3Client,
        previousFrequency int32,
        rpfEstimate int64,
) (WorkResult, error) <span class="cov0" title="0">{
        st, et, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                return WorkResultSuccess, fmt.Errorf("invalid time range in work item: %v", inf.TsRange())
        }</span>
        <span class="cov0" title="0">sourceRows, err := mdb.GetMetricSegs(ctx, lrdb.GetMetricSegsParams{
                OrganizationID: inf.OrganizationID(),
                InstanceNum:    inf.InstanceNum(),
                Dateint:        inf.Dateint(),
                FrequencyMs:    previousFrequency,
                StartTs:        st.Time.UTC().UnixMilli(),
                EndTs:          et.Time.UTC().UnixMilli(),
        })
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get previous metric segments", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">if allRolledUp(sourceRows) </span><span class="cov0" title="0">{
                return WorkResultSuccess, nil
        }</span>

        <span class="cov0" title="0">currentRows, err := mdb.GetMetricSegs(ctx, lrdb.GetMetricSegsParams{
                OrganizationID: inf.OrganizationID(),
                InstanceNum:    inf.InstanceNum(),
                Dateint:        inf.Dateint(),
                FrequencyMs:    inf.FrequencyMs(),
                StartTs:        st.Time.UTC().UnixMilli(),
                EndTs:          et.Time.UTC().UnixMilli(),
        })
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get metric segments", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">err = rollupInterval(ctx, ll, mdb, tmpdir, inf, profile, s3client, sourceRows, currentRows, rpfEstimate)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to rollup interval", slog.Any("error", err))
                return WorkResultTryAgainLater, err
        }</span>

        <span class="cov0" title="0">return WorkResultSuccess, nil</span>
}

// rollupInterval rolls up the metric segments for a given timebox.
func rollupInterval(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        tmpdir string,
        inf lockmgr.Workable,
        profile storageprofile.StorageProfile,
        s3client *awsclient.S3Client,
        sourceRows []lrdb.MetricSeg,
        existingRowsForThisRollup []lrdb.MetricSeg,
        rpfEstimate int64,
) error <span class="cov0" title="0">{
        if len(sourceRows) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">ingest_dateint := int32(0)
        files := make([]string, 0, len(sourceRows))
        for _, row := range sourceRows </span><span class="cov0" title="0">{
                rst, _, ok := RangeBounds(row.TsRange)
                rts_dateint, _ := helpers.MSToDateintHour(rst.Int64)
                ingest_dateint = max(ingest_dateint, rts_dateint)
                if !ok </span><span class="cov0" title="0">{
                        ll.Error("Invalid time range in source row", slog.Any("tsRange", row.TsRange))
                        return fmt.Errorf("invalid time range in source row: %v", row.TsRange)
                }</span>
                <span class="cov0" title="0">dateint, hour := helpers.MSToDateintHour(rst.Int64)
                objectID := helpers.MakeDBObjectID(inf.OrganizationID(), profile.CollectorName, dateint, hour, row.SegmentID, "metrics")
                fn, downloadedSize, is404, err := s3helper.DownloadS3Object(ctx, tmpdir, s3client, profile.Bucket, objectID)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to download S3 object", slog.String("objectID", objectID), slog.Any("error", err))
                        return err
                }</span>
                <span class="cov0" title="0">if is404 </span><span class="cov0" title="0">{
                        ll.Info("S3 object not found, skipping", slog.String("objectID", objectID))
                        continue</span>
                }
                <span class="cov0" title="0">ll.Info("Downloaded S3 SOURCE", slog.String("objectID", objectID), slog.String("bucket", profile.Bucket), slog.Int64("rowFileSize", row.FileSize), slog.Int64("s3FileSize", downloadedSize))
                files = append(files, fn)</span>
        }

        <span class="cov0" title="0">if len(files) == 0 </span><span class="cov0" title="0">{
                ll.Info("No files to roll up, skipping")
                return nil
        }</span>

        <span class="cov0" title="0">startTS, endTS, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                ll.Error("Invalid time range in work item", slog.Any("tsRange", inf.TsRange()))
                return fmt.Errorf("invalid time range in work item: %v", inf.TsRange())
        }</span>

        <span class="cov0" title="0">ll.Info("Rolling up files", slog.Int("fileCount", len(files)), slog.Int("frequency", int(inf.FrequencyMs())), slog.Int64("startTS", startTS.Time.UTC().UnixMilli()), slog.Int64("endTS", endTS.Time.UTC().UnixMilli()))
        merger, err := NewTIDMerger(tmpdir, files, inf.FrequencyMs(), rpfEstimate, startTS.Time.UTC().UnixMilli(), endTS.Time.UTC().UnixMilli())
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to create TIDMerger", slog.Any("error", err))
                return fmt.Errorf("creating TIDMerger: %w", err)
        }</span>

        <span class="cov0" title="0">mergeResult, stats, err := merger.Merge()
        if stats.DatapointsOutOfRange &gt; 0 </span><span class="cov0" title="0">{
                ll.Warn("Some datapoints were out of range", slog.Int64("count", stats.DatapointsOutOfRange))
        }</span>
        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to merge files", slog.Any("error", err))
                return fmt.Errorf("merging files: %w", err)
        }</span>
        <span class="cov0" title="0">ll.Info("Merge results", slog.Any("sourceFiles", files), slog.Any("mergeResult", mergeResult))

        // now we need to update the source items to mark them as having been rolled up,
        // add our new file to the database, and remove any previous files for this timebox.
        params := lrdb.ReplaceMetricSegsParams{
                OrganizationID: inf.OrganizationID(),
                Dateint:        inf.Dateint(),
                IngestDateint:  ingest_dateint,
                InstanceNum:    inf.InstanceNum(),
                FrequencyMs:    inf.FrequencyMs(),
                Published:      true,
                Rolledup:       false,
                CreatedBy:      lrdb.CreateByRollup,
        }

        for _, row := range existingRowsForThisRollup </span><span class="cov0" title="0">{
                ll.Info("removing old metric segment", slog.Int("tidPartition", int(row.TidPartition)), slog.Int64("segmentID", row.SegmentID))
                params.OldRecords = append(params.OldRecords, lrdb.ReplaceMetricSegsOld{
                        TidPartition: row.TidPartition,
                        SegmentID:    row.SegmentID,
                })
        }</span>

        <span class="cov0" title="0">st, et, ok := RangeBounds(inf.TsRange())
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid time range in work item: %v", inf.TsRange())
        }</span>

        <span class="cov0" title="0">dateint, hour := helpers.MSToDateintHour(st.Time.UTC().UnixMilli())
        for tidPartition, result := range mergeResult </span><span class="cov0" title="0">{
                segmentID := s3helper.GenerateID()
                newObjectID := helpers.MakeDBObjectID(inf.OrganizationID(), profile.CollectorName, dateint, hour, segmentID, "metrics")
                ll.Info("Uploading to S3", slog.String("objectID", newObjectID), slog.String("bucket", profile.Bucket))
                err = s3helper.UploadS3Object(ctx, s3client, profile.Bucket, newObjectID, result.FileName)
                if err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to upload new S3 object", slog.String("objectID", newObjectID), slog.Any("error", err))
                        return fmt.Errorf("uploading new S3 object: %w", err)
                }</span>
                <span class="cov0" title="0">ll.Info("adding new metric segment", slog.Int("tidPartition", int(tidPartition)), slog.Int64("segmentID", segmentID))
                params.NewRecords = append(params.NewRecords, lrdb.ReplaceMetricSegsNew{
                        TidPartition: int16(tidPartition),
                        SegmentID:    segmentID,
                        StartTs:      st.Time.UTC().UnixMilli(),
                        EndTs:        et.Time.UTC().UnixMilli(),
                        RecordCount:  result.RecordCount,
                        FileSize:     result.FileSize,
                })</span>
        }

        <span class="cov0" title="0">if err := mdb.ReplaceMetricSegs(ctx, params); err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to replace metric segments", slog.Any("error", err))
                return fmt.Errorf("replacing metric segments: %w", err)
        }</span>
        <span class="cov0" title="0">ll.Info("Replaced metric segments")

        // mark the input rows as having been rolled up.
        newlyRolled := []lrdb.BatchMarkMetricSegsRolledupParams{}
        for _, row := range sourceRows </span><span class="cov0" title="0">{
                if row.Rolledup </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">newlyRolled = append(newlyRolled, lrdb.BatchMarkMetricSegsRolledupParams{
                        OrganizationID: row.OrganizationID,
                        Dateint:        row.Dateint,
                        FrequencyMs:    row.FrequencyMs,
                        SegmentID:      row.SegmentID,
                        InstanceNum:    row.InstanceNum,
                        TidPartition:   row.TidPartition,
                })</span>
        }
        <span class="cov0" title="0">if len(newlyRolled) &gt; 0 </span><span class="cov0" title="0">{
                result := mdb.BatchMarkMetricSegsRolledup(ctx, newlyRolled)
                result.Exec(func(i int, err error) </span><span class="cov0" title="0">{
                        if err != nil </span><span class="cov0" title="0">{
                                ll.Error("Failed to mark metric segments as rolled up", slog.Int("index", i), slog.Any("error", err), slog.Any("record", newlyRolled[i]))
                        }</span>
                })
        }

        <span class="cov0" title="0">if err := queueMetricCompaction(ctx, mdb, qmcFromWorkable(inf)); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("queueing metric compaction: %w", err)
        }</span>
        <span class="cov0" title="0">if err := queueMetricRollup(ctx, mdb, qmcFromWorkable(inf)); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("queueing metric rollup: %w", err)
        }</span>

        // now delete the old files from S3.
        <span class="cov0" title="0">for _, row := range existingRowsForThisRollup </span><span class="cov0" title="0">{
                rst, _, ok := RangeBounds(row.TsRange)
                if !ok </span><span class="cov0" title="0">{
                        ll.Error("Invalid time range in existing row", slog.Any("tsRange", row.TsRange))
                        continue</span>
                }
                <span class="cov0" title="0">dateint, hour := helpers.MSToDateintHour(rst.Int64)
                oid := helpers.MakeDBObjectID(inf.OrganizationID(), profile.CollectorName, dateint, hour, row.SegmentID, "metrics")
                ll.Info("Deleting old S3 object", slog.String("objectID", oid))
                if err := s3helper.ScheduleS3Delete(ctx, mdb, profile.OrganizationID, profile.InstanceNum, profile.Bucket, oid); err != nil </span><span class="cov0" title="0">{
                        ll.Error("scheduleS3Delete", slog.String("error", err.Error()))
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// boxesForRange returns a list of timebox IDs for the given start and end timestamps and frequency.
func boxesForRange(startTs, endTs int64, frequencyMs int32) []int64 <span class="cov8" title="1">{
        if startTs &gt; endTs || frequencyMs &lt;= 0 </span><span class="cov8" title="1">{
                return []int64{}
        }</span>
        <span class="cov8" title="1">firstBox := startTs / int64(frequencyMs)
        lastBox := endTs / int64(frequencyMs)
        nBoxes := lastBox - firstBox + 1
        boxes := make([]int64, nBoxes)
        for n := range nBoxes </span><span class="cov8" title="1">{
                boxes[n] = firstBox + n
        }</span>
        <span class="cov8" title="1">return boxes</span>
}
</pre>
		
		<pre class="file" id="file31" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "os"
        "time"

        "github.com/spf13/cobra"
)

const (
        workSleepTime  = 2 * time.Second
        maxWorkRetries = 100
        targetFileSize = 1_100_000
)

// rootCmd represents the base command when called without any subcommands
var rootCmd = &amp;cobra.Command{
        Use:   "lakerunner",
        Short: "Process s3 signal storage",
        Long:  `Read and process signals written to s3 by the CardinalHQ Open Telemetry Collector's S3 exporter.`,
}

func init() <span class="cov8" title="1">{
        rootCmd.AddCommand(debugCmd)
}</span>

// Execute adds all child commands to the root command and sets flags appropriately.
// This is called by main.main(). It only needs to happen once to the rootCmd.
func Execute() <span class="cov0" title="0">{
        err := rootCmd.Execute()
        if err != nil </span><span class="cov0" title="0">{
                os.Exit(1)
        }</span>
}
</pre>
		
		<pre class="file" id="file32" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "os"
        "os/signal"
        "syscall"
)

// handleSignals is a utility function that sets up a context that will be cancelled
// when an interrupt signal (SIGINT) or termination signal (SIGTERM) is received.
// This allows the keyboard ^C or k8s to gracefully shut down the application.
func handleSignals(ctx context.Context) (context.Context, context.CancelFunc) <span class="cov0" title="0">{
        return signal.NotifyContext(ctx, os.Interrupt, syscall.SIGTERM)
}</span>
</pre>
		
		<pre class="file" id="file33" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "fmt"

        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/DataDog/sketches-go/ddsketch/mapping"
        "github.com/DataDog/sketches-go/ddsketch/store"
)

func EncodeSketch(sketch *ddsketch.DDSketch) []byte <span class="cov8" title="1">{
        var buf []byte
        sketch.Encode(&amp;buf, false)
        return buf
}</span>

func DecodeSketch(data []byte) (*ddsketch.DDSketch, error) <span class="cov8" title="1">{
        m, err := mapping.NewLogarithmicMapping(0.01)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">sk, err := ddsketch.DecodeDDSketch(data, store.DefaultProvider, m)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return sk, nil</span>
}

func Merge(sketch *ddsketch.DDSketch, other *ddsketch.DDSketch) error <span class="cov0" title="0">{
        return sketch.MergeWith(other)
}</span>

func MergeEncodedSketch(a, b []byte) ([]byte, error) <span class="cov0" title="0">{
        skA, err := DecodeSketch(a)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("decoding sketch A: %w", err)
        }</span>
        <span class="cov0" title="0">skB, err := DecodeSketch(b)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("decoding sketch B: %w", err)
        }</span>
        <span class="cov0" title="0">if err := Merge(skA, skB); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("merging sketches: %w", err)
        }</span>
        <span class="cov0" title="0">return EncodeSketch(skA), nil</span>
}
</pre>
		
		<pre class="file" id="file34" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "fmt"
        "log/slog"

        "github.com/spf13/cobra"
        "go.opentelemetry.io/otel/attribute"

        "github.com/cardinalhq/lakerunner/cmd/sweeper"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "sweeper",
                Short: "Do general cleanup tasks",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        servicename := "lakerunner-sweeper"
                        addlAttrs := attribute.NewSet(
                                attribute.String("action", "sweep"),
                        )
                        doneCtx, doneFx, err := setupTelemetry(servicename, &amp;addlAttrs)
                        if err != nil </span><span class="cov0" title="0">{
                                return fmt.Errorf("failed to setup telemetry: %w", err)
                        }</span>

                        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                                if err := doneFx(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Error shutting down telemetry", slog.Any("error", err))
                                }</span>
                        }()

                        <span class="cov0" title="0">cmd := sweeper.New(myInstanceID, servicename)
                        return cmd.Run(doneCtx)</span>
                },
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}
</pre>
		
		<pre class="file" id="file35" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package sweeper

import (
        "context"
        "errors"
        "log/slog"
        "os"
        "sync"
        "time"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/awsclient/s3helper"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lrdb"
)

const (
        gcBatchLimit int32         = 1000
        gcBatchDelay time.Duration = 500 * time.Millisecond
        gcPeriod     time.Duration = time.Hour
        gcCutoffAge  time.Duration = 10 * 24 * time.Hour
)

type sweeper struct {
        instanceID            int64
        assumeRoleSessionName string
        sp                    storageprofile.StorageProfileProvider
}

func New(instanceID int64, assumeRoleSessionName string) *sweeper <span class="cov0" title="0">{
        sp, err := storageprofile.SetupStorageProfiles()
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to setup storage profiles", slog.Any("error", err))
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">return &amp;sweeper{
                instanceID:            instanceID,
                assumeRoleSessionName: assumeRoleSessionName,
                sp:                    sp,
        }</span>
}

func (cmd *sweeper) Run(doneCtx context.Context) error <span class="cov0" title="0">{
        ctx, cancel := context.WithCancel(doneCtx)
        defer cancel()

        mdb, err := dbopen.LRDBStore(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">awsmanager, err := awsclient.NewManager(ctx,
                awsclient.WithAssumeRoleSessionName(cmd.assumeRoleSessionName),
        )
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">slog.Info("Starting sweeper", slog.Int64("instanceID", cmd.instanceID))

        var wg sync.WaitGroup
        errCh := make(chan error, 3)

        // Aggressive object delete loop
        wg.Add(1)
        go func() </span><span class="cov0" title="0">{
                defer wg.Done()
                if err := objectCleanerLoop(ctx, slog.Default(), cmd.sp, mdb, awsmanager); err != nil &amp;&amp; !errors.Is(err, context.Canceled) </span><span class="cov0" title="0">{
                        errCh &lt;- err
                }</span>
        }()

        // Periodic: workqueue expiry
        <span class="cov0" title="0">wg.Add(1)
        go func() </span><span class="cov0" title="0">{
                defer wg.Done()
                if err := periodicLoop(ctx, time.Minute, func(c context.Context) error </span><span class="cov0" title="0">{
                        return runWorkqueueExpiry(c, slog.Default(), mdb)
                }</span>); err != nil &amp;&amp; !errors.Is(err, context.Canceled) <span class="cov0" title="0">{
                        errCh &lt;- err
                }</span>
        }()

        // Periodic: inqueue expiry
        <span class="cov0" title="0">wg.Add(1)
        go func() </span><span class="cov0" title="0">{
                defer wg.Done()
                if err := periodicLoop(ctx, time.Minute, func(c context.Context) error </span><span class="cov0" title="0">{
                        return runInqueueExpiry(c, slog.Default(), mdb)
                }</span>); err != nil &amp;&amp; !errors.Is(err, context.Canceled) <span class="cov0" title="0">{
                        errCh &lt;- err
                }</span>
        }()

        // Periodic: workqueue GC
        <span class="cov0" title="0">wg.Add(1)
        go func() </span><span class="cov0" title="0">{
                defer wg.Done()
                if err := workqueueGCLoop(ctx, slog.Default(), mdb); err != nil &amp;&amp; !errors.Is(err, context.Canceled) </span><span class="cov0" title="0">{
                        errCh &lt;- err
                }</span>
        }()

        // Wait for cancellation or the first hard error
        <span class="cov0" title="0">select </span>{
        case &lt;-ctx.Done():<span class="cov0" title="0"></span>
                // graceful shutdown
        case err := &lt;-errCh:<span class="cov0" title="0">
                cancel()
                wg.Wait()
                return err</span>
        }
        <span class="cov0" title="0">wg.Wait()
        return ctx.Err()</span>
}

// Runs f immediately, then on a ticker every period. Never more than once per period.
func periodicLoop(ctx context.Context, period time.Duration, f func(context.Context) error) error <span class="cov0" title="0">{
        if err := f(ctx); err != nil &amp;&amp; !errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                slog.Error("periodic task error", slog.Any("error", err))
        }</span>

        <span class="cov0" title="0">t := time.NewTicker(period)
        defer t.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                case &lt;-t.C:<span class="cov0" title="0">
                        if err := f(ctx); err != nil &amp;&amp; !errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                                slog.Error("periodic task error", slog.Any("error", err))
                                // keep going; periodic tasks should be resilient
                        }</span>
                }
        }
}

// Aggressive loop for object cleanup.
// If work was done: tiny delay; else a slightly longer pause. Errors are logged and retried.
func objectCleanerLoop(ctx context.Context, ll *slog.Logger, sp storageprofile.StorageProfileProvider, mdb lrdb.StoreFull, awsmanager *awsclient.Manager) error <span class="cov0" title="0">{
        const (
                delayIfNoWork = 5 * time.Second
                delayIfError  = 5 * time.Second
        )
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                default:<span class="cov0" title="0"></span>
                }

                <span class="cov0" title="0">didWork, err := runObjCleaner(ctx, ll, sp, mdb, awsmanager)
                switch </span>{
                case err != nil:<span class="cov0" title="0">
                        ll.Error("Failed to run object cleaner", slog.Any("error", err))
                        if stop := sleepCtx(ctx, delayIfError); stop </span><span class="cov0" title="0">{
                                return ctx.Err()
                        }</span>
                case didWork:<span class="cov0" title="0">
                        // run right away again
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                return ctx.Err()</span>
                        default:<span class="cov0" title="0"></span>
                        }
                default:<span class="cov0" title="0">
                        if stop := sleepCtx(ctx, delayIfNoWork); stop </span><span class="cov0" title="0">{
                                return ctx.Err()
                        }</span>
                }
        }
}

func sleepCtx(ctx context.Context, d time.Duration) bool <span class="cov0" title="0">{
        t := time.NewTimer(d)
        defer t.Stop()
        select </span>{
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return true</span>
        case &lt;-t.C:<span class="cov0" title="0">
                return false</span>
        }
}

func runObjCleaner(ctx context.Context, ll *slog.Logger, sp storageprofile.StorageProfileProvider, mdb lrdb.StoreFull, awsmanager *awsclient.Manager) (bool, error) <span class="cov0" title="0">{
        const maxrows = 1000
        objs, err := mdb.ObjectCleanupGet(ctx, maxrows)
        if err != nil </span><span class="cov0" title="0">{
                if errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                        return false, nil
                }</span>
                <span class="cov0" title="0">return false, err</span>
        }
        <span class="cov0" title="0">if len(objs) == 0 </span><span class="cov0" title="0">{
                return false, nil
        }</span>

        <span class="cov0" title="0">didwork := len(objs) == maxrows

        jobs := make(chan lrdb.ObjectCleanupGetRow, len(objs))
        var wg sync.WaitGroup
        for range 10 </span><span class="cov0" title="0">{
                wg.Add(1)
                go func() </span><span class="cov0" title="0">{
                        defer wg.Done()
                        for obj := range jobs </span><span class="cov0" title="0">{
                                cleanupObj(ctx, ll, sp, mdb, awsmanager, obj)
                        }</span>
                }()
        }
        <span class="cov0" title="0">for _, obj := range objs </span><span class="cov0" title="0">{
                jobs &lt;- obj
        }</span>
        <span class="cov0" title="0">close(jobs)
        wg.Wait()

        return didwork, nil</span>
}

func cleanupObj(ctx context.Context, ll *slog.Logger, sp storageprofile.StorageProfileProvider, mdb lrdb.StoreFull, awsmanager *awsclient.Manager, obj lrdb.ObjectCleanupGetRow) <span class="cov0" title="0">{
        profile, err := sp.Get(ctx, obj.OrganizationID, obj.InstanceNum)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get storage profile", slog.Any("error", err), slog.String("objectID", obj.ObjectID))
                failWork(ctx, ll, mdb, obj.ID)
                return
        }</span>
        <span class="cov0" title="0">if profile.Role == "" &amp;&amp; !profile.Hosted </span><span class="cov0" title="0">{
                ll.Error("No role on non-hosted profile", slog.String("objectID", obj.ObjectID))
                failWork(ctx, ll, mdb, obj.ID)
                return
        }</span>

        <span class="cov0" title="0">s3client, err := awsmanager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to get S3 client", slog.Any("error", err))
                failWork(ctx, ll, mdb, obj.ID)
                return
        }</span>

        <span class="cov0" title="0">if err := s3helper.DeleteS3Object(ctx, s3client, profile.Bucket, obj.ObjectID); err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to delete S3 object", slog.Any("error", err), slog.String("objectID", obj.ObjectID))
                failWork(ctx, ll, mdb, obj.ID)
                return
        }</span>

        <span class="cov0" title="0">if err := mdb.ObjectCleanupComplete(ctx, obj.ID); err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to mark object cleanup complete", slog.Any("error", err), slog.String("objectID", obj.ObjectID))
                failWork(ctx, ll, mdb, obj.ID)
                return
        }</span>
        <span class="cov0" title="0">ll.Info("Successfully cleaned up object", slog.Any("request", obj))</span>
}

func failWork(ctx context.Context, ll *slog.Logger, mdb lrdb.StoreFull, id uuid.UUID) <span class="cov0" title="0">{
        if err := mdb.ObjectCleanupFail(ctx, id); err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to mark object cleanup failed", slog.Any("error", err), slog.String("objectID", id.String()))
        }</span>
}

func runWorkqueueExpiry(ctx context.Context, ll *slog.Logger, mdb lrdb.StoreFull) error <span class="cov0" title="0">{
        expired, err := mdb.WorkQueueCleanup(ctx)
        if err != nil </span><span class="cov0" title="0">{
                if errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov0" title="0">ll.Error("Failed to expire objects", slog.Any("error", err))
                return err</span>
        }
        <span class="cov0" title="0">for _, obj := range expired </span><span class="cov0" title="0">{
                ll.Info("Expired work/lock", slog.Any("work", obj))
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func runInqueueExpiry(ctx context.Context, ll *slog.Logger, mdb lrdb.StoreFull) error <span class="cov0" title="0">{
        if err := mdb.CleanupInqueueWork(ctx); err != nil </span><span class="cov0" title="0">{
                if errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov0" title="0">ll.Error("Failed to expire objects", slog.Any("error", err))
                return err</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func workqueueGCLoop(ctx context.Context, ll *slog.Logger, mdb lrdb.StoreFull) error <span class="cov0" title="0">{
        runOnce := func() </span><span class="cov0" title="0">{
                cutoff := time.Now().Add(-gcCutoffAge).UTC()

                for </span><span class="cov0" title="0">{
                        if ctx.Err() != nil </span><span class="cov0" title="0">{
                                return
                        }</span>

                        <span class="cov0" title="0">deleted, err := mdb.WorkQueueGC(ctx, lrdb.WorkQueueGCParams{
                                Cutoff:  cutoff,
                                Maxrows: gcBatchLimit,
                        })
                        if err != nil </span><span class="cov0" title="0">{
                                ll.Error("WorkQueueGC failed", slog.Any("error", err))
                                return
                        }</span>

                        <span class="cov0" title="0">if deleted == 0 </span><span class="cov0" title="0">{
                                return
                        }</span>

                        <span class="cov0" title="0">ll.Info("WorkQueueGC deleted rows", slog.Int("deleted", int(deleted)))

                        if deleted &lt; gcBatchLimit </span><span class="cov0" title="0">{
                                return
                        }</span>

                        <span class="cov0" title="0">if sleepCtx(ctx, gcBatchDelay) </span><span class="cov0" title="0">{
                                return
                        }</span>
                }
        }

        <span class="cov0" title="0">runOnce()

        t := time.NewTicker(gcPeriod)
        defer t.Stop()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                case &lt;-t.C:<span class="cov0" title="0">
                        runOnce()</span>
                }
        }
}
</pre>
		
		<pre class="file" id="file36" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "fmt"
        "os"
        "runtime"
        "strconv"
        "strings"

        "github.com/spf13/cobra"
)

func init() <span class="cov8" title="1">{
        cmd := &amp;cobra.Command{
                Use:   "sysinfo",
                Short: "Print Go runtime + cgroup limits &amp; sanity-check alignment",
                RunE: func(_ *cobra.Command, _ []string) error </span><span class="cov0" title="0">{
                        return runSysinfo()
                }</span>,
        }

        <span class="cov8" title="1">rootCmd.AddCommand(cmd)</span>
}

func runSysinfo() error <span class="cov0" title="0">{
        // 1) Go runtime basics
        numHost := runtime.NumCPU()
        gomax := runtime.GOMAXPROCS(0)
        gogc := os.Getenv("GOGC")
        if gogc == "" </span><span class="cov0" title="0">{
                gogc = "&lt;unset&gt;"
        }</span>
        <span class="cov0" title="0">gomem := os.Getenv("GOMEMLIMIT")
        if gomem == "" </span><span class="cov0" title="0">{
                gomem = "&lt;unset&gt;"
        }</span>

        <span class="cov0" title="0">fmt.Println("=== Go Runtime ===")
        fmt.Printf("  GOOS:           %s\n", runtime.GOOS)
        fmt.Printf("  GOARCH:         %s\n", runtime.GOARCH)
        fmt.Printf("  NumCPU (host):  %d\n", numHost)
        fmt.Printf("  GOMAXPROCS:     %d\n", gomax)
        fmt.Printf("  GOGC:           %s\n", gogc)
        fmt.Printf("  GOMEMLIMIT:     %s\n", gomem)

        // 2) cgroup CPU quota
        quotaCores, rawQuota, err := getCPUQuotaCores()
        fmt.Println("\n=== cgroup CPU quota ===")
        if err != nil </span><span class="cov0" title="0">{
                fmt.Printf("  error reading quota: %v\n", err)
        }</span> else<span class="cov0" title="0"> if quotaCores &lt;= 0 </span><span class="cov0" title="0">{
                fmt.Printf("  none (unlimited) — raw: %q\n", rawQuota)
        }</span> else<span class="cov0" title="0"> {
                fmt.Printf("  %.2f cores  — raw: %q\n", quotaCores, rawQuota)
        }</span>

        // 3) sanity checks
        <span class="cov0" title="0">fmt.Println("\n=== Config sanity check ===")
        // 3a) CPU vs GOMAXPROCS
        if quotaCores &gt; 0 </span><span class="cov0" title="0">{
                if gomax == numHost </span><span class="cov0" title="0">{
                        fmt.Printf("⚠️  GOMAXPROCS=%d equals host NumCPU=%d; quota not applied\n", gomax, numHost)
                }</span> else<span class="cov0" title="0"> if float64(gomax) &gt; quotaCores </span><span class="cov0" title="0">{
                        fmt.Printf("⚠️  GOMAXPROCS=%d exceeds container quota of %.2f cores\n", gomax, quotaCores)
                }</span>
        }

        // 3b) GOGC set?
        <span class="cov0" title="0">if gogc == "&lt;unset&gt;" </span><span class="cov0" title="0">{
                fmt.Println("⚠️  GOGC is unset; using default=100 (you may want GOGC=50 or lower)")
        }</span>

        // 3c) GOMEMLIMIT set?
        <span class="cov0" title="0">if gomem == "&lt;unset&gt;" </span><span class="cov0" title="0">{
                fmt.Println("⚠️  GOMEMLIMIT is unset; no heap cap (you may want to set this below your pod memory limit)")
        }</span>

        // 4) Go memory snapshot
        <span class="cov0" title="0">var ms runtime.MemStats
        runtime.ReadMemStats(&amp;ms)
        fmt.Println("\n=== Go Memory Stats (MiB) ===")
        fmt.Printf("  HeapAlloc:  %6d\n", ms.HeapAlloc/1024/1024)
        fmt.Printf("  HeapSys:    %6d\n", ms.HeapSys/1024/1024)
        fmt.Printf("  StackInuse:%6d\n", ms.StackInuse/1024/1024)
        fmt.Printf("  Sys:        %6d\n", ms.Sys/1024/1024)
        fmt.Printf("  NumGC:      %6d\n", ms.NumGC)

        return nil</span>
}

// getCPUQuotaCores reads cgroup v2 cpu.max or v1 cpu.cfs_* and returns
// the effective quota in cores (e.g. 150000/100000 = 1.5 cores).
// rawQuota is the raw file contents for diagnostic.
func getCPUQuotaCores() (cores float64, rawQuota string, err error) <span class="cov0" title="0">{
        // Try cgroup v2
        const v2path = "/sys/fs/cgroup/cpu.max"
        if data, e := os.ReadFile(v2path); e == nil </span><span class="cov0" title="0">{
                raw := strings.TrimSpace(string(data))
                rawQuota = raw
                parts := strings.Fields(raw)
                if len(parts) &gt;= 2 </span><span class="cov0" title="0">{
                        if parts[0] == "max" </span><span class="cov0" title="0">{
                                return 0, raw, nil
                        }</span>
                        <span class="cov0" title="0">q, err1 := strconv.ParseFloat(parts[0], 64)
                        p, err2 := strconv.ParseFloat(parts[1], 64)
                        if err1 == nil &amp;&amp; err2 == nil &amp;&amp; p &gt; 0 </span><span class="cov0" title="0">{
                                return q / p, raw, nil
                        }</span>
                }
                <span class="cov0" title="0">return 0, rawQuota, fmt.Errorf("unexpected format")</span>
        }

        // Fallback to cgroup v1
        <span class="cov0" title="0">rawQ, errQ := os.ReadFile("/sys/fs/cgroup/cpu/cpu.cfs_quota_us")
        rawP, errP := os.ReadFile("/sys/fs/cgroup/cpu/cpu.cfs_period_us")
        if errQ == nil &amp;&amp; errP == nil </span><span class="cov0" title="0">{
                sq := strings.TrimSpace(string(rawQ))
                sp := strings.TrimSpace(string(rawP))
                rawQuota = fmt.Sprintf("%s %s", sq, sp)
                if sq != "-1" </span><span class="cov0" title="0">{
                        q, err1 := strconv.ParseFloat(sq, 64)
                        p, err2 := strconv.ParseFloat(sp, 64)
                        if err1 == nil &amp;&amp; err2 == nil &amp;&amp; p &gt; 0 </span><span class="cov0" title="0">{
                                return q / p, rawQuota, nil
                        }</span>
                }
                <span class="cov0" title="0">return 0, rawQuota, nil</span>
        }

        <span class="cov0" title="0">return 0, "", fmt.Errorf("no cgroup CPU quota files available")</span>
}
</pre>
		
		<pre class="file" id="file37" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "fmt"
        "log/slog"
        "os"
        "runtime"
        "time"

        "github.com/cardinalhq/oteltools/pkg/telemetry"
        slogmulti "github.com/samber/slog-multi"
        "go.opentelemetry.io/contrib/bridges/otelslog"
        "go.opentelemetry.io/contrib/instrumentation/host"
        iruntime "go.opentelemetry.io/contrib/instrumentation/runtime"
        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/metric"

        "github.com/cardinalhq/lakerunner/internal/idgen"
)

var (
        commonAttributes attribute.Set

        meter  = otel.Meter("github.com/cardinalhq/lakerunner")
        tracer = otel.Tracer("github.com/cardinalhq/lakerunner")

        myInstanceID int64

        dbExecDuration         metric.Float64Histogram
        inqueueFetchDuration   metric.Float64Histogram
        inqueueDuration        metric.Float64Histogram
        workqueueDuration      metric.Float64Histogram
        workqueueFetchDuration metric.Float64Histogram
        workqueueLag           metric.Float64Histogram
        manualGCHistogram      metric.Float64Histogram

        // existsGauge is a gauge that indicates if the service is running (1) or not (0).
        // It is set to 1, and never changes.  This is unused, but is here to ensure
        // that the counter is not murdered by the garbage collector.
        // nolint:unused
        existsGauge metric.Int64Gauge
)

func setupTelemetry(servicename string, addlAttrs *attribute.Set) (context.Context, func() error, error) <span class="cov0" title="0">{
        myInstanceID = idgen.DefaultFlakeGenerator.NextID()

        // Catch signals to stop the process as gracefully as possible.
        doneCtx, doneCancel := handleSignals(context.Background())

        f := func() error </span><span class="cov0" title="0">{
                return nil
        }</span>

        // make all the counters, gauges, etc that everyone is likely to use.
        <span class="cov0" title="0">setupGlobalMetrics()

        attrs := []attribute.KeyValue{
                attribute.Int64("instanceID", myInstanceID),
        }
        if addlAttrs != nil </span><span class="cov0" title="0">{
                iter := addlAttrs.Iter()
                for iter.Next() </span><span class="cov0" title="0">{
                        attrs = append(attrs, iter.Attribute())
                }</span>
        }
        <span class="cov0" title="0">commonAttributes = attribute.NewSet(attrs...)

        if os.Getenv("OTEL_SERVICE_NAME") != "" &amp;&amp; os.Getenv("ENABLE_OTLP_TELEMETRY") == "true" </span><span class="cov0" title="0">{
                slog.Info("OpenTelemetry exporting enabled")
                slog.SetDefault(slog.New(slogmulti.Fanout(
                        slog.NewTextHandler(os.Stdout, nil),
                        otelslog.NewHandler(servicename),
                )).With(
                        slog.String("service", servicename),
                        slog.Int64("instanceID", myInstanceID),
                ))

                otelShutdown, err := telemetry.SetupOTelSDK(doneCtx)
                if err != nil </span><span class="cov0" title="0">{
                        return doneCtx, nil, fmt.Errorf("failed to setup OpenTelemetry SDK: %w", err)
                }</span>

                <span class="cov0" title="0">if err := iruntime.Start(iruntime.WithMinimumReadMemStatsInterval(time.Second * 10)); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("failed to start runtime metrics", "error", err.Error())
                }</span>

                <span class="cov0" title="0">if err := host.Start(); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("failed to start host metrics", "error", err.Error())
                }</span>

                <span class="cov0" title="0">f = func() error </span><span class="cov0" title="0">{
                        defer doneCancel()
                        slog.Info("Shutting down OpenTelemetry SDK")
                        ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
                        defer cancel()
                        return otelShutdown(ctx)
                }</span>
        }

        <span class="cov0" title="0">return doneCtx, f, nil</span>
}

func setupGlobalMetrics() <span class="cov0" title="0">{
        m, err := meter.Float64Histogram(
                "lakerunner.workqueue.request.delay",
                metric.WithUnit("ms"),
                metric.WithDescription("The delay in ms for a request for new work to be returned"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create queue.request.delay histogram: %w", err))</span>
        }
        <span class="cov0" title="0">workqueueFetchDuration = m

        m, err = meter.Float64Histogram(
                "lakerunner.workqueue.duration",
                metric.WithUnit("s"),
                metric.WithDescription("The duration in seconds for a work item to be processed"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create work.duration histogram: %w", err))</span>
        }
        <span class="cov0" title="0">workqueueDuration = m

        m, err = meter.Float64Histogram(
                "lakerunner.inqueue.request.delay",
                metric.WithUnit("s"),
                metric.WithDescription("The delay in seconds for a request for new inqueue work to be returned"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create inqueue.request.delay histogram: %w", err))</span>
        }
        <span class="cov0" title="0">inqueueFetchDuration = m

        m, err = meter.Float64Histogram(
                "lakerunner.inqueue.duration",
                metric.WithUnit("s"),
                metric.WithDescription("The duration in seconds for an inqueue item to be processed"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create inqueue.duration histogram: %w", err))</span>
        }
        <span class="cov0" title="0">inqueueDuration = m

        m, err = meter.Float64Histogram(
                "lakerunner.db.exec.duration",
                metric.WithUnit("s"),
                metric.WithDescription("The duration in seconds for a database update to be processed"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create db.update.duration histogram: %w", err))</span>
        }
        <span class="cov0" title="0">dbExecDuration = m

        m, err = meter.Float64Histogram(
                "lakerunner.workqueue.lag",
                metric.WithUnit("s"),
                metric.WithDescription("The lag in seconds for a work item to be processed in the work queue"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create workqueue.lag histogram: %w", err))</span>
        }
        <span class="cov0" title="0">workqueueLag = m

        m, err = meter.Float64Histogram(
                "lakerunner.manual_gc.duration",
                metric.WithDescription("Duration of manual garbage collection in seconds"),
                metric.WithUnit("s"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create manual_gc.duration histogram: %w", err))</span>
        }
        <span class="cov0" title="0">manualGCHistogram = m

        mg, err := meter.Int64Gauge(
                "lakerunner.exists",
                metric.WithDescription("Indicates if the service is running (1) or not (0)"),
        )
        if err != nil </span><span class="cov0" title="0">{
                panic(fmt.Errorf("failed to create exists.gauge: %w", err))</span>
        }
        <span class="cov0" title="0">existsGauge = mg
        mg.Record(context.Background(), 1, metric.WithAttributeSet(commonAttributes))</span>
}

func gc() <span class="cov0" title="0">{
        n := time.Now()
        runtime.GC()
        manualGCHistogram.Record(context.Background(), time.Since(n).Seconds(), metric.WithAttributeSet(commonAttributes))
}</span>
</pre>
		
		<pre class="file" id="file38" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        mapset "github.com/deckarep/golang-set/v2"

        "github.com/cardinalhq/lakerunner/internal/buffet"
)

type TidAccumulatorProvider struct{}

func (p *TidAccumulatorProvider) NewAccumulator() buffet.StatsAccumulator <span class="cov8" title="1">{
        return NewTidAccumulator()
}</span>

type TidAccumulator struct {
        set mapset.Set[int64]
}

func NewTidAccumulator() *TidAccumulator <span class="cov8" title="1">{
        return &amp;TidAccumulator{
                set: mapset.NewSet[int64](),
        }
}</span>

func (a *TidAccumulator) Add(row map[string]any) <span class="cov8" title="1">{
        if tid, ok := row["_cardinalhq.tid"].(int64); ok </span><span class="cov8" title="1">{
                a.set.Add(tid)
        }</span>
}

type TidAccumulatorResult struct {
        Cardinality int // number of unique TIDs
}

func (a *TidAccumulator) Finalize() any <span class="cov8" title="1">{
        return TidAccumulatorResult{
                Cardinality: a.set.Cardinality(),
        }
}</span>
</pre>
		
		<pre class="file" id="file39" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "errors"
        "fmt"
        "io"
        "log/slog"
        "math"

        "slices"

        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/parquet-go/parquet-go"

        "github.com/cardinalhq/lakerunner/internal/buffet"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
)

// TIDMerger rolls up multiple Parquet files into multiple files.
// It is expected that the files are already sorted by TID, so
// reading from them will yield rows in TID order.

type MergeStats struct {
        DatapointsOutOfRange int64
}

type TIDMerger struct {
        files       []string
        tmpdir      string
        nodes       map[string]parquet.Node
        rowEstimate int64
        interval    int32
        startTS     int64
        endTS       int64

        stats MergeStats
}

type WriteResult struct {
        FileName    string
        RecordCount int64
        FileSize    int64
        TidCount    int32 // number of unique TIDs in the file
}

// NewTIDMerger creates a new TIDMerger instance.
// the interval must be exactly one interval between startTS and endTS.
// startTS and endTS are used to determine the timestamp of the merged rows.
// StartTS is inclusive, endTS is exclusive.0
func NewTIDMerger(tmpdir string, files []string, interval int32, rowEstimate int64, startTS int64, endTS int64) (*TIDMerger, error) <span class="cov8" title="1">{
        tslen := endTS - startTS
        if tslen%int64(interval) != 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("startTS %d and endTS %d must be aligned with interval %d", startTS, endTS, interval)
        }</span>
        <span class="cov8" title="1">return &amp;TIDMerger{
                files:       files,
                interval:    interval,
                rowEstimate: rowEstimate,
                tmpdir:      tmpdir,
                nodes:       make(map[string]parquet.Node),
                startTS:     startTS,
                endTS:       endTS,
        }, nil</span>
}

func (m *TIDMerger) validate() error <span class="cov8" title="1">{
        if len(m.files) == 0 </span><span class="cov0" title="0">{
                return errors.New("no files to merge in TIDMerger")
        }</span>
        <span class="cov8" title="1">if slices.Contains(m.files, "") </span><span class="cov0" title="0">{
                return errors.New("empty file name in TIDMerger")
        }</span>
        <span class="cov8" title="1">return nil</span>
}

// readerState holds a parquet reader, an in-memory buffer of rows,
// and exposes the current row and its TID.
const readBatchSize = 16

type readerState struct {
        reader   *parquet.GenericReader[map[string]any]
        buffer   []map[string]any
        idx      int
        closed   bool
        fileName string

        current    map[string]any
        currentTID int64
}

// loadNextBatch reads up to readBatchSize rows into buffer, updates current/currentTID,
// and marks closed if EOF is reached.
func (rs *readerState) loadNextBatch() error <span class="cov8" title="1">{
        if rs.closed </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov8" title="1">temp := make([]map[string]any, readBatchSize)
        for i := range readBatchSize </span><span class="cov8" title="1">{
                temp[i] = make(map[string]any)
        }</span>
        <span class="cov8" title="1">n, err := rs.reader.Read(temp)
        if n == 0 &amp;&amp; errors.Is(err, io.EOF) </span><span class="cov8" title="1">{
                rs.closed = true
                rs.buffer = nil
                rs.current = nil
                return nil
        }</span>
        <span class="cov8" title="1">if err != nil &amp;&amp; !errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                return fmt.Errorf("failed reading parquet batch from %s: %w", rs.fileName, err)
        }</span>

        <span class="cov8" title="1">if n == 0 </span><span class="cov0" title="0">{
                rs.closed = true
                rs.buffer = nil
                rs.current = nil
                return nil
        }</span>

        <span class="cov8" title="1">rs.buffer = temp[:n]
        rs.idx = 0
        rs.current = rs.buffer[0]
        tidVal, ok := rs.current["_cardinalhq.tid"].(int64)
        if !ok </span><span class="cov0" title="0">{
                return fmt.Errorf("file %s: row does not contain a valid int64 _cardinalhq.tid", rs.fileName)
        }</span>
        <span class="cov8" title="1">rs.currentTID = tidVal
        return nil</span>
}

// advance moves to the next row in buffer or loads the next batch if needed.
func (rs *readerState) advance() error <span class="cov8" title="1">{
        if rs.closed </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">rs.idx++
        if rs.idx &lt; len(rs.buffer) </span><span class="cov8" title="1">{
                rs.current = rs.buffer[rs.idx]
                tidVal, ok := rs.current["_cardinalhq.tid"].(int64)
                if !ok </span><span class="cov0" title="0">{
                        return fmt.Errorf("file %s: row does not contain a valid int64 _cardinalhq.tid", rs.fileName)
                }</span>
                <span class="cov8" title="1">rs.currentTID = tidVal
                return nil</span>
        }
        <span class="cov8" title="1">return rs.loadNextBatch()</span>
}

// Merge opens all input files, merges rows sorted by TID, and writes merged output.
func (m *TIDMerger) Merge() ([]WriteResult, MergeStats, error) <span class="cov8" title="1">{
        if err := m.validate(); err != nil </span><span class="cov0" title="0">{
                return nil, m.stats, fmt.Errorf("invalid merge config: %w", err)
        }</span>

        <span class="cov8" title="1">infiles := make([]*filecrunch.FileHandle, 0, len(m.files))
        defer func() </span><span class="cov8" title="1">{
                for _, fh := range infiles </span><span class="cov8" title="1">{
                        if err := fh.Close(); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to close file handle", "file", fh.File.Name(), "error", err)
                        }</span>
                }
        }()

        <span class="cov8" title="1">readers := make([]*parquet.GenericReader[map[string]any], 0, len(m.files))
        defer func() </span><span class="cov8" title="1">{
                for _, rdr := range readers </span><span class="cov8" title="1">{
                        if rdr != nil </span><span class="cov8" title="1">{
                                if err := rdr.Close(); err != nil </span><span class="cov0" title="0">{
                                        slog.Error("Failed to close parquet reader", "error", err)
                                }</span>
                        }
                }
        }()

        <span class="cov8" title="1">nodeBuilder := buffet.NewNodeMapBuilder()
        for _, file := range m.files </span><span class="cov8" title="1">{
                fh, err := filecrunch.LoadSchemaForFile(file)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, m.stats, fmt.Errorf("failed to load schema for file %s: %w", file, err)
                }</span>
                <span class="cov8" title="1">infiles = append(infiles, fh)

                reader := parquet.NewGenericReader[map[string]any](fh.File, fh.Schema)
                readers = append(readers, reader)

                if err := nodeBuilder.AddNodes(fh.Nodes); err != nil </span><span class="cov0" title="0">{
                        return nil, m.stats, fmt.Errorf("failed to add nodes for file %s: %w", file, err)
                }</span>
        }
        // ensure that we have the schema we will be writing
        <span class="cov8" title="1">if err := nodeBuilder.Add(map[string]any{
                "_cardinalhq.tid":       int64(0),
                "_cardinalhq.timestamp": int64(0),
                "_cardinalhq.name":      "",
                "sketch":                []byte{},
                "rollup_count":          float64(0),
                "rollup_sum":            float64(0),
                "rollup_avg":            float64(0),
                "rollup_max":            float64(0),
                "rollup_min":            float64(0),
                "rollup_p25":            float64(0),
                "rollup_p50":            float64(0),
                "rollup_p75":            float64(0),
                "rollup_p90":            float64(0),
                "rollup_p95":            float64(0),
                "rollup_p99":            float64(0),
        }); err != nil </span><span class="cov0" title="0">{
                return nil, m.stats, fmt.Errorf("failed to add rollup/sketch nodes for writing: %w", err)
        }</span>

        <span class="cov8" title="1">m.nodes = nodeBuilder.Build()

        writer, err := buffet.NewWriter("tid-merger-*", m.tmpdir, m.nodes, m.rowEstimate,
                buffet.WithGroupFunc(GroupTIDGroupFunc),
                buffet.WithStatsProvider(&amp;TidAccumulatorProvider{}),
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, m.stats, fmt.Errorf("failed to create writer: %w", err)
        }</span>
        <span class="cov8" title="1">defer func() </span><span class="cov8" title="1">{ writer.Abort() }</span>()

        <span class="cov8" title="1">states := make([]*readerState, len(readers))
        for i, rdr := range readers </span><span class="cov8" title="1">{
                states[i] = &amp;readerState{
                        reader:   rdr,
                        buffer:   nil,
                        idx:      0,
                        closed:   false,
                        fileName: m.files[i],
                }
        }</span>

        <span class="cov8" title="1">for _, rs := range states </span><span class="cov8" title="1">{
                if err := rs.loadNextBatch(); err != nil </span><span class="cov0" title="0">{
                        return nil, m.stats, err
                }</span>
        }

        <span class="cov8" title="1">for </span><span class="cov8" title="1">{
                smallest := int64(math.MaxInt64)
                foundAny := false
                for _, rs := range states </span><span class="cov8" title="1">{
                        if rs.closed </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        <span class="cov8" title="1">if rs.currentTID &lt; smallest </span><span class="cov8" title="1">{
                                smallest = rs.currentTID
                                foundAny = true
                        }</span>
                }
                <span class="cov8" title="1">if !foundAny </span><span class="cov8" title="1">{
                        break</span>
                }

                <span class="cov8" title="1">groupedRows := make([]map[string]any, 0, len(states))
                for _, rs := range states </span><span class="cov8" title="1">{
                        if rs.closed </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        // Collect all rows from this reader with the current smallest TID
                        <span class="cov8" title="1">for !rs.closed &amp;&amp; rs.currentTID == smallest </span><span class="cov8" title="1">{
                                groupedRows = append(groupedRows, rs.current)
                                if err := rs.advance(); err != nil </span><span class="cov0" title="0">{
                                        return nil, m.stats, err
                                }</span>
                        }
                }

                <span class="cov8" title="1">combinedRows := m.mergeRows(groupedRows)
                if len(combinedRows) &gt; 0 </span><span class="cov8" title="1">{
                        for _, row := range combinedRows </span><span class="cov8" title="1">{
                                if err := writer.Write(row); err != nil </span><span class="cov0" title="0">{
                                        return nil, m.stats, fmt.Errorf("failed to write row: %w", err)
                                }</span>
                        }
                }
        }

        <span class="cov8" title="1">results, err := writer.Close()
        if err != nil </span><span class="cov0" title="0">{
                return nil, m.stats, fmt.Errorf("error closing writer: %w", err)
        }</span>

        <span class="cov8" title="1">ret := make([]WriteResult, 0, len(results))
        for _, res := range results </span><span class="cov8" title="1">{
                var stats TidAccumulatorResult
                stats, _ = res.Stats.(TidAccumulatorResult)
                ret = append(ret, WriteResult{
                        FileName:    res.FileName,
                        RecordCount: res.RecordCount,
                        FileSize:    res.FileSize,
                        TidCount:    int32(stats.Cardinality),
                })
        }</span>

        <span class="cov8" title="1">return ret, m.stats, nil</span>
}

type mergekey struct {
        tid       int64
        timestamp int64
        name      string
}

type mergeaccumulator struct {
        row           map[string]any
        sketch        *ddsketch.DDSketch
        contributions int
}

func tsInRange(ts, startTS, endTS int64) bool <span class="cov8" title="1">{
        return ts &gt;= startTS &amp;&amp; ts &lt; endTS
}</span>

// mergeRows combines multiple rows with the same TID into a single row.
func (m *TIDMerger) mergeRows(rows []map[string]any) []map[string]any <span class="cov8" title="1">{
        if len(rows) &lt;= 1 </span><span class="cov8" title="1">{
                ts, ok := getTimestampFromRecord(rows[0])
                if !ok </span><span class="cov0" title="0">{
                        slog.Error("Row does not contain a valid int64 _cardinalhq.timestamp", "row", rows[0])
                        return nil // invalid row, cannot merge
                }</span>
                <span class="cov8" title="1">if !tsInRange(ts, m.startTS, m.endTS) </span><span class="cov0" title="0">{
                        m.stats.DatapointsOutOfRange++
                        slog.Warn("Row timestamp out of range", "timestamp", ts, "startTS", m.startTS, "endTS", m.endTS)
                        return nil // out of range, cannot merge
                }</span>
                <span class="cov8" title="1">rows[0]["_cardinalhq.timestamp"] = ts / int64(m.interval) * int64(m.interval) // align to interval
                return rows</span>
        }

        <span class="cov8" title="1">merged := make(map[mergekey]*mergeaccumulator)
        for _, row := range rows </span><span class="cov8" title="1">{
                rowTS, ok := getTimestampFromRecord(row)
                if !ok </span><span class="cov0" title="0">{
                        slog.Error("Row does not contain a valid int64 _cardinalhq.timestamp", "row", row)
                        continue</span>
                }

                <span class="cov8" title="1">if !tsInRange(rowTS, m.startTS, m.endTS) </span><span class="cov0" title="0">{
                        m.stats.DatapointsOutOfRange++
                        continue</span>
                }

                <span class="cov8" title="1">key, sketchBytes, err := makekey(row, int32(m.interval))
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to make key for row", "error", err, "row", row)
                        continue</span>
                }
                <span class="cov8" title="1">sketch, err := DecodeSketch(sketchBytes)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to decode sketch", "error", err)
                        continue</span>
                }

                <span class="cov8" title="1">if _, exists := merged[key]; !exists </span><span class="cov8" title="1">{
                        merged[key] = &amp;mergeaccumulator{
                                row:           row,
                                contributions: 1,
                        }
                        merged[key].sketch = sketch
                }</span> else<span class="cov8" title="1"> {
                        // accumulate contributions
                        merged[key].contributions++
                        if err := merged[key].sketch.MergeWith(sketch); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to merge sketch", "error", err)
                                continue</span>
                        }
                }
        }

        <span class="cov8" title="1">result := make([]map[string]any, 0, len(merged))
        for key, acc := range merged </span><span class="cov8" title="1">{
                if acc.contributions &gt; 1 </span><span class="cov8" title="1">{
                        if err := updateFromSketch(acc); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to update row from sketch", "error", err)
                                continue</span>
                        }
                }

                <span class="cov8" title="1">acc.row["_cardinalhq.timestamp"] = key.timestamp
                result = append(result, acc.row)</span>
        }

        <span class="cov8" title="1">return result</span>
}

func updateFromSketch(acc *mergeaccumulator) error <span class="cov8" title="1">{
        rollupCountIn := acc.sketch.GetCount()
        rollupSumIn := acc.sketch.GetSum()

        acc.row["rollup_count"] = rollupCountIn
        acc.row["rollup_sum"] = rollupSumIn
        acc.row["rollup_avg"] = rollupSumIn / rollupCountIn

        rollupMaxIn, err := acc.sketch.GetMaxValue()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("getting max value from sketch: %w", err)
        }</span>
        <span class="cov8" title="1">acc.row["rollup_max"] = rollupMaxIn

        rollupMinIn, err := acc.sketch.GetMinValue()
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("getting min value from sketch: %w", err)
        }</span>
        <span class="cov8" title="1">acc.row["rollup_min"] = rollupMinIn

        quantiles, err := acc.sketch.GetValuesAtQuantiles([]float64{0.25, 0.50, 0.75, 0.90, 0.95, 0.99})
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("getting quantiles from sketch: %w", err)
        }</span>
        <span class="cov8" title="1">acc.row["rollup_p25"] = quantiles[0]
        acc.row["rollup_p50"] = quantiles[1]
        acc.row["rollup_p75"] = quantiles[2]
        acc.row["rollup_p90"] = quantiles[3]
        acc.row["rollup_p95"] = quantiles[4]
        acc.row["rollup_p99"] = quantiles[5]

        acc.row["sketch"] = EncodeSketch(acc.sketch)

        return nil</span>
}

var (
        ErrorInvalidSketchType = errors.New("invalid sketch type, expected []byte or string")
        ErrorInvalidTID        = errors.New("record does not contain a valid int64 _cardinalhq.tid")
        ErrorInvalidTimestamp  = errors.New("record does not contain a valid int64 _cardinalhq.timestamp")
        ErrorInvalidName       = errors.New("record does not contain a valid string _cardinalhq.name")
)

func getTimestampFromRecord(rec map[string]any) (int64, bool) <span class="cov8" title="1">{
        timestamp, ok := rec["_cardinalhq.timestamp"].(int64)
        return timestamp, ok
}</span>

func makekey(rec map[string]any, interval int32) (key mergekey, sketchBytes []byte, err error) <span class="cov8" title="1">{
        tid, ok := rec["_cardinalhq.tid"].(int64)
        if !ok </span><span class="cov8" title="1">{
                return key, nil, ErrorInvalidTID
        }</span>
        <span class="cov8" title="1">timestamp, ok := getTimestampFromRecord(rec)
        if !ok </span><span class="cov8" title="1">{
                return key, nil, ErrorInvalidTimestamp
        }</span>
        <span class="cov8" title="1">name, ok := rec["_cardinalhq.name"].(string)
        if !ok </span><span class="cov8" title="1">{
                return key, nil, ErrorInvalidName
        }</span>
        <span class="cov8" title="1">sketchVal, ok := rec["sketch"]
        if !ok </span><span class="cov8" title="1">{
                return key, nil, ErrorInvalidSketchType
        }</span>
        <span class="cov8" title="1">switch v := sketchVal.(type) </span>{
        case []byte:<span class="cov8" title="1">
                sketchBytes = v</span>
        case string:<span class="cov8" title="1">
                sketchBytes = []byte(v)</span>
        default:<span class="cov8" title="1">
                return key, nil, ErrorInvalidSketchType</span>
        }

        <span class="cov8" title="1">return mergekey{
                tid:       tid,
                timestamp: (timestamp / int64(interval)) * int64(interval), // start of interval
                name:      name,
        }, sketchBytes, nil</span>
}

func GroupTIDGroupFunc(prev, current map[string]any) bool <span class="cov8" title="1">{
        ptid, ok := prev["_cardinalhq.tid"].(int64)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">ctid, ok := current["_cardinalhq.tid"].(int64)
        if !ok </span><span class="cov8" title="1">{
                return false
        }</span>
        <span class="cov8" title="1">return ptid == ctid</span>
}

func calculateTargetRecordsPerFile(recordCount int, estimatedBytesPerRecord int, targetFileSize int64) int64 <span class="cov8" title="1">{
        if recordCount &lt;= 0 || estimatedBytesPerRecord &lt;= 0 || targetFileSize &lt;= 0 </span><span class="cov8" title="1">{
                return 0
        }</span>

        <span class="cov8" title="1">totalRecords := int64(recordCount)
        eBPR := int64(estimatedBytesPerRecord)
        totalSize := totalRecords * eBPR
        if totalSize &lt;= targetFileSize </span><span class="cov8" title="1">{
                return totalRecords
        }</span>
        <span class="cov8" title="1">filesNeeded := min((totalSize+targetFileSize-1)/targetFileSize, totalRecords)
        return (totalRecords + filesNeeded - 1) / filesNeeded</span>
}
</pre>
		
		<pre class="file" id="file40" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "log/slog"
        "time"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5/pgtype"

        "github.com/cardinalhq/lakerunner/internal/helpers"
        "github.com/cardinalhq/lakerunner/lockmgr"
        "github.com/cardinalhq/lakerunner/lrdb"
)

type qmc struct {
        OrganizationID uuid.UUID
        InstanceNum    int16
        FrequencyMs    int32
        TsRange        pgtype.Range[pgtype.Timestamptz]
}

func qmcFromWorkable(inf lockmgr.Workable) qmc <span class="cov0" title="0">{
        return qmc{
                OrganizationID: inf.OrganizationID(),
                InstanceNum:    inf.InstanceNum(),
                FrequencyMs:    inf.FrequencyMs(),
                TsRange:        inf.TsRange(),
        }
}</span>

func qmcFromInqueue(inf lrdb.Inqueue, frequency int32, startTS int64) qmc <span class="cov0" title="0">{
        return qmc{
                OrganizationID: inf.OrganizationID,
                InstanceNum:    inf.InstanceNum,
                FrequencyMs:    frequency,
                TsRange: pgtype.Range[pgtype.Timestamptz]{
                        LowerType: pgtype.Inclusive,
                        UpperType: pgtype.Exclusive,
                        Lower:     pgtype.Timestamptz{Time: time.UnixMilli(startTS).UTC(), Valid: true},
                        Upper:     pgtype.Timestamptz{Time: time.UnixMilli(startTS).UTC().Add(time.Duration(frequency) * time.Millisecond), Valid: true},
                },
        }
}</span>

func priorityForFrequencyForCompaction(f int32) int32 <span class="cov0" title="0">{
        switch f </span>{
        case 10_000:<span class="cov0" title="0">
                return 1001</span>
        case 60_000:<span class="cov0" title="0">
                return 801</span>
        case 300_000:<span class="cov0" title="0">
                return 601</span>
        case 1_200_000:<span class="cov0" title="0">
                return 401</span>
        case 3_600_000:<span class="cov0" title="0">
                return 201</span>
        default:<span class="cov0" title="0">
                return 0</span>
        }
}

func priorityForFrequencyForRollup(f int32) int32 <span class="cov0" title="0">{
        switch f </span>{
        case 10_000:<span class="cov0" title="0">
                return 1000</span>
        case 60_000:<span class="cov0" title="0">
                return 800</span>
        case 300_000:<span class="cov0" title="0">
                return 600</span>
        case 1_200_000:<span class="cov0" title="0">
                return 400</span>
        case 3_600_000:<span class="cov0" title="0">
                return 200</span>
        default:<span class="cov0" title="0">
                return 0</span>
        }
}

func queueMetricCompaction(ctx context.Context, mdb lrdb.StoreFull, inf qmc) error <span class="cov0" title="0">{
        // compaction will lock the upstream's frequency's worth of data, so find the upstream frequency.
        upstreamFrequency, ok := rollupNotifications[inf.FrequencyMs]
        if !ok </span><span class="cov0" title="0">{
                return nil
                // slog.Warn("unknown frequency for compaction", "frequency_ms", inf.FrequencyMs)
                // upstreamFrequency = inf.FrequencyMs
        }</span>

        <span class="cov0" title="0">startTS, _, ok := RangeBounds(inf.TsRange)
        if !ok </span><span class="cov0" title="0">{
                slog.Error("invalid time range for metric compaction", "ts_range", inf.TsRange)
                return nil // invalid range, nothing to do
        }</span>

        <span class="cov0" title="0">upstreamDur := time.Duration(upstreamFrequency) * time.Millisecond
        parentStart := startTS.Time.UTC().Truncate(upstreamDur)
        parentEnd := parentStart.Add(upstreamDur)
        dateint, _ := helpers.MSToDateintHour(parentStart.UTC().UnixMilli())
        runableAt := parentStart.Add(upstreamDur * 2)

        rp := lrdb.WorkQueueAddParams{
                OrgID:     inf.OrganizationID,
                Instance:  inf.InstanceNum,
                Signal:    lrdb.SignalEnumMetrics,
                Action:    lrdb.ActionEnumCompact,
                Dateint:   dateint,
                Frequency: inf.FrequencyMs,
                TsRange: pgtype.Range[pgtype.Timestamptz]{
                        LowerType: pgtype.Inclusive,
                        UpperType: pgtype.Exclusive,
                        Lower:     pgtype.Timestamptz{Time: parentStart, Valid: true},
                        Upper:     pgtype.Timestamptz{Time: parentEnd, Valid: true},
                        Valid:     true,
                },
                RunnableAt: runableAt,
                Priority:   priorityForFrequencyForCompaction(inf.FrequencyMs),
        }
        //slog.Info("queueing metric compaction", "params", rp)
        return mdb.WorkQueueAdd(ctx, rp)</span>
}

// queueMetricRollup queues a metric rollup job for the given frequency and time range.
func queueMetricRollup(ctx context.Context, mdb lrdb.StoreFull, inf qmc) error <span class="cov0" title="0">{
        // rollups end when the last frequency is processed.
        upstreamFrequency, ok := rollupNotifications[inf.FrequencyMs]
        if !ok </span><span class="cov0" title="0">{
                slog.Warn("unknown frequency for rollup", "frequency_ms", inf.FrequencyMs)
                return nil
        }</span>

        <span class="cov0" title="0">startTS, _, ok := RangeBounds(inf.TsRange)
        if !ok </span><span class="cov0" title="0">{
                slog.Error("invalid time range for metric rollup", "ts_range", inf.TsRange)
                return nil // invalid range, nothing to do
        }</span>

        <span class="cov0" title="0">upstreamDur := time.Duration(upstreamFrequency) * time.Millisecond
        parentStart := startTS.Time.UTC().Truncate(upstreamDur)
        parentEnd := parentStart.Add(upstreamDur)
        dateint, _ := helpers.MSToDateintHour(parentStart.UTC().UnixMilli())
        runableAt := parentStart.Add(upstreamDur * 2)

        rp := lrdb.WorkQueueAddParams{
                OrgID:     inf.OrganizationID,
                Instance:  inf.InstanceNum,
                Signal:    lrdb.SignalEnumMetrics,
                Action:    lrdb.ActionEnumRollup,
                Dateint:   dateint,
                Frequency: upstreamFrequency,
                TsRange: pgtype.Range[pgtype.Timestamptz]{
                        LowerType: pgtype.Inclusive,
                        UpperType: pgtype.Exclusive,
                        Lower:     pgtype.Timestamptz{Time: parentStart, Valid: true},
                        Upper:     pgtype.Timestamptz{Time: parentEnd, Valid: true},
                        Valid:     true,
                },
                RunnableAt: runableAt,
                Priority:   priorityForFrequencyForRollup(upstreamFrequency),
        }
        //slog.Info("queueing metric rollup", "params", rp)
        return mdb.WorkQueueAdd(ctx, rp)</span>
}

// queueLogCompaction queues a log compaction job for the entire dateint
func queueLogCompaction(ctx context.Context, mdb lrdb.StoreFull, inf qmc) error <span class="cov0" title="0">{
        upstreamDur := 24 * time.Hour
        startTS, _, ok := RangeBounds(inf.TsRange)
        if !ok </span><span class="cov0" title="0">{
                slog.Error("invalid time range for log compaction notification", "ts_range", inf.TsRange)
                return nil // invalid range, nothing to do
        }</span>

        <span class="cov0" title="0">parentStart := startTS.Time.UTC().Truncate(upstreamDur)
        parentEnd := parentStart.Add(upstreamDur)
        dateint, _ := helpers.MSToDateintHour(parentStart.UTC().UnixMilli())

        return mdb.WorkQueueAdd(ctx, lrdb.WorkQueueAddParams{
                OrgID:     inf.OrganizationID,
                Instance:  inf.InstanceNum,
                Signal:    lrdb.SignalEnumLogs,
                Action:    lrdb.ActionEnumCompact,
                Dateint:   dateint,
                Frequency: -1,
                TsRange: pgtype.Range[pgtype.Timestamptz]{
                        LowerType: pgtype.Inclusive,
                        UpperType: pgtype.Exclusive,
                        Lower:     pgtype.Timestamptz{Time: parentStart, Valid: true},
                        Upper:     pgtype.Timestamptz{Time: parentEnd, Valid: true},
                        Valid:     true,
                },
                RunnableAt: time.Now().UTC().Add(5 * time.Minute), // give it a little time to settle
        })</span>
}
</pre>
		
		<pre class="file" id="file41" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
        "math"
        "os"
        "time"

        "github.com/jackc/pgx/v5"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/metric"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/estimator"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
        "github.com/cardinalhq/lakerunner/lockmgr"
        "github.com/cardinalhq/lakerunner/lrdb"
)

type RunqueueProcessingFunction func(
        ctx context.Context,
        ll *slog.Logger,
        tmpdir string,
        awsmanager *awsclient.Manager,
        sp storageprofile.StorageProfileProvider,
        mdb lrdb.StoreFull,
        inf lockmgr.Workable,
        rpfEstimate int64,
) (WorkResult, error)

type WorkResult int

const (
        WorkResultSuccess WorkResult = iota
        WorkResultTryAgainLater
)

type RunqueueLoopContext struct {
        ctx        context.Context
        wqm        lockmgr.WorkQueueManager
        mdb        lrdb.StoreFull
        sp         storageprofile.StorageProfileProvider
        awsmanager *awsclient.Manager
        estimator  estimator.Estimator
        signal     string
        action     string
        ll         *slog.Logger
}

func NewRunqueueLoopContext(ctx context.Context, signal string, action string, assumeRoleSessionName string) (*RunqueueLoopContext, error) <span class="cov0" title="0">{
        ll := slog.Default().With(
                slog.String("signal", signal),
                slog.String("action", action),
        )

        mdb, err := dbopen.LRDBStore(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to open LRDB store: %w", err)
        }</span>

        <span class="cov0" title="0">awsmanager, err := awsclient.NewManager(ctx, awsclient.WithAssumeRoleSessionName(assumeRoleSessionName))
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create AWS manager: %w", err)
        }</span>

        <span class="cov0" title="0">est, err := estimator.NewEstimator(ctx, mdb)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create estimator: %w", err)
        }</span>

        <span class="cov0" title="0">sp, err := storageprofile.SetupStorageProfiles()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to setup storage profiles: %w", err)
        }</span>

        <span class="cov0" title="0">freqs, err := frequenciesToRequest(signal, action)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get frequencies for signal %s and action %s: %w", signal, action, err)
        }</span>

        <span class="cov0" title="0">wqm := lockmgr.NewWorkQueueManager(mdb, myInstanceID, lrdb.SignalEnum(signal), lrdb.ActionEnum(action), freqs, math.MinInt32)
        go wqm.Run(ctx)

        return &amp;RunqueueLoopContext{
                ctx:        ctx,
                wqm:        wqm,
                mdb:        mdb,
                sp:         sp,
                awsmanager: awsmanager,
                estimator:  est,
                signal:     signal,
                action:     action,
                ll:         ll,
        }, nil</span>
}

func RunqueueLoop(loop *RunqueueLoopContext, pfx RunqueueProcessingFunction) error <span class="cov0" title="0">{
        ctx := context.Background()

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-loop.ctx.Done():<span class="cov0" title="0">
                        return loop.ctx.Err()</span>
                default:<span class="cov0" title="0"></span>
                }

                <span class="cov0" title="0">t0 := time.Now()
                shouldBackoff, didWork, err := workqueueProcess(ctx, loop, pfx)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov0" title="0">if didWork </span><span class="cov0" title="0">{
                        loop.ll.Info("Completed work", slog.Duration("elapsed", time.Since(t0)))
                }</span>

                <span class="cov0" title="0">if shouldBackoff </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-loop.ctx.Done():<span class="cov0" title="0">
                                return loop.ctx.Err()</span>
                        case &lt;-time.After(workSleepTime):<span class="cov0" title="0"></span>
                        }
                }

                <span class="cov0" title="0">gc()</span>
        }
}

func frequenciesToRequest(signal, action string) ([]int32, error) <span class="cov8" title="1">{
        switch signal </span>{
        case "logs":<span class="cov8" title="1">
                if action == "compact" </span><span class="cov8" title="1">{
                        return []int32{-1}, nil
                }</span>
                <span class="cov8" title="1">return nil, errors.New("unknown action for logs signal: " + action)</span>
        case "metrics":<span class="cov8" title="1">
                switch action </span>{
                case "compact":<span class="cov8" title="1">
                        return acceptedMetricFrequencies, nil</span>
                case "rollup":<span class="cov8" title="1">
                        freqs := make([]int32, 0, len(rollupSources))
                        for k := range rollupSources </span><span class="cov8" title="1">{
                                freqs = append(freqs, k)
                        }</span>
                        <span class="cov8" title="1">return freqs, nil</span>
                }
                <span class="cov8" title="1">return nil, errors.New("unknown action for metrics signal: " + action)</span>
        default:<span class="cov8" title="1">
                return nil, errors.New("unknown signal type: " + signal)</span>
        }
}

func workqueueProcess(
        ctx context.Context,
        loop *RunqueueLoopContext,
        pfx RunqueueProcessingFunction) (bool, bool, error) <span class="cov0" title="0">{

        ctx, span := tracer.Start(ctx, "workqueueProcess", trace.WithAttributes(commonAttributes.ToSlice()...))
        defer span.End()

        t0 := time.Now()
        inf, err := loop.wqm.RequestWork()
        workqueueFetchDuration.Record(ctx, time.Since(t0).Seconds(),
                metric.WithAttributeSet(commonAttributes),
                metric.WithAttributes(
                        attribute.Bool("hasError", err != nil &amp;&amp; !errors.Is(err, pgx.ErrNoRows)),
                        attribute.Bool("errorIsNoRows", errors.Is(err, pgx.ErrNoRows)),
                ))
        if err != nil || inf == nil </span><span class="cov0" title="0">{
                return true, false, err
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                if err := inf.Fail(); err != nil </span><span class="cov0" title="0">{
                        loop.ll.Error("Failed to release work item", slog.Any("error", err))
                }</span>
        }()

        <span class="cov0" title="0">orgAttrs := attribute.NewSet(
                attribute.String("organizationID", inf.OrganizationID().String()),
                attribute.Int64("instanceNum", int64(inf.InstanceNum())),
                attribute.Int64("priority", int64(inf.Priority())),
                attribute.Int64("frequencyMs", int64(inf.FrequencyMs())),
        )

        workLag := max(time.Since(inf.RunnableAt()), 0)
        workqueueLag.Record(ctx, workLag.Seconds(),
                metric.WithAttributeSet(commonAttributes),
                metric.WithAttributeSet(orgAttrs),
        )

        ll := loop.ll.With(
                slog.Int64("workQueueID", inf.ID()),
                slog.Int("tries", int(inf.Tries())),
                slog.String("organizationID", inf.OrganizationID().String()),
                slog.Int("instanceNum", int(inf.InstanceNum())),
        )

        ll.Info("Processing work queue item",
                slog.Int("priority", int(inf.Priority())),
                slog.Int("frequencyMs", int(inf.FrequencyMs())),
                slog.Int("dateint", int(inf.Dateint())),
                slog.Time("runnableAt", inf.RunnableAt()),
                slog.Duration("workLag", workLag),
        )

        tmpdir, err := os.MkdirTemp("", "lakerunner-workqueue-*")
        if err != nil </span><span class="cov0" title="0">{
                ll.Error("Failed to create temporary directory", slog.Any("error", err))
                return true, false, fmt.Errorf("failed to create temporary directory: %w", err)
        }</span>
        <span class="cov0" title="0">ll.Info("Created temporary directory", slog.String("path", tmpdir))
        defer func() </span><span class="cov0" title="0">{
                if err := os.RemoveAll(tmpdir); err != nil </span><span class="cov0" title="0">{
                        ll.Error("Failed to remove temporary directory", slog.String("path", tmpdir), slog.Any("error", err))
                }</span> else<span class="cov0" title="0"> {
                        ll.Info("Removed temporary directory", slog.String("path", tmpdir))
                }</span>
        }()

        <span class="cov0" title="0">estBytesPerRecord := loop.estimator.Get(inf.OrganizationID(), inf.InstanceNum(), inf.Signal()).EstimatedRecordCount
        t0 = time.Now()
        result, err := pfx(ctx, ll, tmpdir, loop.awsmanager, loop.sp, loop.mdb, inf, estBytesPerRecord)
        workqueueDuration.Record(ctx, time.Since(t0).Seconds(),
                metric.WithAttributeSet(commonAttributes),
                metric.WithAttributeSet(orgAttrs),
                metric.WithAttributes(
                        attribute.Bool("hasError", err != nil),
                        attribute.Int("result", int(result)),
                ))
        switch result </span>{
        case WorkResultSuccess:<span class="cov0" title="0">
                return false, true, inf.Complete()</span>
        case WorkResultTryAgainLater:<span class="cov0" title="0">
                return true, false, inf.Fail()</span>
        default:<span class="cov0" title="0">
                ll.Error("Unexpected work result", slog.Int("result", int(result)), slog.Any("error", err))
                return true, false, inf.Fail()</span>
        }
}
</pre>
		
		<pre class="file" id="file42" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package cmd

import (
        "context"
        "log/slog"

        "github.com/cardinalhq/lakerunner/lrdb"
)

type WorkqueueHandler struct {
        ctx context.Context
        ll  *slog.Logger
        mdb lrdb.StoreFull
        inf lrdb.WorkQueueClaimRow
}

func NewWorkqueueHandler(
        ctx context.Context,
        ll *slog.Logger,
        mdb lrdb.StoreFull,
        inf lrdb.WorkQueueClaimRow,
) *WorkqueueHandler <span class="cov0" title="0">{
        return &amp;WorkqueueHandler{ctx, ll, mdb, inf}
}</span>

func (h *WorkqueueHandler) CompleteWork() <span class="cov0" title="0">{
        if err := h.mdb.WorkQueueComplete(h.ctx, lrdb.WorkQueueCompleteParams{
                ID:       h.inf.ID,
                WorkerID: myInstanceID,
        }); err != nil </span><span class="cov0" title="0">{
                h.ll.Error("WorkQueueComplete failed", slog.Any("error", err))
        }</span>
}

func (h *WorkqueueHandler) RetryWork() <span class="cov0" title="0">{
        if err := h.mdb.WorkQueueFail(h.ctx, lrdb.WorkQueueFailParams{
                ID:       h.inf.ID,
                WorkerID: myInstanceID,
        }); err != nil </span><span class="cov0" title="0">{
                h.ll.Error("WorkQueueFail failed", slog.Any("error", err))
        }</span>
}
</pre>
		
		<pre class="file" id="file43" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package dbase

import (
        "fmt"
        "math/big"
        "strings"

        "github.com/google/uuid"
)

func UUIDToBase36(id uuid.UUID) string <span class="cov8" title="1">{
        bi := new(big.Int).SetBytes(id[:])

        ret := bi.Text(36)
        const fixedLength = 25
        if len(ret) &lt; fixedLength </span><span class="cov8" title="1">{
                ret = strings.Repeat("0", fixedLength-len(ret)) + ret
        }</span>
        <span class="cov8" title="1">return ret</span>
}

// Base36ToUUID converts a base36 string (assumed to be 25 characters long)
// back into a uuid.UUID.
func Base36ToUUID(s string) (uuid.UUID, error) <span class="cov8" title="1">{
        bi, ok := new(big.Int).SetString(s, 36)
        if !ok </span><span class="cov8" title="1">{
                return uuid.Nil, fmt.Errorf("invalid base36 string: %s", s)
        }</span>
        <span class="cov8" title="1">if bi.BitLen() &gt; 128 </span><span class="cov8" title="1">{
                return uuid.Nil, fmt.Errorf("number too large for UUID: %s", s)
        }</span>
        <span class="cov8" title="1">b := bi.Bytes()

        if len(b) &lt; 16 </span><span class="cov8" title="1">{
                padded := make([]byte, 16)
                copy(padded[16-len(b):], b)
                b = padded
        }</span>
        <span class="cov8" title="1">var id uuid.UUID
        copy(id[:], b)
        return id, nil</span>
}
</pre>
		
		<pre class="file" id="file44" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package jsongz

import (
        "bufio"
        "compress/gzip"
        "encoding/json"
        "fmt"
        "maps"
        "os"
        "strings"

        "github.com/cardinalhq/lakerunner/fileconv"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
)

type JSONGzReader struct {
        fname    string
        file     *os.File
        gzReader *gzip.Reader
        scanner  *bufio.Scanner
        mapper   *translate.Mapper
        tags     map[string]string
        rowIndex int
}

var _ fileconv.Reader = (*JSONGzReader)(nil)

func NewJSONGzReader(fname string, mapper *translate.Mapper, tags map[string]string) (*JSONGzReader, error) <span class="cov8" title="1">{
        file, err := os.Open(fname)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to open file %s: %w", fname, err)
        }</span>

        <span class="cov8" title="1">gzReader, err := gzip.NewReader(file)
        if err != nil </span><span class="cov0" title="0">{
                file.Close()
                return nil, fmt.Errorf("failed to create gzip reader: %w", err)
        }</span>

        <span class="cov8" title="1">scanner := bufio.NewScanner(gzReader)
        scanner.Buffer(make([]byte, 0, 64*1024), 1024*1024) // 1MB max line size

        return &amp;JSONGzReader{
                fname:    fname,
                file:     file,
                gzReader: gzReader,
                scanner:  scanner,
                mapper:   mapper,
                tags:     tags,
                rowIndex: 0,
        }, nil</span>
}

func (r *JSONGzReader) Close() error <span class="cov8" title="1">{
        var err error
        if r.gzReader != nil </span><span class="cov8" title="1">{
                if err = r.gzReader.Close(); err != nil </span><span class="cov0" title="0">{
                        err = fmt.Errorf("failed to close gzip reader: %w", err)
                }</span>
        }
        <span class="cov8" title="1">if r.file != nil </span><span class="cov8" title="1">{
                if closeErr := r.file.Close(); closeErr != nil </span><span class="cov0" title="0">{
                        if err != nil </span><span class="cov0" title="0">{
                                err = fmt.Errorf("failed to close file: %w, gzip error: %w", closeErr, err)
                        }</span> else<span class="cov0" title="0"> {
                                err = fmt.Errorf("failed to close file: %w", closeErr)
                        }</span>
                }
        }
        <span class="cov8" title="1">return err</span>
}

func (r *JSONGzReader) GetRow() (row map[string]any, done bool, err error) <span class="cov8" title="1">{
        if r.scanner == nil </span><span class="cov0" title="0">{
                return nil, true, fmt.Errorf("scanner is not initialized")
        }</span>

        <span class="cov8" title="1">if !r.scanner.Scan() </span><span class="cov8" title="1">{
                if err := r.scanner.Err(); err != nil </span><span class="cov0" title="0">{
                        return nil, false, fmt.Errorf("failed to scan line: %w", err)
                }</span>
                // EOF reached
                <span class="cov8" title="1">return nil, true, nil</span>
        }

        <span class="cov8" title="1">line := r.scanner.Text()
        if line == "" </span><span class="cov8" title="1">{
                return r.GetRow()
        }</span>

        <span class="cov8" title="1">var jsonData map[string]any
        if err := json.Unmarshal([]byte(line), &amp;jsonData); err != nil </span><span class="cov0" title="0">{
                return nil, false, fmt.Errorf("failed to parse JSON line %d: %w", r.rowIndex+1, err)
        }</span>

        <span class="cov8" title="1">if tags, ok := jsonData["tags"].([]any); ok </span><span class="cov0" title="0">{
                for _, tag := range tags </span><span class="cov0" title="0">{
                        if tagStr, ok := tag.(string); ok &amp;&amp; strings.Contains(tagStr, ":") </span><span class="cov0" title="0">{
                                parts := strings.SplitN(tagStr, ":", 2)
                                if len(parts) == 2 </span><span class="cov0" title="0">{
                                        key := strings.TrimSpace(parts[0])
                                        value := strings.TrimSpace(parts[1])

                                        if isResourceAttribute(key) </span><span class="cov0" title="0">{
                                                jsonData["resource."+key] = value
                                        }</span> else<span class="cov0" title="0"> {
                                                jsonData[key] = value
                                        }</span>
                                }
                        }
                }
                <span class="cov0" title="0">delete(jsonData, "tags")</span>
        }

        <span class="cov8" title="1">parsedRow := translate.ParseLogRow(r.mapper, jsonData)

        ret := make(map[string]any)
        for k, v := range parsedRow.ResourceAttributes </span><span class="cov0" title="0">{
                ret["resource."+k] = v
        }</span>
        <span class="cov8" title="1">for k, v := range parsedRow.ScopeAttributes </span><span class="cov0" title="0">{
                ret["scope."+k] = v
        }</span>
        <span class="cov8" title="1">for k, v := range parsedRow.RecordAttributes </span><span class="cov8" title="1">{
                if strings.HasPrefix(k, "log.") </span><span class="cov0" title="0">{
                        ret[strings.TrimPrefix(k, "log.")] = v
                }</span> else<span class="cov8" title="1"> {
                        ret[k] = v
                }</span>
        }
        <span class="cov8" title="1">maps.Copy(ret, parsedRow.RawAttributes)

        if _, ok := ret["_cardinalhq.timestamp"]; !ok &amp;&amp; parsedRow.Timestamp &gt; 0 </span><span class="cov8" title="1">{
                ret["_cardinalhq.timestamp"] = parsedRow.Timestamp / 1000000 // Convert nanoseconds to milliseconds
        }</span>
        <span class="cov8" title="1">if _, ok := ret["_cardinalhq.message"]; !ok &amp;&amp; parsedRow.Body != "" </span><span class="cov8" title="1">{
                ret["_cardinalhq.message"] = parsedRow.Body
        }</span>
        <span class="cov8" title="1">ret["_cardinalhq.name"] = "log.events"
        ret["_cardinalhq.telemetry_type"] = "logs"
        ret["_cardinalhq.value"] = float64(1)

        // Add tags
        for k, v := range r.tags </span><span class="cov0" title="0">{
                ret[k] = v
        }</span>

        <span class="cov8" title="1">r.rowIndex++
        return ret, false, nil</span>
}

// isResourceAttribute determines if a field should be treated as a resource attribute
func isResourceAttribute(key string) bool <span class="cov0" title="0">{
        resourcePrefixes := []string{
                "k8s.", "kubernetes.", "app.kubernetes.io/",
                "container.", "pod.", "node.", "namespace.",
                "service.", "deployment.", "statefulset.",
                "image.", "host.", "region.", "zone.",
                "instance.", "cluster.", "node.",
        }

        keyLower := strings.ToLower(key)
        for _, prefix := range resourcePrefixes </span><span class="cov0" title="0">{
                if strings.HasPrefix(keyLower, prefix) </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}
</pre>
		
		<pre class="file" id="file45" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package proto

import (
        "fmt"
        "io"
        "os"

        "go.opentelemetry.io/collector/pdata/pmetric"

        "github.com/cardinalhq/lakerunner/cmd/otel"
        "github.com/cardinalhq/lakerunner/fileconv"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
        "github.com/cardinalhq/lakerunner/internal/idgen"
)

type MetricsProtoReader struct {
        fname   string
        file    *os.File
        metrics *pmetric.Metrics
        // Streaming state
        currentResourceIndex int
        metricQueue          []map[string]any
        queueIndex           int
        mapper               *translate.Mapper
        tags                 map[string]string
        translator           *otel.TableTranslator
        idg                  idgen.IDGenerator
}

var _ fileconv.Reader = (*MetricsProtoReader)(nil)

func NewMetricsProtoReader(fname string, mapper *translate.Mapper, tags map[string]string) (*MetricsProtoReader, error) <span class="cov8" title="1">{
        file, err := os.Open(fname)
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to open file %s: %w", fname, err)
        }</span>

        <span class="cov8" title="1">metrics, err := parseProtoToOtelMetrics(file)
        if err != nil </span><span class="cov0" title="0">{
                file.Close()
                return nil, fmt.Errorf("failed to parse proto to OTEL metrics: %w", err)
        }</span>

        <span class="cov8" title="1">translator := otel.NewTableTranslator()
        idg := idgen.NewULIDGenerator()

        return &amp;MetricsProtoReader{
                fname:                fname,
                file:                 nil, // File is closed after parsing
                metrics:              metrics,
                currentResourceIndex: 0,
                metricQueue:          nil,
                queueIndex:           0,
                mapper:               mapper,
                tags:                 tags,
                translator:           translator,
                idg:                  idg,
        }, nil</span>
}

func (r *MetricsProtoReader) Close() error <span class="cov8" title="1">{
        r.metrics = nil
        return nil
}</span>

func (r *MetricsProtoReader) GetRow() (row map[string]any, done bool, err error) <span class="cov8" title="1">{
        if r.metrics == nil </span><span class="cov0" title="0">{
                return nil, true, fmt.Errorf("proto metrics are not initialized")
        }</span>

        <span class="cov8" title="1">if r.queueIndex &gt;= len(r.metricQueue) </span><span class="cov8" title="1">{
                if !r.loadNextResourceMetric() </span><span class="cov0" title="0">{
                        return nil, true, nil // No more resource metrics
                }</span>
        }

        <span class="cov8" title="1">metric := r.metricQueue[r.queueIndex]

        for k, v := range r.tags </span><span class="cov8" title="1">{
                metric[k] = v
        }</span>

        <span class="cov8" title="1">r.queueIndex++

        return metric, false, nil</span>
}

// loadNextResourceMetric loads the next resource metric and populates the queue
func (r *MetricsProtoReader) loadNextResourceMetric() bool <span class="cov8" title="1">{
        if r.currentResourceIndex &gt;= r.metrics.ResourceMetrics().Len() </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">resourceMetric := r.metrics.ResourceMetrics().At(r.currentResourceIndex)

        singleResourceMetric := pmetric.NewMetrics()
        newResourceMetric := singleResourceMetric.ResourceMetrics().AppendEmpty()

        resourceMetric.CopyTo(newResourceMetric)

        convertedMetrics, err := r.translator.MetricsFromOtel(&amp;singleResourceMetric, nil)
        if err != nil </span><span class="cov0" title="0">{
                r.currentResourceIndex++
                return r.loadNextResourceMetric()
        }</span>

        <span class="cov8" title="1">r.metricQueue = convertedMetrics
        r.queueIndex = 0
        r.currentResourceIndex++

        return true</span>
}

// parseProtoToOtelMetrics parses protobuf data into OpenTelemetry metrics format
func parseProtoToOtelMetrics(file *os.File) (*pmetric.Metrics, error) <span class="cov8" title="1">{
        unmarshaler := &amp;pmetric.ProtoUnmarshaler{}

        data, err := io.ReadAll(file)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read file: %w", err)
        }</span>

        <span class="cov8" title="1">metrics, err := unmarshaler.UnmarshalMetrics(data)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unmarshal protobuf metrics: %w", err)
        }</span>

        <span class="cov8" title="1">return &amp;metrics, nil</span>
}
</pre>
		
		<pre class="file" id="file46" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package proto

import (
        "fmt"
        "io"
        "os"

        "go.opentelemetry.io/collector/pdata/plog"

        "github.com/cardinalhq/lakerunner/cmd/otel"
        "github.com/cardinalhq/lakerunner/fileconv"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
        "github.com/cardinalhq/lakerunner/internal/idgen"
)

type ProtoReader struct {
        fname string
        file  *os.File
        logs  *plog.Logs
        // Streaming state
        currentResourceIndex int
        logQueue             []map[string]any
        queueIndex           int
        mapper               *translate.Mapper
        tags                 map[string]string
        translator           *otel.TableTranslator
        idg                  idgen.IDGenerator
}

var _ fileconv.Reader = (*ProtoReader)(nil)

func NewProtoReader(fname string, mapper *translate.Mapper, tags map[string]string) (*ProtoReader, error) <span class="cov8" title="1">{
        file, err := os.Open(fname)
        if err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to open file %s: %w", fname, err)
        }</span>

        <span class="cov8" title="1">logs, err := parseProtoToOtelLogs(file)
        if err != nil </span><span class="cov0" title="0">{
                file.Close()
                return nil, fmt.Errorf("failed to parse proto to OTEL logs: %w", err)
        }</span>

        <span class="cov8" title="1">translator := otel.NewTableTranslator()
        idg := idgen.NewULIDGenerator()

        return &amp;ProtoReader{
                fname:                fname,
                file:                 nil, // File is closed after parsing
                logs:                 logs,
                currentResourceIndex: 0,
                logQueue:             nil,
                queueIndex:           0,
                mapper:               mapper,
                tags:                 tags,
                translator:           translator,
                idg:                  idg,
        }, nil</span>
}

func (r *ProtoReader) Close() error <span class="cov8" title="1">{
        r.logs = nil
        return nil
}</span>

func (r *ProtoReader) GetRow() (row map[string]any, done bool, err error) <span class="cov8" title="1">{
        if r.logs == nil </span><span class="cov0" title="0">{
                return nil, true, fmt.Errorf("proto logs are not initialized")
        }</span>

        <span class="cov8" title="1">if r.queueIndex &gt;= len(r.logQueue) </span><span class="cov8" title="1">{
                if !r.loadNextResourceLog() </span><span class="cov0" title="0">{
                        return nil, true, nil // No more resource logs
                }</span>
        }

        <span class="cov8" title="1">log := r.logQueue[r.queueIndex]

        for k, v := range r.tags </span><span class="cov8" title="1">{
                log[k] = v
        }</span>

        <span class="cov8" title="1">r.queueIndex++

        return log, false, nil</span>
}

// loadNextResourceLog loads the next resource log and populates the queue
func (r *ProtoReader) loadNextResourceLog() bool <span class="cov8" title="1">{
        if r.currentResourceIndex &gt;= r.logs.ResourceLogs().Len() </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov8" title="1">resourceLog := r.logs.ResourceLogs().At(r.currentResourceIndex)

        singleResourceLog := plog.NewLogs()
        newResourceLog := singleResourceLog.ResourceLogs().AppendEmpty()

        resourceLog.CopyTo(newResourceLog)

        convertedLogs, err := r.translator.LogsFromOtel(&amp;singleResourceLog, nil)
        if err != nil </span><span class="cov0" title="0">{
                r.currentResourceIndex++
                return r.loadNextResourceLog()
        }</span>

        <span class="cov8" title="1">r.logQueue = convertedLogs
        r.queueIndex = 0
        r.currentResourceIndex++

        return true</span>
}

// parseProtoToOtelLogs parses protobuf data into OpenTelemetry logs format
func parseProtoToOtelLogs(file *os.File) (*plog.Logs, error) <span class="cov8" title="1">{
        unmarshaler := &amp;plog.ProtoUnmarshaler{}

        data, err := io.ReadAll(file)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read file: %w", err)
        }</span>

        <span class="cov8" title="1">logs, err := unmarshaler.UnmarshalLogs(data)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to unmarshal protobuf logs: %w", err)
        }</span>

        <span class="cov8" title="1">return &amp;logs, nil</span>
}
</pre>
		
		<pre class="file" id="file47" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package rawparquet

import (
        "errors"
        "fmt"
        "io"
        "maps"

        "github.com/parquet-go/parquet-go"

        "github.com/cardinalhq/lakerunner/fileconv"
        "github.com/cardinalhq/lakerunner/fileconv/translate"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
)

type RawParquetReader struct {
        fname  string
        fh     *filecrunch.FileHandle
        pf     *parquet.File
        pfr    *parquet.GenericReader[map[string]any]
        mapper *translate.Mapper
        tags   map[string]string
}

var _ fileconv.Reader = (*RawParquetReader)(nil)

func NewRawParquetReader(fname string, mapper *translate.Mapper, tags map[string]string) (*RawParquetReader, error) <span class="cov8" title="1">{
        fh, err := filecrunch.LoadSchemaForFile(fname)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to load schema for file %s: %w", fname, err)
        }</span>
        <span class="cov8" title="1">pf := fh.ParquetFile
        pfr := parquet.NewGenericReader[map[string]any](fh.File, fh.Schema)

        return &amp;RawParquetReader{
                fname:  fname,
                fh:     fh,
                pf:     pf,
                pfr:    pfr,
                mapper: mapper,
                tags:   tags,
        }, nil</span>
}

func (r *RawParquetReader) Close() error <span class="cov8" title="1">{
        var err error
        if r.pfr != nil </span><span class="cov8" title="1">{
                if err = r.pfr.Close(); err != nil </span><span class="cov0" title="0">{
                        err = errors.Join(err, fmt.Errorf("failed to close parquet reader: %w", err))
                }</span>
        }
        <span class="cov8" title="1">if r.fh != nil </span><span class="cov8" title="1">{
                if err = r.fh.Close(); err != nil </span><span class="cov0" title="0">{
                        err = errors.Join(err, fmt.Errorf("failed to close file handle: %w", err))
                }</span>
        }
        <span class="cov8" title="1">r.pf = nil
        r.fh = nil
        return err</span>
}

func (r *RawParquetReader) NumRows() int64 <span class="cov8" title="1">{
        if r.pfr == nil </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="1">return r.pfr.NumRows()</span>
}

func (r *RawParquetReader) GetRow() (row map[string]any, done bool, err error) <span class="cov8" title="1">{
        if r.pfr == nil </span><span class="cov0" title="0">{
                return nil, true, fmt.Errorf("parquet file reader is not initialized")
        }</span>

        <span class="cov8" title="1">rows := make([]map[string]any, 1)
        rows[0] = make(map[string]any)

        n, err := r.pfr.Read(rows)
        if n == 0 &amp;&amp; err != nil </span><span class="cov8" title="1">{
                if errors.Is(err, io.EOF) </span><span class="cov8" title="1">{
                        return nil, true, nil
                }</span>
                <span class="cov0" title="0">return nil, false, fmt.Errorf("failed to read row: %w", err)</span>
        }
        <span class="cov8" title="1">if n != 1 </span><span class="cov0" title="0">{
                return nil, true, fmt.Errorf("expected to read %d rows, got %d", len(rows), n)
        }</span>

        <span class="cov8" title="1">parsedRow := translate.ParseLogRow(r.mapper, rows[0])

        ret := make(map[string]any)
        for k, v := range parsedRow.ResourceAttributes </span><span class="cov8" title="1">{
                ret["resource."+k] = v
        }</span>
        <span class="cov8" title="1">for k, v := range parsedRow.ScopeAttributes </span><span class="cov0" title="0">{
                ret["scope."+k] = v
        }</span>
        <span class="cov8" title="1">for k, v := range parsedRow.RecordAttributes </span><span class="cov8" title="1">{
                ret["log."+k] = v
        }</span>
        <span class="cov8" title="1">maps.Copy(ret, parsedRow.RawAttributes)
        if _, ok := ret["_cardinalhq.timestamp"]; !ok &amp;&amp; parsedRow.Timestamp &gt; 0 </span><span class="cov0" title="0">{
                ret["_cardinalhq.timestamp"] = parsedRow.Timestamp
        }</span>
        <span class="cov8" title="1">if _, ok := ret["_cardinalhq.message"]; !ok &amp;&amp; parsedRow.Body != "" </span><span class="cov0" title="0">{
                ret["_cardinalhq.message"] = parsedRow.Body
        }</span>
        <span class="cov8" title="1">ret["_cardinalhq.name"] = "log.events"
        ret["_cardinalhq.telemetry_type"] = "logs"
        ret["_cardinalhq.value"] = float64(1)

        for k, v := range r.tags </span><span class="cov0" title="0">{
                ret[k] = v
        }</span>

        <span class="cov8" title="1">return ret, false, nil</span>
}
</pre>
		
		<pre class="file" id="file48" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package translate

import (
        "fmt"
        "slices"
        "strconv"
        "strings"
        "time"
)

type TranslatedLog struct {
        // Milliseconds since Unix epoch.
        Timestamp int64
        Body      string
        // Attributes partitioned by destination.
        ResourceAttributes map[string]string
        ScopeAttributes    map[string]string
        RecordAttributes   map[string]string
        RawAttributes      map[string]any
}

func ParseLogRow(mapper *Mapper, input map[string]any) TranslatedLog <span class="cov8" title="1">{
        now := time.Now().UnixMilli()
        var ts int64 = -1
        var body string

        resAttrs := make(map[string]string)
        scopeAttrs := make(map[string]string)
        recAttrs := make(map[string]string)
        rawAttrs := make(map[string]any)

        for rawKey, rawVal := range input </span><span class="cov8" title="1">{
                if rawVal == nil </span><span class="cov8" title="1">{
                        continue</span>
                }

                <span class="cov8" title="1">lc := strings.ToLower(rawKey)

                // Timestamp?
                if ts &lt;= 0 &amp;&amp; slices.Contains(mapper.TimestampColumns, lc) </span><span class="cov8" title="1">{
                        if parsed, ok := coerceToUnixMillis(rawVal, mapper.TimeFormat); ok </span><span class="cov8" title="1">{
                                ts = parsed
                        }</span>
                        <span class="cov8" title="1">continue</span>
                }

                // Message?
                <span class="cov8" title="1">if body == "" &amp;&amp; slices.Contains(mapper.MessageColumns, lc) </span><span class="cov8" title="1">{
                        body = toString(rawVal)
                        continue</span>
                }

                <span class="cov8" title="1">if strings.HasPrefix(lc, "_") </span><span class="cov0" title="0">{
                        rawAttrs[lc] = rawVal
                        continue</span>
                }

                // Decide promotion target maps for this top-level key.
                <span class="cov8" title="1">target := recAttrs
                if slices.Contains(mapper.ResourceColumns, lc) || strings.HasPrefix(lc, "resource.") </span><span class="cov8" title="1">{
                        lc = strings.TrimPrefix(lc, "resource.")
                        target = resAttrs
                }</span> else<span class="cov8" title="1"> if slices.Contains(mapper.ScopeColumns, lc) || strings.HasPrefix(lc, "scope.") </span><span class="cov8" title="1">{
                        lc = strings.TrimPrefix(lc, "scope.")
                        target = scopeAttrs
                }</span>
                <span class="cov8" title="1">lc = strings.TrimPrefix(lc, "log.")

                // Flatten (may produce multiple keys). Base prefix is lowercased top-level key.
                flattenValue(lc, rawVal, target)</span>
        }

        <span class="cov8" title="1">if ts &lt; 0 </span><span class="cov8" title="1">{
                ts = now
        }</span>

        <span class="cov8" title="1">return TranslatedLog{
                Timestamp:          ts,
                Body:               body,
                ResourceAttributes: resAttrs,
                ScopeAttributes:    scopeAttrs,
                RecordAttributes:   recAttrs,
                RawAttributes:      rawAttrs,
        }</span>
}

// coerceToUnixMillis interprets various input representations and normalizes to Unix milliseconds.
func coerceToUnixMillis(v any, tformat string) (int64, bool) <span class="cov8" title="1">{
        switch t := v.(type) </span>{
        case time.Time:<span class="cov8" title="1">
                return t.UnixMilli(), true</span>

        case *time.Time:<span class="cov8" title="1">
                if t == nil </span><span class="cov8" title="1">{
                        return 0, false
                }</span>
                <span class="cov8" title="1">return t.UnixMilli(), true</span>

        case int64:<span class="cov8" title="1">
                return normalizeEpochToMillis(t)</span>
        case int:<span class="cov8" title="1">
                return normalizeEpochToMillis(int64(t))</span>
        case uint64:<span class="cov8" title="1">
                return normalizeEpochToMillis(int64(t))</span>
        case uint:<span class="cov8" title="1">
                return normalizeEpochToMillis(int64(t))</span>
        case float64:<span class="cov8" title="1">
                return normalizeEpochToMillis(int64(t))</span>

        case string:<span class="cov8" title="1">
                s := strings.TrimSpace(t)
                if s == "" </span><span class="cov8" title="1">{
                        return 0, false
                }</span>
                // integer string?
                <span class="cov8" title="1">if n, err := strconv.ParseInt(s, 10, 64); err == nil </span><span class="cov8" title="1">{
                        return normalizeEpochToMillis(n)
                }</span>
                // formatted timestamp?
                <span class="cov8" title="1">if tformat != "" </span><span class="cov8" title="1">{
                        if ts, err := time.Parse(tformat, s); err == nil </span><span class="cov8" title="1">{
                                return ts.UnixMilli(), true
                        }</span>
                }
        }

        <span class="cov8" title="1">return 0, false</span>
}

const (
        // same thresholds as before, in their original units:
        secondsUpper      = int64(4_000_000_000)     // ~ year 2100 in seconds
        millisecondsUpper = secondsUpper * 1_000     // in milliseconds
        microsecondsUpper = secondsUpper * 1_000_000 // in microseconds
)

// normalizeEpochToMillis guesses the input unit (s, ms, µs, ns) based on magnitude
// and returns milliseconds. Precision finer than 1 ms is truncated.
func normalizeEpochToMillis(n int64) (int64, bool) <span class="cov8" title="1">{
        if n &lt; 0 </span><span class="cov8" title="1">{
                return 0, false
        }</span>
        <span class="cov8" title="1">switch </span>{
        case n &lt; secondsUpper:<span class="cov8" title="1">
                // seconds → ms
                return n * 1_000, true</span>
        case n &lt; millisecondsUpper:<span class="cov8" title="1">
                // already in ms
                return n, true</span>
        case n &lt; microsecondsUpper:<span class="cov8" title="1">
                // µs → ms (drop sub-ms)
                return n / 1_000, true</span>
        default:<span class="cov8" title="1">
                // assume ns → ms (drop sub-ms)
                return n / 1_000_000, true</span>
        }
}

// flattenValue flattens nested structures into dotted / indexed keys.
// Rules:
//
//        map -&gt; prefix.child
//        slice -&gt; prefix[index]
//
// Scalar -&gt; prefix = string(value)
func flattenValue(prefix string, v any, out map[string]string) <span class="cov8" title="1">{
        switch val := v.(type) </span>{
        case map[string]any:<span class="cov8" title="1">
                for k, nested := range val </span><span class="cov8" title="1">{
                        child := k
                        if prefix != "" </span><span class="cov8" title="1">{
                                child = prefix + "." + child
                        }</span>
                        <span class="cov8" title="1">flattenValue(child, nested, out)</span>
                }
        case map[any]any:<span class="cov8" title="1"> // common with YAML
                for rk, nested := range val </span><span class="cov8" title="1">{
                        k := toString(rk)
                        child := k
                        if prefix != "" </span><span class="cov8" title="1">{
                                child = prefix + "." + child
                        }</span>
                        <span class="cov8" title="1">flattenValue(child, nested, out)</span>
                }
        case []any:<span class="cov8" title="1">
                for i, elem := range val </span><span class="cov8" title="1">{
                        flattenValue(prefix+"["+strconv.Itoa(i)+"]", elem, out)
                }</span>
        case []string:<span class="cov8" title="1">
                for i, elem := range val </span><span class="cov8" title="1">{
                        out[prefix+"["+strconv.Itoa(i)+"]"] = elem
                }</span>
        case []int:<span class="cov8" title="1">
                for i, elem := range val </span><span class="cov8" title="1">{
                        out[prefix+"["+strconv.Itoa(i)+"]"] = strconv.FormatInt(int64(elem), 10)
                }</span>
        case []int64:<span class="cov8" title="1">
                for i, elem := range val </span><span class="cov8" title="1">{
                        out[prefix+"["+strconv.Itoa(i)+"]"] = strconv.FormatInt(elem, 10)
                }</span>
        case []float64:<span class="cov8" title="1">
                for i, elem := range val </span><span class="cov8" title="1">{
                        out[prefix+"["+strconv.Itoa(i)+"]"] = strconv.FormatFloat(elem, 'f', -1, 64)
                }</span>
        default:<span class="cov8" title="1">
                out[prefix] = toString(val)</span>
        }
}

// toString renders supported scalar types to string (attributes stored as strings).
func toString(v any) string <span class="cov8" title="1">{
        switch x := v.(type) </span>{
        case string:<span class="cov8" title="1">
                return x</span>
        case []byte:<span class="cov8" title="1">
                return string(x)</span>
        case time.Time:<span class="cov8" title="1">
                return x.Format(time.RFC3339Nano)</span>
        case *time.Time:<span class="cov8" title="1">
                if x == nil </span><span class="cov8" title="1">{
                        return ""
                }</span>
                <span class="cov8" title="1">return x.Format(time.RFC3339Nano)</span>
        case int:<span class="cov8" title="1">
                return strconv.FormatInt(int64(x), 10)</span>
        case int8:<span class="cov8" title="1">
                return strconv.FormatInt(int64(x), 10)</span>
        case int16:<span class="cov8" title="1">
                return strconv.FormatInt(int64(x), 10)</span>
        case int32:<span class="cov8" title="1">
                return strconv.FormatInt(int64(x), 10)</span>
        case int64:<span class="cov8" title="1">
                return strconv.FormatInt(x, 10)</span>
        case uint:<span class="cov8" title="1">
                return strconv.FormatUint(uint64(x), 10)</span>
        case uint8:<span class="cov8" title="1">
                return strconv.FormatUint(uint64(x), 10)</span>
        case uint16:<span class="cov8" title="1">
                return strconv.FormatUint(uint64(x), 10)</span>
        case uint32:<span class="cov8" title="1">
                return strconv.FormatUint(uint64(x), 10)</span>
        case uint64:<span class="cov8" title="1">
                return strconv.FormatUint(x, 10)</span>
        case float32:<span class="cov8" title="1">
                return strconv.FormatFloat(float64(x), 'f', -1, 32)</span>
        case float64:<span class="cov8" title="1">
                return strconv.FormatFloat(x, 'f', -1, 64)</span>
        case bool:<span class="cov8" title="1">
                if x </span><span class="cov8" title="1">{
                        return "true"
                }</span>
                <span class="cov8" title="1">return "false"</span>
        default:<span class="cov8" title="1">
                return fmt.Sprintf("%v", x)</span>
        }
}
</pre>
		
		<pre class="file" id="file49" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package translate

import (
        "strings"
        "time"
)

type Mapper struct {
        TimestampColumns []string
        MessageColumns   []string
        ResourceColumns  []string
        ScopeColumns     []string
        TimeFormat       string
}

type MapperOption func(*Mapper)

func NewMapper(opts ...MapperOption) *Mapper <span class="cov0" title="0">{
        mapper := &amp;Mapper{
                TimestampColumns: []string{
                        "timestamp",
                        "time",
                        "ts",
                },
                MessageColumns: []string{
                        "message",
                        "msg",
                },
                ResourceColumns: nil,
                ScopeColumns:    nil,
                TimeFormat:      time.RFC3339Nano,
        }
        for _, opt := range opts </span><span class="cov0" title="0">{
                opt(mapper)
        }</span>
        <span class="cov0" title="0">return mapper</span>
}

// WithTimestampColumn adds a column to the timestamp.
// If not set, defaults to "timestamp", "time", and "ts".
func WithTimestampColumn(name string) MapperOption <span class="cov0" title="0">{
        return func(m *Mapper) </span><span class="cov0" title="0">{
                m.TimestampColumns = []string{strings.ToLower(name)}
        }</span>
}

// WithMessageColumn adds a column to the message body.
// If not set, defaults to "message" and "msg".
func WithMessageColumn(name string) MapperOption <span class="cov0" title="0">{
        return func(m *Mapper) </span><span class="cov0" title="0">{
                m.MessageColumns = []string{strings.ToLower(name)}
        }</span>
}

// WithResourceColumn adds a column to the resource attributes.
// If not set, defaults to an empty map.
func WithResourceColumns(names []string) MapperOption <span class="cov0" title="0">{
        return func(m *Mapper) </span><span class="cov0" title="0">{
                m.ResourceColumns = names
        }</span>
}

// WithScopeColumn adds a column to the scope attributes.
// If not set, defaults to an empty map.
func WithScopeColumn(names []string) MapperOption <span class="cov0" title="0">{
        return func(m *Mapper) </span><span class="cov0" title="0">{
                m.ScopeColumns = names
        }</span>
}

// WithTimeFormat sets the time format for parsing timestamps.
// See https://pkg.go.dev/time#Parse for supported formats.
// If not set, defaults to time.RFC3339Nano.
func WithTimeFormat(format string) MapperOption <span class="cov0" title="0">{
        return func(m *Mapper) </span><span class="cov0" title="0">{
                m.TimeFormat = format
        }</span>
}
</pre>
		
		<pre class="file" id="file50" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package awsclient

import (
        "context"
        "fmt"
        "sync"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/config"
        "github.com/aws/aws-sdk-go-v2/service/sts"
        "go.opentelemetry.io/contrib/instrumentation/github.com/aws/aws-sdk-go-v2/otelaws"
        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/trace"
)

type Manager struct {
        baseCfg     aws.Config
        stsClient   *sts.Client
        sessionName string

        sync.RWMutex
        providers map[roleKey]aws.CredentialsProvider
        tracer    trace.Tracer
}

// ManagerOption is a functional option for configuring the Manager.
type ManagerOption func(*Manager)

func WithAssumeRoleSessionName(name string) ManagerOption <span class="cov0" title="0">{
        return func(mgr *Manager) </span><span class="cov0" title="0">{
                mgr.sessionName = name
        }</span>
}

// NewManager initializes AWS config + a single STS client.
func NewManager(ctx context.Context, opts ...ManagerOption) (*Manager, error) <span class="cov0" title="0">{
        cfg, err := config.LoadDefaultConfig(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("loading AWS config: %w", err)
        }</span>

        <span class="cov0" title="0">otelaws.AppendMiddlewares(&amp;cfg.APIOptions)

        tracer := otel.Tracer("github.com/cardinalhq/lakerunner/internal/awsclient")
        mgr := &amp;Manager{
                baseCfg:     cfg,
                stsClient:   sts.NewFromConfig(cfg),
                sessionName: "default-session-name",
                providers:   make(map[roleKey]aws.CredentialsProvider),
                tracer:      tracer,
        }
        for _, opt := range opts </span><span class="cov0" title="0">{
                opt(mgr)
        }</span>

        <span class="cov0" title="0">return mgr, nil</span>
}
</pre>
		
		<pre class="file" id="file51" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package awsclient

import (
        "context"
        "crypto/tls"
        "net/http"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/credentials/stscreds"
        "github.com/aws/aws-sdk-go-v2/service/s3"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/internal/storageprofile"
)

type S3Client struct {
        Client *s3.Client
        Tracer trace.Tracer
}

// ----------------------------------------------------------------
// internal config struct for GetS3
// ----------------------------------------------------------------
type s3Config struct {
        RoleARN      string
        Region       string
        applyConfigs []func(*aws.Config)
        applyS3s     []func(*s3.Options)
}

// S3Option is a functional option for GetS3.
type S3Option func(*s3Config)

// WithRole sets the IAM Role ARN to assume (empty = no assume).
func WithRole(roleARN string) S3Option <span class="cov0" title="0">{
        return func(c *s3Config) </span><span class="cov0" title="0">{
                c.RoleARN = roleARN
        }</span>
}

// WithRegion overrides the AWS region for this call.
func WithRegion(region string) S3Option <span class="cov0" title="0">{
        return func(c *s3Config) </span><span class="cov0" title="0">{
                c.Region = region
        }</span>
}

// WithEndpoint forces a custom S3 endpoint (eg MinIO, Ceph).
func WithEndpoint(url string) S3Option <span class="cov0" title="0">{
        return func(c *s3Config) </span><span class="cov0" title="0">{
                c.applyS3s = append(c.applyS3s, func(o *s3.Options) </span><span class="cov0" title="0">{
                        o.BaseEndpoint = aws.String(url)
                }</span>)
        }
}

// WithPathStyle uses path-style addressing instead of virtual-host.
func WithPathStyle() S3Option <span class="cov0" title="0">{
        return func(c *s3Config) </span><span class="cov0" title="0">{
                c.applyS3s = append(c.applyS3s, func(o *s3.Options) </span><span class="cov0" title="0">{
                        o.UsePathStyle = true
                }</span>)
        }
}

// WithInsecureTLS turns off cert verification (for self-signed or insecure).
func WithInsecureTLS() S3Option <span class="cov0" title="0">{
        return func(c *s3Config) </span><span class="cov0" title="0">{
                c.applyConfigs = append(c.applyConfigs, func(cfg *aws.Config) </span><span class="cov0" title="0">{
                        tr := http.DefaultTransport.(*http.Transport).Clone()
                        tr.TLSClientConfig = &amp;tls.Config{InsecureSkipVerify: true}
                        cfg.HTTPClient = &amp;http.Client{Transport: tr}
                }</span>)
        }
}

type roleKey struct {
        Region  string
        RoleARN string
}

func (m *Manager) GetS3(ctx context.Context, opts ...S3Option) (*S3Client, error) <span class="cov0" title="0">{
        sc := s3Config{
                Region: m.baseCfg.Region,
        }
        for _, o := range opts </span><span class="cov0" title="0">{
                o(&amp;sc)
        }</span>

        <span class="cov0" title="0">key := roleKey{Region: sc.Region, RoleARN: sc.RoleARN}
        m.RLock()
        provider, ok := m.providers[key]
        m.RUnlock()
        if !ok </span><span class="cov0" title="0">{
                m.Lock()
                if provider, ok = m.providers[key]; !ok </span><span class="cov0" title="0">{
                        if sc.RoleARN == "" </span><span class="cov0" title="0">{
                                provider = m.baseCfg.Credentials
                        }</span> else<span class="cov0" title="0"> {
                                p := stscreds.NewAssumeRoleProvider(m.stsClient, sc.RoleARN, func(o *stscreds.AssumeRoleOptions) </span><span class="cov0" title="0">{
                                        o.RoleSessionName = m.sessionName
                                }</span>)
                                <span class="cov0" title="0">provider = aws.NewCredentialsCache(p)</span>
                        }
                        <span class="cov0" title="0">m.providers[key] = provider</span>
                }
                <span class="cov0" title="0">m.Unlock()</span>
        }

        <span class="cov0" title="0">cfg := m.baseCfg.Copy()
        cfg.Region = sc.Region
        cfg.Credentials = provider
        for _, fn := range sc.applyConfigs </span><span class="cov0" title="0">{
                fn(&amp;cfg)
        }</span>

        <span class="cov0" title="0">client := s3.NewFromConfig(cfg, sc.applyS3s...)

        return &amp;S3Client{Client: client, Tracer: m.tracer}, nil</span>
}

// helper to bind your StorageProfile
func (m *Manager) GetS3ForProfile(ctx context.Context, p storageprofile.StorageProfile) (*S3Client, error) <span class="cov0" title="0">{
        var opts []S3Option
        if p.Role != "" </span><span class="cov0" title="0">{
                opts = append(opts, WithRole(p.Role))
        }</span>
        <span class="cov0" title="0">if p.Region != "" </span><span class="cov0" title="0">{
                opts = append(opts, WithRegion(p.Region))
        }</span>
        <span class="cov0" title="0">if p.Endpoint != "" </span><span class="cov0" title="0">{
                opts = append(opts, WithEndpoint(p.Endpoint))
        }</span>
        <span class="cov0" title="0">if p.UsePathStyle </span><span class="cov0" title="0">{
                opts = append(opts, WithPathStyle())
        }</span>
        <span class="cov0" title="0">if p.InsecureTLS </span><span class="cov0" title="0">{
                opts = append(opts, WithInsecureTLS())
        }</span>
        <span class="cov0" title="0">return m.GetS3(ctx, opts...)</span>
}

// type customResolverV2 struct{ url string }

// func (r customResolverV2) ResolveEndpoint(
//         ctx context.Context,
//         params s3.EndpointParameters,
// ) (smithyendpoint.Endpoint, error) {
//         return smithyendpoint.Endpoint{
//                 URL:               r.url,
//                 SigningRegion:     params.Region,
//                 HostnameImmutable: true,
//         }, nil
// }
</pre>
		
		<pre class="file" id="file52" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package s3helper

import "github.com/cardinalhq/lakerunner/internal/idgen"

var flake *idgen.SonyFlakeGenerator

func init() <span class="cov8" title="1">{
        var err error
        flake, err = idgen.NewFlakeGenerator()
        if err != nil </span><span class="cov0" title="0">{
                panic(err)</span>
        }
}

func GenerateID() int64 <span class="cov0" title="0">{
        if flake == nil </span><span class="cov0" title="0">{
                panic("flake generator is not initialized")</span>
        }
        <span class="cov0" title="0">id := flake.NextID()
        return id</span>
}
</pre>
		
		<pre class="file" id="file53" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package s3helper

import (
        "context"
        "errors"
        "fmt"
        "os"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/feature/s3/manager"
        "github.com/aws/aws-sdk-go-v2/service/s3"
        "github.com/aws/aws-sdk-go-v2/service/s3/types"
        "github.com/google/uuid"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/lrdb"
)

func S3ErrorIs404(err error) bool <span class="cov0" title="0">{
        var noKeyErr *types.NoSuchKey
        return errors.As(err, &amp;noKeyErr)
}</span>

func DownloadS3Object(
        ctx context.Context,
        dir string,
        s3client *awsclient.S3Client,
        bucketID, objectID string,
) (tmpfile string, size int64, notFound bool, err error) <span class="cov0" title="0">{
        downloader := manager.NewDownloader(s3client.Client)

        f, err := os.CreateTemp(dir, "s3-*.parquet")
        if err != nil </span><span class="cov0" title="0">{
                return "", 0, false, fmt.Errorf("create temp file: %w", err)
        }</span>

        <span class="cov0" title="0">ctx, span := s3client.Tracer.Start(ctx, "s3helper.DownloadS3Object",
                trace.WithAttributes(
                        attribute.String("bucketID", bucketID),
                        attribute.String("objectID", objectID),
                ),
        )
        defer span.End()

        size, err = downloader.Download(ctx, f, &amp;s3.GetObjectInput{
                Bucket: aws.String(bucketID),
                Key:    aws.String(objectID),
        })
        if err != nil </span><span class="cov0" title="0">{
                _ = f.Close()
                _ = os.Remove(f.Name())
                if S3ErrorIs404(err) </span><span class="cov0" title="0">{
                        return "", 0, true, nil
                }</span>
                <span class="cov0" title="0">return "", 0, false, fmt.Errorf("download %s/%s: %w", bucketID, objectID, err)</span>
        }

        // close on success; ignore close error because the bytes are already flushed by the SDK
        <span class="cov0" title="0">_ = f.Close()
        return f.Name(), size, false, nil</span>
}

func UploadS3Object(ctx context.Context, s3client *awsclient.S3Client, bucketID, objectID string, sourceFilename string) error <span class="cov0" title="0">{
        uploader := manager.NewUploader(s3client.Client)
        file, err := os.Open(sourceFilename)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to open temporarily file %s: %w", sourceFilename, err)
        }</span>
        <span class="cov0" title="0">defer file.Close()

        var span trace.Span
        ctx, span = s3client.Tracer.Start(ctx, "s3helper.UploadS3Object",
                trace.WithAttributes(
                        attribute.String("bucketID", bucketID),
                ),
        )
        defer span.End()

        _, err = uploader.Upload(ctx, &amp;s3.PutObjectInput{
                Bucket:      aws.String(bucketID),
                Key:         aws.String(objectID),
                Body:        file,
                ContentType: aws.String("application/vnd.apache.parquet"),
                Metadata: map[string]string{
                        "writer": "lakerunner-go",
                },
        })
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to upload S3 object: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func DeleteS3Object(ctx context.Context, s3client *awsclient.S3Client, bucketID, objectID string) error <span class="cov0" title="0">{
        var span trace.Span
        ctx, span = s3client.Tracer.Start(ctx, "s3helper.DeleteS3Object",
                trace.WithAttributes(
                        attribute.String("bucketID", bucketID),
                ),
        )
        defer span.End()

        _, err := s3client.Client.DeleteObject(ctx, &amp;s3.DeleteObjectInput{
                Bucket: aws.String(bucketID),
                Key:    aws.String(objectID),
        })
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to delete S3 object: %w", err)
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// func deleteS3Objects(ctx context.Context, s3client *s3.Client, bucketID string, objectIDs []string) error {
//         oids := make([]types.ObjectIdentifier, len(objectIDs))
//         for i, id := range objectIDs {
//                 oids[i] = types.ObjectIdentifier{
//                         Key: aws.String(id),
//                 }
//         }
//         result, err := s3client.DeleteObjects(ctx, &amp;s3.DeleteObjectsInput{
//                 Bucket: aws.String(bucketID),
//                 Delete: &amp;types.Delete{
//                         Objects: oids,
//                         Quiet:   aws.Bool(true), // only return errors
//                 },
//         })
//         if err != nil {
//                 slog.Error("Failed to bunk delete objects", slog.Any("error", err))
//                 return err
//         }
//         for _, err := range result.Errors {
//                 slog.Error("Failed to delete S3 object", slog.String("objectID", *err.Key), slog.Any("error", err.Message))
//         }
//         return nil
// }

func ScheduleS3Delete(ctx context.Context, mdb lrdb.StoreFull, org_id uuid.UUID, instance_num int16, bucketID, objectID string) error <span class="cov0" title="0">{
        return mdb.ObjectCleanupAdd(ctx, lrdb.ObjectCleanupAddParams{
                OrganizationID: org_id,
                InstanceNum:    instance_num,
                BucketID:       bucketID,
                ObjectID:       objectID,
        })
}</span>
</pre>
		
		<pre class="file" id="file54" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package s3helper

import (
        "time"
)

func HourFromMillis(ms int64) int16 <span class="cov8" title="1">{
        t := time.UnixMilli(ms).UTC()
        return int16(t.Hour())
}</span>
</pre>
		
		<pre class="file" id="file55" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package awsclient

import (
        "context"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/credentials/stscreds"
        "github.com/aws/aws-sdk-go-v2/service/sqs"
        "go.opentelemetry.io/otel/trace"

        "github.com/cardinalhq/lakerunner/internal/storageprofile"
)

type SQSClient struct {
        Client *sqs.Client
        Tracer trace.Tracer
}

// ----------------------------------------------------------------
// internal config struct for GetSQS
// ----------------------------------------------------------------
type sqsConfig struct {
        RoleARN      string
        Region       string
        applyConfigs []func(*aws.Config)
        applySQSs    []func(*sqs.Options)
}

// SQSOption is a functional option for GetSQS.
type SQSOption func(*sqsConfig)

// WithSQSRole sets the IAM Role ARN to assume (empty = no assume).
func WithSQSRole(roleARN string) SQSOption <span class="cov0" title="0">{
        return func(c *sqsConfig) </span><span class="cov0" title="0">{
                c.RoleARN = roleARN
        }</span>
}

// WithSQSRegion overrides the AWS region for this call.
func WithSQSRegion(region string) SQSOption <span class="cov0" title="0">{
        return func(c *sqsConfig) </span><span class="cov0" title="0">{
                c.Region = region
        }</span>
}

func (m *Manager) GetSQS(ctx context.Context, opts ...SQSOption) (*SQSClient, error) <span class="cov0" title="0">{
        sc := sqsConfig{
                Region: m.baseCfg.Region,
        }
        for _, o := range opts </span><span class="cov0" title="0">{
                o(&amp;sc)
        }</span>

        <span class="cov0" title="0">key := roleKey{Region: sc.Region, RoleARN: sc.RoleARN}
        m.RLock()
        provider, ok := m.providers[key]
        m.RUnlock()
        if !ok </span><span class="cov0" title="0">{
                m.Lock()
                if provider, ok = m.providers[key]; !ok </span><span class="cov0" title="0">{
                        if sc.RoleARN == "" </span><span class="cov0" title="0">{
                                provider = m.baseCfg.Credentials
                        }</span> else<span class="cov0" title="0"> {
                                p := stscreds.NewAssumeRoleProvider(m.stsClient, sc.RoleARN, func(o *stscreds.AssumeRoleOptions) </span><span class="cov0" title="0">{
                                        o.RoleSessionName = m.sessionName
                                }</span>)
                                <span class="cov0" title="0">provider = aws.NewCredentialsCache(p)</span>
                        }
                        <span class="cov0" title="0">m.providers[key] = provider</span>
                }
                <span class="cov0" title="0">m.Unlock()</span>
        }

        <span class="cov0" title="0">cfg := m.baseCfg.Copy()
        cfg.Region = sc.Region
        cfg.Credentials = provider
        for _, fn := range sc.applyConfigs </span><span class="cov0" title="0">{
                fn(&amp;cfg)
        }</span>

        <span class="cov0" title="0">client := sqs.NewFromConfig(cfg, sc.applySQSs...)

        return &amp;SQSClient{Client: client, Tracer: m.tracer}, nil</span>
}

// helper to bind your StorageProfile
func (m *Manager) GetSQSForProfile(ctx context.Context, p storageprofile.StorageProfile) (*SQSClient, error) <span class="cov0" title="0">{
        var opts []SQSOption
        if p.Role != "" </span><span class="cov0" title="0">{
                opts = append(opts, WithSQSRole(p.Role))
        }</span>
        <span class="cov0" title="0">if p.Region != "" </span><span class="cov0" title="0">{
                opts = append(opts, WithSQSRegion(p.Region))
        }</span>
        <span class="cov0" title="0">return m.GetSQS(ctx, opts...)</span>
}
</pre>
		
		<pre class="file" id="file56" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

// Package buffet provides a buffered Parquet writer that
//  1. gob-spills every row to disk,
//  2. remembers which columns ever had non-nil values,
//  3. on Close(), splits buffered rows into one or more Parquet files
//     (based on max rows per file and an optional grouping function),
//     streams rows back out into Parquet files, and returns a slice of Results.
//
// The minimal schema is built from any column written to the Writer with non-nil values.
// This means that, depending on the pattern of your written data and how the files are
// split on output, a file may have columns that are entirely empty.  As we use
// this as a final stage output from reading many input files, this is usually not a
// problem, as the input file's records will typically be spread throughout the output files,
// resulting in all the columns being used anyway.
package buffet

import (
        "encoding/gob"
        "errors"
        "fmt"
        "io"
        "os"
        "sort"

        "github.com/parquet-go/parquet-go"
)

// GroupFunc determines whether two consecutive rows must be written to the same Parquet file.
// Return true to force previous and current rows into the same file, even if maxRowsPerFile is reached.
type GroupFunc func(prev, current map[string]any) bool

// Define the per-file accumulator interface:
type StatsAccumulator interface {
        // Add is called once per row.
        Add(row map[string]any)
        // Finalize is called exactly once, after the last row.
        // It can return any summary type (e.g. a struct, map, number…).
        Finalize() any
}

// Define the provider interface that the caller implements:
type StatsProvider interface {
        // NewAccumulator is called whenever you open a new Parquet file.
        NewAccumulator() StatsAccumulator
}

const FileSizeUnavailable = int64(-1)

type Writer struct {
        // spill
        tmp     *os.File
        encoder *gob.Encoder
        // state for gob spill
        count int64
        // for schema and parquet output
        baseName    string
        schemaNodes map[string]parquet.Node
        tmpdir      string
        rowsPerFile int64
        groupFunc   GroupFunc
        closed      bool
        seenCols    map[string]bool
        keepCols    []string
        statsProv   StatsProvider
        currentAcc  StatsAccumulator
}

type Result struct {
        FileName    string // path to the .parquet file, in temp dir
        RecordCount int64  // how many rows in this file
        FileSize    int64  // size of the Parquet file in bytes
        Stats       any    // stats from StatsAccumulator, if provided
}

func init() <span class="cov8" title="1">{
        // Register the concrete types we expect in record values.
        gob.Register(map[string]any{})
        gob.Register(int64(0))
        gob.Register(float64(0))
        gob.Register(string(""))
        gob.Register(bool(false))
}</span>

type WriterOption interface {
        apply(*Writer)
}

func WithGroupFunc(f GroupFunc) WriterOption <span class="cov0" title="0">{
        return &amp;groupFuncOption{f: f}
}</span>

type groupFuncOption struct {
        f GroupFunc
}

func (o *groupFuncOption) apply(w *Writer) <span class="cov0" title="0">{
        w.groupFunc = o.f
}</span>

func WithStatsProvider(p StatsProvider) WriterOption <span class="cov0" title="0">{
        return &amp;statsProviderOption{p: p}
}</span>

type statsProviderOption struct {
        p StatsProvider
}

func (o *statsProviderOption) apply(w *Writer) <span class="cov0" title="0">{
        w.statsProv = o.p
}</span>

// WithStatsAccumulator is a convenience function to use a StatsProvider with a single accumulator.
// NewWriter sets up a new spill file and remembers your base schema.
// baseName is used as the “row group name” in NewSchema (for metadata).
//
// rowsPerFile controls how many rows to write per Parquet file. If &lt;= 0, all rows go into a single file.
// groupFunc can be nil; if non-nil, it is used to force rows into the same file even if rowsPerFile is reached.
//
// All files are created in tmpdir, and this directory must be cleaned up by the caller.
// Files will remain in tmpdir both after Close() and if an error occurs.
// The common pattern is to create a per-work-item tmpdir, use it, and remove the
// entire tmpdir when all files are no longer needed.
//
// Writers are not concurrency-safe.
func NewWriter(
        baseName string,
        tmpdir string,
        schemaNodes map[string]parquet.Node,
        rowsPerfile int64,
        opts ...WriterOption,
) (*Writer, error) <span class="cov0" title="0">{
        tmp, err := os.CreateTemp(tmpdir, "buffet-*.gob")
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("buffet: create temp spill file: %w", err)
        }</span>

        <span class="cov0" title="0">for name, node := range schemaNodes </span><span class="cov0" title="0">{
                if name == "" </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("buffet: schema node name cannot be empty")
                }</span>
                <span class="cov0" title="0">if node == nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("buffet: schema node %q cannot be nil", name)
                }</span>
        }

        <span class="cov0" title="0">writer := &amp;Writer{
                tmp:         tmp,
                encoder:     gob.NewEncoder(tmp),
                baseName:    baseName,
                schemaNodes: schemaNodes,
                tmpdir:      tmpdir,
                rowsPerFile: rowsPerfile,
                seenCols:    make(map[string]bool),
        }

        for _, opt := range opts </span><span class="cov0" title="0">{
                opt.apply(writer)
        }</span>

        <span class="cov0" title="0">return writer, nil</span>
}

// Write gob-encodes one record (map[string]any) and increments the spill count.
func (w *Writer) Write(row map[string]any) error <span class="cov0" title="0">{
        if w.closed </span><span class="cov0" title="0">{
                return ErrAlreadyClosed
        }</span>

        // ensure we don't have any columns that are not in the schema
        <span class="cov0" title="0">for k := range row </span><span class="cov0" title="0">{
                if _, ok := w.schemaNodes[k]; !ok </span><span class="cov0" title="0">{
                        return fmt.Errorf("buffet: write row with column %q not in the schema node list", k)
                }</span>
        }

        <span class="cov0" title="0">if err := w.encoder.Encode(row); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("buffet: gob-encode row: %w", err)
        }</span>
        <span class="cov0" title="0">w.count++

        for k, v := range row </span><span class="cov0" title="0">{
                if v != nil </span><span class="cov0" title="0">{
                        w.seenCols[k] = true
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

var (
        ErrAlreadyClosed = errors.New("buffet: writer already closed")
)

// Abort stops any further operations, closes the spill file, and removes it.
func (w *Writer) Abort() <span class="cov0" title="0">{
        if w.closed </span><span class="cov0" title="0">{
                return
        }</span>
        <span class="cov0" title="0">w.closed = true
        if w.tmp != nil </span><span class="cov0" title="0">{
                _ = w.tmp.Close()
                _ = os.Remove(w.tmp.Name())
        }</span>
}

// Close finalizes the spill, splits rows into Parquet files based on maxRowsPerFile and groupFunc,
// writes out those Parquet files, cleans up the temp spill, and returns a slice of Results.
// If no rows were written (count == 0), it removes the spill and returns an empty slice.
func (w *Writer) Close() ([]Result, error) <span class="cov0" title="0">{
        if w.closed </span><span class="cov0" title="0">{
                return nil, ErrAlreadyClosed
        }</span>
        <span class="cov0" title="0">w.closed = true

        // --- tear down the spill file ---
        if err := w.tmp.Close(); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("buffet: close spill: %w", err)
        }</span>
        <span class="cov0" title="0">if w.count == 0 </span><span class="cov0" title="0">{
                os.Remove(w.tmp.Name())
                return nil, nil
        }</span>

        <span class="cov0" title="0">in, err := os.Open(w.tmp.Name())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("buffet: reopen spill: %w", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                in.Close()
                os.Remove(w.tmp.Name())
        }</span>()
        <span class="cov0" title="0">decoder := gob.NewDecoder(in)

        // --- compute global keepCols &amp; schema once ---
        w.keepCols = make([]string, 0, len(w.seenCols))
        for c := range w.seenCols </span><span class="cov0" title="0">{
                w.keepCols = append(w.keepCols, c)
        }</span>
        <span class="cov0" title="0">sort.Strings(w.keepCols)
        nodes := make(map[string]parquet.Node, len(w.keepCols))
        for _, c := range w.keepCols </span><span class="cov0" title="0">{
                nodes[c] = w.schemaNodes[c]
        }</span>
        <span class="cov0" title="0">schema := parquet.NewSchema(w.baseName, parquet.Group(nodes))
        wc, err := parquet.NewWriterConfig(WriterOptions(w.tmpdir, schema)...)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("buffet: writer config: %w", err)
        }</span>

        <span class="cov0" title="0">var outFile *os.File
        var pw *parquet.GenericWriter[map[string]any]
        var rowsInFile int64

        openNext := func() error </span><span class="cov0" title="0">{
                f, err := os.CreateTemp(w.tmpdir, "buffet-*.parquet")
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">outFile = f
                pw = parquet.NewGenericWriter[map[string]any](f, wc)
                if w.statsProv != nil </span><span class="cov0" title="0">{
                        w.currentAcc = w.statsProv.NewAccumulator()
                }</span>
                <span class="cov0" title="0">rowsInFile = 0
                return nil</span>
        }

        <span class="cov0" title="0">closeCurrent := func() </span><span class="cov0" title="0">{
                if pw != nil </span><span class="cov0" title="0">{
                        pw.Close()
                }</span>
                <span class="cov0" title="0">if outFile != nil </span><span class="cov0" title="0">{
                        outFile.Close()
                }</span>
                <span class="cov0" title="0">if rowsInFile == 0 &amp;&amp; outFile != nil </span><span class="cov0" title="0">{
                        os.Remove(outFile.Name())
                }</span>
        }

        <span class="cov0" title="0">var results []Result
        var prevRow map[string]any

        for </span><span class="cov0" title="0">{
                var row map[string]any
                if err := decoder.Decode(&amp;row); err != nil </span><span class="cov0" title="0">{
                        if errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                                break</span>
                        }
                        <span class="cov0" title="0">closeCurrent()
                        return nil, fmt.Errorf("buffet: gob-decode: %w", err)</span>
                }

                <span class="cov0" title="0">if pw == nil </span><span class="cov0" title="0">{
                        if err := openNext(); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("buffet: open first parquet file: %w", err)
                        }</span>
                }

                <span class="cov0" title="0">if w.rowsPerFile &gt; 0 &amp;&amp; rowsInFile &gt;= w.rowsPerFile &amp;&amp;
                        !(w.groupFunc != nil &amp;&amp; prevRow != nil &amp;&amp; w.groupFunc(prevRow, row)) </span><span class="cov0" title="0">{
                        closeCurrent()
                        results = append(results, Result{
                                FileName:    outFile.Name(),
                                RecordCount: rowsInFile,
                        })
                        if err := openNext(); err != nil </span><span class="cov0" title="0">{
                                return nil, fmt.Errorf("buffet: open next parquet file: %w", err)
                        }</span>
                }

                <span class="cov0" title="0">filtered := make(map[string]any, len(w.keepCols))
                for _, c := range w.keepCols </span><span class="cov0" title="0">{
                        filtered[c] = row[c]
                }</span>

                <span class="cov0" title="0">if _, err := pw.Write([]map[string]any{filtered}); err != nil </span><span class="cov0" title="0">{
                        pw.Close()
                        outFile.Close()
                        os.Remove(outFile.Name())
                        return nil, fmt.Errorf("buffet: write row: %w", err)
                }</span>
                <span class="cov0" title="0">if w.currentAcc != nil </span><span class="cov0" title="0">{
                        w.currentAcc.Add(filtered)
                }</span>
                <span class="cov0" title="0">rowsInFile++
                prevRow = row</span>
        }

        <span class="cov0" title="0">if pw != nil </span><span class="cov0" title="0">{
                closeCurrent()
                if rowsInFile &gt; 0 </span><span class="cov0" title="0">{
                        var stats any
                        if w.currentAcc != nil </span><span class="cov0" title="0">{
                                stats = w.currentAcc.Finalize()
                        }</span>
                        <span class="cov0" title="0">results = append(results, Result{
                                FileName:    outFile.Name(),
                                RecordCount: rowsInFile,
                                Stats:       stats,
                        })</span>
                }
        }

        <span class="cov0" title="0">for i := range results </span><span class="cov0" title="0">{
                if info, err := os.Stat(results[i].FileName); err == nil </span><span class="cov0" title="0">{
                        results[i].FileSize = info.Size()
                }</span> else<span class="cov0" title="0"> {
                        results[i].FileSize = FileSizeUnavailable
                }</span>
        }

        <span class="cov0" title="0">return results, nil</span>
}
</pre>
		
		<pre class="file" id="file57" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package buffet

import (
        "fmt"
        "maps"

        "github.com/parquet-go/parquet-go"
)

// NodeMapBuilder accumulates multiple example rows (map[string]any) and produces
// a consolidated map[string]parquet.Node. It ensures that fields with the same
// key have compatible types across all added examples.
type NodeMapBuilder struct {
        nodes map[string]parquet.Node
}

// NewNodeMapBuilder initializes an empty builder.
func NewNodeMapBuilder() *NodeMapBuilder <span class="cov8" title="1">{
        return &amp;NodeMapBuilder{nodes: make(map[string]parquet.Node)}
}</span>

// Add inspects the fields of example (a map[string]any) and merges their types
// into the builder. If a field name already exists but the new node’s String()
// differs, Add returns an error.
func (b *NodeMapBuilder) Add(example map[string]any) error <span class="cov8" title="1">{
        for name, val := range example </span><span class="cov8" title="1">{
                if val == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">node, err := ParquetNodeFromType(name, val)
                if err != nil </span><span class="cov8" title="1">{
                        return fmt.Errorf("failed to build node for field %q: %w", name, err)
                }</span>
                <span class="cov8" title="1">if existing, ok := b.nodes[name]; ok </span><span class="cov8" title="1">{
                        if !parquet.EqualNodes(existing, node) </span><span class="cov8" title="1">{
                                return fmt.Errorf(
                                        "type mismatch for field %q: existing=%s, new=%s",
                                        name, existing.String(), node.String(),
                                )
                        }</span>
                } else<span class="cov8" title="1"> {
                        b.nodes[name] = node
                }</span>
        }
        <span class="cov8" title="1">return nil</span>
}

func (b *NodeMapBuilder) AddNodes(nodes map[string]parquet.Node) error <span class="cov0" title="0">{
        for name, node := range nodes </span><span class="cov0" title="0">{
                if existing, ok := b.nodes[name]; ok </span><span class="cov0" title="0">{
                        if !parquet.EqualNodes(existing, node) </span><span class="cov0" title="0">{
                                return fmt.Errorf(
                                        "type mismatch for field %q: existing=%s, new=%s",
                                        name, existing.String(), node.String(),
                                )
                        }</span>
                } else<span class="cov0" title="0"> {
                        b.nodes[name] = node
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// Build returns a copy of the consolidated node map. You can pass this into
// NewAutoMapWriterWithNodeMap().
func (b *NodeMapBuilder) Build() map[string]parquet.Node <span class="cov8" title="1">{
        out := make(map[string]parquet.Node, len(b.nodes))
        maps.Copy(out, b.nodes) // Copy the map to avoid external mutations
        return out
}</span>
</pre>
		
		<pre class="file" id="file58" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package buffet

import (
        "fmt"

        "github.com/parquet-go/parquet-go"
)

func WriterOptions(tmpdir string, schema *parquet.Schema) []parquet.WriterOption <span class="cov8" title="1">{
        return []parquet.WriterOption{
                schema,
                parquet.Compression(&amp;parquet.Zstd),
                parquet.PageBufferSize(32 * 1024),
                parquet.ColumnIndexSizeLimit(1024),
                parquet.MaxRowsPerRowGroup(80_000),
                parquet.DataPageStatistics(true),
                parquet.ColumnPageBuffers(
                        parquet.NewFileBufferPool(tmpdir, "buffers.*"),
                ),
        }
}</span>

var dictionaryFieldOverride = map[string]bool{
        "_cardinalhq.message": false,
        "_cardinalhq.tid":     false,
}

// wantDictionary returns true if the field should use dictionary encoding.
// The default is true, but can be overridded in the dictionaryFieldOverride map.
func wantDictionary(name string) bool <span class="cov8" title="1">{
        v, ok := dictionaryFieldOverride[name]
        if ok </span><span class="cov0" title="0">{
                return v
        }</span>
        <span class="cov8" title="1">return true</span>
}

// ParquetNodeFromType returns a parquet.Node for the given Go type.
// Not all types are supported.
func ParquetNodeFromType(name string, t any) (parquet.Node, error) <span class="cov8" title="1">{
        enc := func(n parquet.Node) parquet.Node </span><span class="cov8" title="1">{
                if n.Leaf() &amp;&amp; wantDictionary(name) </span><span class="cov8" title="1">{
                        n = parquet.Encoded(n, &amp;parquet.RLEDictionary)
                }</span>
                <span class="cov8" title="1">return n</span>
        }

        <span class="cov8" title="1">switch t.(type) </span>{
        case byte:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Uint(8))), nil</span>
        case []byte:<span class="cov8" title="1">
                return parquet.Optional(parquet.Leaf(parquet.ByteArrayType)), nil</span>

        case int8:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Int(8))), nil</span>
        case []int8:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Int(8)))), nil</span>

        case int16:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Int(16))), nil</span>
        case []int16:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Int(16)))), nil</span>

        case int32:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Int(32))), nil</span>
        case []int32:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Int(32)))), nil</span>

        case int64:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Int(64))), nil</span>
        case []int64:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Int(64)))), nil</span>

        case float32:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Leaf(parquet.FloatType))), nil</span>
        case []float32:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Leaf(parquet.FloatType)))), nil</span>

        case float64:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Leaf(parquet.DoubleType))), nil</span>
        case []float64:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Leaf(parquet.DoubleType)))), nil</span>

        case string:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.String())), nil</span>
        case []string:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.String()))), nil</span>

        case bool:<span class="cov8" title="1">
                return parquet.Optional(enc(parquet.Leaf(parquet.BooleanType))), nil</span>
        case []bool:<span class="cov8" title="1">
                return parquet.Optional(parquet.List(enc(parquet.Leaf(parquet.BooleanType)))), nil</span>

        default:<span class="cov8" title="1">
                return nil, fmt.Errorf("unsupported type %T", t)</span>
        }
}

func NodesFromMap(nodes map[string]parquet.Node, tags map[string]any) error <span class="cov0" title="0">{
        for k, v := range tags </span><span class="cov0" title="0">{
                if v == nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">node, err := ParquetNodeFromType(k, v)
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("parquet node from type for key %s: %w", k, err)
                }</span>
                <span class="cov0" title="0">if on, ok := nodes[k]; ok </span><span class="cov0" title="0">{
                        if !parquet.EqualNodes(on, node) </span><span class="cov0" title="0">{
                                return fmt.Errorf("type mismatch for key %s: existing %T, new %T", k, on, node)
                        }</span>
                        <span class="cov0" title="0">continue</span>
                }
                <span class="cov0" title="0">nodes[k] = node</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func ParquetSchemaFromNodemap(name string, fields map[string]parquet.Node) (*parquet.Schema, error) <span class="cov8" title="1">{
        return parquet.NewSchema(name, parquet.Group(fields)), nil
}</span>
</pre>
		
		<pre class="file" id="file59" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: c_tables.sql

package configdb

import (
        "context"

        "github.com/google/uuid"
)

const getStorageProfileByCollectorNameUncached = `-- name: GetStorageProfileByCollectorNameUncached :one
SELECT
  sp.cloud_provider AS cloud_provider,
  sp.region AS region,
  sp.role AS role,
  sp.hosted AS hosted,
  sp.bucket AS bucket,
  c.instance_num::SMALLINT AS instance_num,
  c.organization_id::UUID AS organization_id,
  c.external_id::TEXT AS external_id
FROM
  c_storage_profiles sp
  LEFT OUTER JOIN c_collectors c ON c.storage_profile_id = sp.id
WHERE
  c.deleted_at IS NULL
  AND c.organization_id = $1
  AND c.external_id = $2
`

type GetStorageProfileByCollectorNameParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        CollectorName  string    `json:"collector_name"`
}

type GetStorageProfileByCollectorNameRow struct {
        CloudProvider  string    `json:"cloud_provider"`
        Region         string    `json:"region"`
        Role           *string   `json:"role"`
        Hosted         bool      `json:"hosted"`
        Bucket         string    `json:"bucket"`
        InstanceNum    int16     `json:"instance_num"`
        OrganizationID uuid.UUID `json:"organization_id"`
        ExternalID     string    `json:"external_id"`
}

func (q *Queries) GetStorageProfileByCollectorNameUncached(ctx context.Context, arg GetStorageProfileByCollectorNameParams) (GetStorageProfileByCollectorNameRow, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, getStorageProfileByCollectorNameUncached, arg.OrganizationID, arg.CollectorName)
        var i GetStorageProfileByCollectorNameRow
        err := row.Scan(
                &amp;i.CloudProvider,
                &amp;i.Region,
                &amp;i.Role,
                &amp;i.Hosted,
                &amp;i.Bucket,
                &amp;i.InstanceNum,
                &amp;i.OrganizationID,
                &amp;i.ExternalID,
        )
        return i, err
}</span>

const getStorageProfileUncached = `-- name: GetStorageProfileUncached :one
SELECT
  sp.cloud_provider AS cloud_provider,
  sp.region AS region,
  sp.role AS role,
  sp.hosted AS hosted,
  sp.bucket AS bucket,
  c.instance_num::SMALLINT AS instance_num,
  c.organization_id::UUID AS organization_id,
  c.external_id::TEXT AS external_id
FROM
  c_storage_profiles sp
  LEFT OUTER JOIN c_collectors c ON c.storage_profile_id = sp.id
WHERE
  c.deleted_at IS NULL
  AND c.organization_id = $1
  AND c.instance_num = $2
`

type GetStorageProfileParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        InstanceNum    int16     `json:"instance_num"`
}

type GetStorageProfileRow struct {
        CloudProvider  string    `json:"cloud_provider"`
        Region         string    `json:"region"`
        Role           *string   `json:"role"`
        Hosted         bool      `json:"hosted"`
        Bucket         string    `json:"bucket"`
        InstanceNum    int16     `json:"instance_num"`
        OrganizationID uuid.UUID `json:"organization_id"`
        ExternalID     string    `json:"external_id"`
}

func (q *Queries) GetStorageProfileUncached(ctx context.Context, arg GetStorageProfileParams) (GetStorageProfileRow, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, getStorageProfileUncached, arg.OrganizationID, arg.InstanceNum)
        var i GetStorageProfileRow
        err := row.Scan(
                &amp;i.CloudProvider,
                &amp;i.Region,
                &amp;i.Role,
                &amp;i.Hosted,
                &amp;i.Bucket,
                &amp;i.InstanceNum,
                &amp;i.OrganizationID,
                &amp;i.ExternalID,
        )
        return i, err
}</span>

const getStorageProfilesByBucketNameUncached = `-- name: GetStorageProfilesByBucketNameUncached :many
SELECT
  sp.cloud_provider AS cloud_provider,
  sp.region AS region,
  sp.role AS role,
  sp.hosted AS hosted,
  sp.bucket AS bucket,
  c.instance_num::SMALLINT AS instance_num,
  c.organization_id::UUID AS organization_id,
  c.external_id::TEXT AS external_id
FROM
  c_storage_profiles sp
  LEFT OUTER JOIN c_collectors c ON c.storage_profile_id = sp.id
WHERE
  c.deleted_at IS NULL
  AND sp.bucket = $1
`

type GetStorageProfilesByBucketNameRow struct {
        CloudProvider  string    `json:"cloud_provider"`
        Region         string    `json:"region"`
        Role           *string   `json:"role"`
        Hosted         bool      `json:"hosted"`
        Bucket         string    `json:"bucket"`
        InstanceNum    int16     `json:"instance_num"`
        OrganizationID uuid.UUID `json:"organization_id"`
        ExternalID     string    `json:"external_id"`
}

func (q *Queries) GetStorageProfilesByBucketNameUncached(ctx context.Context, bucketName string) ([]GetStorageProfilesByBucketNameRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, getStorageProfilesByBucketNameUncached, bucketName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []GetStorageProfilesByBucketNameRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i GetStorageProfilesByBucketNameRow
                if err := rows.Scan(
                        &amp;i.CloudProvider,
                        &amp;i.Region,
                        &amp;i.Role,
                        &amp;i.Hosted,
                        &amp;i.Bucket,
                        &amp;i.InstanceNum,
                        &amp;i.OrganizationID,
                        &amp;i.ExternalID,
                ); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}
</pre>
		
		<pre class="file" id="file60" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0

package configdb

import (
        "context"

        "github.com/jackc/pgx/v5"
        "github.com/jackc/pgx/v5/pgconn"
)

type DBTX interface {
        Exec(context.Context, string, ...interface{}) (pgconn.CommandTag, error)
        Query(context.Context, string, ...interface{}) (pgx.Rows, error)
        QueryRow(context.Context, string, ...interface{}) pgx.Row
}

func New(db DBTX) *Queries <span class="cov0" title="0">{
        return &amp;Queries{db: db}
}</span>

type Queries struct {
        db DBTX
}

func (q *Queries) WithTx(tx pgx.Tx) *Queries <span class="cov0" title="0">{
        return &amp;Queries{
                db: tx,
        }
}</span>
</pre>
		
		<pre class="file" id="file61" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package configdb

import (
        "context"
        "time"

        "github.com/jackc/pgx/v5/pgxpool"
        "github.com/pgx-contrib/pgxotel"
)

// NewConnectionPool creates a new connection pool
// using the PostgreSQL connection string provided, and
// using pgx v5.
func NewConnectionPool(ctx context.Context, url string) (*pgxpool.Pool, error) <span class="cov0" title="0">{
        cfg, err := pgxpool.ParseConfig(url)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">cfg.ConnConfig.Tracer = &amp;pgxotel.QueryTracer{
                Name: "configdb",
        }

        // Pool sizing
        cfg.MaxConns = 10
        cfg.MinConns = 1
        cfg.MinIdleConns = 1

        // Lifetimes &amp; health
        cfg.MaxConnIdleTime = 2 * time.Minute
        cfg.MaxConnLifetime = 30 * time.Minute
        cfg.MaxConnLifetimeJitter = 5 * time.Minute
        cfg.HealthCheckPeriod = 30 * time.Second

        return pgxpool.NewWithConfig(ctx, cfg)</span>
}
</pre>
		
		<pre class="file" id="file62" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package configdb

import (
        "context"
        "errors"

        "github.com/jellydator/ttlcache/v3"
)

type StorageProfileCacheValue struct {
        GetStorageProfileRow
        error
}

func (store *Store) GetStorageProfile(ctx context.Context, params GetStorageProfileParams) (GetStorageProfileRow, error) <span class="cov0" title="0">{
        loader := ttlcache.LoaderFunc[GetStorageProfileParams, StorageProfileCacheValue](
                func(cache *ttlcache.Cache[GetStorageProfileParams, StorageProfileCacheValue], key GetStorageProfileParams) *ttlcache.Item[GetStorageProfileParams, StorageProfileCacheValue] </span><span class="cov0" title="0">{
                        row, err := store.Queries.GetStorageProfileUncached(ctx, key)
                        item := cache.Set(key, StorageProfileCacheValue{
                                GetStorageProfileRow: row,
                                error:                err,
                        }, ttlcache.DefaultTTL)
                        return item
                }</span>,
        )
        <span class="cov0" title="0">v := store.storageProfileCache.Get(params, ttlcache.WithLoader(loader))
        if v != nil </span><span class="cov0" title="0">{
                return v.Value().GetStorageProfileRow, v.Value().error
        }</span>
        <span class="cov0" title="0">return GetStorageProfileRow{}, errors.New("failed to get storage profile from cache")</span>
}

type StorageProfileByNameCacheValue struct {
        GetStorageProfileByCollectorNameRow
        error
}

func (store *Store) GetStorageProfileByCollectorName(ctx context.Context, params GetStorageProfileByCollectorNameParams) (GetStorageProfileByCollectorNameRow, error) <span class="cov0" title="0">{
        loader := ttlcache.LoaderFunc[GetStorageProfileByCollectorNameParams, StorageProfileByNameCacheValue](
                func(cache *ttlcache.Cache[GetStorageProfileByCollectorNameParams, StorageProfileByNameCacheValue], key GetStorageProfileByCollectorNameParams) *ttlcache.Item[GetStorageProfileByCollectorNameParams, StorageProfileByNameCacheValue] </span><span class="cov0" title="0">{
                        row, err := store.Queries.GetStorageProfileByCollectorNameUncached(ctx, key)
                        item := cache.Set(key, StorageProfileByNameCacheValue{
                                GetStorageProfileByCollectorNameRow: row,
                                error:                               err,
                        }, ttlcache.DefaultTTL)
                        return item
                }</span>,
        )
        <span class="cov0" title="0">v := store.storageProfileByCollectorNameCache.Get(params, ttlcache.WithLoader(loader))
        if v != nil </span><span class="cov0" title="0">{
                return v.Value().GetStorageProfileByCollectorNameRow, v.Value().error
        }</span>
        <span class="cov0" title="0">return GetStorageProfileByCollectorNameRow{}, errors.New("failed to get storage profile by collector name from cache")</span>
}

type StorageProfilesByBucketNameCacheValue struct {
        rows []GetStorageProfilesByBucketNameRow
        err  error
}

func (store *Store) GetStorageProfilesByBucketName(ctx context.Context, bucketName string) ([]GetStorageProfilesByBucketNameRow, error) <span class="cov0" title="0">{
        loader := ttlcache.LoaderFunc[string, StorageProfilesByBucketNameCacheValue](
                func(cache *ttlcache.Cache[string, StorageProfilesByBucketNameCacheValue], key string) *ttlcache.Item[string, StorageProfilesByBucketNameCacheValue] </span><span class="cov0" title="0">{
                        rows, err := store.Queries.GetStorageProfilesByBucketNameUncached(ctx, key)
                        item := cache.Set(key, StorageProfilesByBucketNameCacheValue{
                                rows: rows,
                                err:  err,
                        }, ttlcache.DefaultTTL)
                        return item
                }</span>,
        )
        <span class="cov0" title="0">v := store.storageProfilesByBucketNameCache.Get(bucketName, ttlcache.WithLoader(loader))
        if v != nil </span><span class="cov0" title="0">{
                return v.Value().rows, v.Value().err
        }</span>
        <span class="cov0" title="0">return nil, errors.New("failed to get storage profiles by bucket name from cache")</span>
}
</pre>
		
		<pre class="file" id="file63" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package configdb

import (
        "time"

        "github.com/jackc/pgx/v5/pgxpool"
        "github.com/jellydator/ttlcache/v3"
)

// Store provides all functions to execute db queries and transactions
type Store struct {
        *Queries
        connPool                           *pgxpool.Pool
        storageProfileCache                *ttlcache.Cache[GetStorageProfileParams, StorageProfileCacheValue]
        storageProfileByCollectorNameCache *ttlcache.Cache[GetStorageProfileByCollectorNameParams, StorageProfileByNameCacheValue]
        storageProfilesByBucketNameCache   *ttlcache.Cache[string, StorageProfilesByBucketNameCacheValue]
}

func NewEmptyStore() *Store <span class="cov0" title="0">{
        store := &amp;Store{
                storageProfileCache: ttlcache.New(
                        ttlcache.WithTTL[GetStorageProfileParams, StorageProfileCacheValue](5 * time.Minute),
                ),
                storageProfileByCollectorNameCache: ttlcache.New(
                        ttlcache.WithTTL[GetStorageProfileByCollectorNameParams, StorageProfileByNameCacheValue](5 * time.Minute),
                ),
                storageProfilesByBucketNameCache: ttlcache.New(
                        ttlcache.WithTTL[string, StorageProfilesByBucketNameCacheValue](5 * time.Minute),
                ),
        }
        go store.storageProfileCache.Start()
        go store.storageProfileByCollectorNameCache.Start()
        return store
}</span>

// NewStore creates a new Store
func NewStore(connPool *pgxpool.Pool) *Store <span class="cov0" title="0">{
        s := NewEmptyStore()
        s.connPool = connPool
        s.Queries = New(connPool)
        return s
}</span>
</pre>
		
		<pre class="file" id="file64" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package duckdbx

import (
        "context"
        "database/sql"
        "fmt"
        "time"

        _ "github.com/marcboeker/go-duckdb/v2"
)

type option func(*Config)

type Config struct {
        MemoryLimitMB int64
        Extensions    []ExtensionConfig
        Metrics       bool
        MetricsPeriod time.Duration
        SetupFx       SetupFunction

        pollerContext context.Context
}

type ExtensionConfig struct {
        Name     string
        LoadPath string
}

type SetupFunction func(context.Context, *sql.Conn) error

// WithSetupFunction sets a function to be called on each connection
// returned by db.Conn().
func WithSetupFunction(f SetupFunction) option <span class="cov0" title="0">{
        return func(c *Config) </span><span class="cov0" title="0">{
                c.SetupFx = f
        }</span>
}

// WithMemoryLimitMB sets a memory limit for DuckDB in megabytes.
func WithMemoryLimitMB(limit int64) option <span class="cov0" title="0">{
        return func(c *Config) </span><span class="cov0" title="0">{
                c.MemoryLimitMB = limit
        }</span>
}

// WithExtension specifies a DuckDB extension to install and load on connection setup.
// The loadpath can be an empty string to use the default load path, which will
// load from the network if not already installed.
func WithExtension(ext string, loadpath string) option <span class="cov0" title="0">{
        return func(c *Config) </span><span class="cov0" title="0">{
                c.Extensions = append(c.Extensions, ExtensionConfig{
                        Name:     ext,
                        LoadPath: loadpath,
                })
        }</span>
}

// WithMetrics enables periodic polling of DuckDB memory metrics.
// The period argument specifies how often to poll the metrics.
// The context can be set with WithMetricsContext, which is recommended to allow
// for graceful shutdown of the polling goroutine.
func WithMetrics(period time.Duration) option <span class="cov0" title="0">{
        return func(c *Config) </span><span class="cov0" title="0">{
                c.Metrics = true
                c.MetricsPeriod = period
        }</span>
}

// WithMetricsContext sets the context used for metrics polling.
// If the context is cancelled, metrics polling will stop.
func WithMetricsContext(ctx context.Context) option <span class="cov0" title="0">{
        return func(c *Config) </span><span class="cov0" title="0">{
                c.pollerContext = ctx
        }</span>
}

type DB struct {
        db     *sql.DB
        config Config
}

// Open opens a DuckDB database with the given data source name and options.
// this is generally called once, and the returned DB is shared and used to
// create connections.
func Open(dataSourceName string, opts ...option) (*DB, error) <span class="cov0" title="0">{
        db, err := sql.Open("duckdb", dataSourceName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">config := Config{
                MetricsPeriod: 10 * time.Second,
                pollerContext: context.Background(),
        }

        for _, opt := range opts </span><span class="cov0" title="0">{
                opt(&amp;config)
        }</span>

        <span class="cov0" title="0">d := &amp;DB{db: db, config: config}

        if config.Metrics </span><span class="cov0" title="0">{
                go d.pollMemoryMetrics(config.pollerContext)
        }</span>

        <span class="cov0" title="0">return d, nil</span>
}

// Conn returns a new connection to the database, with any setup
// (such as setting memory limits and loading extensions) already performed.
func (d *DB) Conn(ctx context.Context) (*sql.Conn, error) <span class="cov0" title="0">{
        conn, err := d.db.Conn(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">if err := d.setupConn(ctx, conn); err != nil </span><span class="cov0" title="0">{
                conn.Close()
                return nil, err
        }</span>

        <span class="cov0" title="0">return conn, nil</span>
}

func (d *DB) setupConn(ctx context.Context, conn *sql.Conn) error <span class="cov0" title="0">{
        if d.config.MemoryLimitMB &gt; 0 </span><span class="cov0" title="0">{
                stmt := fmt.Sprintf("SET memory_limit='%dMB';", d.config.MemoryLimitMB)
                if _, err := conn.ExecContext(ctx, stmt); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to set memory limit: %w", err)
                }</span>
        }
        <span class="cov0" title="0">for _, ext := range d.config.Extensions </span><span class="cov0" title="0">{
                stmt := fmt.Sprintf("INSTALL %s", ext.Name)
                if _, err := conn.ExecContext(ctx, stmt); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to install extension '%s': %w", ext.Name, err)
                }</span>
                <span class="cov0" title="0">if _, err := conn.ExecContext(ctx, fmt.Sprintf("LOAD %s;", ext.Name)); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to load extension '%s': %w", ext.Name, err)
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

func (d *DB) SetMaxOpenConns(n int) <span class="cov0" title="0">{
        d.db.SetMaxOpenConns(n)
}</span>

func (d *DB) SetMaxIdleConns(n int) <span class="cov0" title="0">{
        d.db.SetMaxIdleConns(n)
}</span>

func (d *DB) Close() error <span class="cov0" title="0">{
        return d.db.Close()
}</span>

// Query executes a SQL query using a new DuckDB connection and returns the result set.
// The caller is responsible for calling rows.Close() after iteration.
func (d *DB) Query(ctx context.Context, query string, args ...any) (*sql.Rows, error) <span class="cov0" title="0">{
        conn, err := d.Conn(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to get duckdb connection: %w", err)
        }</span>

        <span class="cov0" title="0">rows, err := conn.QueryContext(ctx, query, args...)
        if err != nil </span><span class="cov0" title="0">{
                closeErr := conn.Close()
                if closeErr != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("query failed, and closing connection also failed: %v; %v", err, closeErr)
                }</span>
                <span class="cov0" title="0">return nil, fmt.Errorf("query execution failed: %w", err)</span>
        }

        <span class="cov0" title="0">return rows, nil</span>
}
</pre>
		
		<pre class="file" id="file65" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package duckdbx

import (
        "context"
        "database/sql"
        "strconv"
        "strings"
)

type returnedMemoryStats struct {
        DatabaseName string
        DatabaseSize string
        BlockSize    int64
        TotalBlocks  int64
        UsedBlocks   int64
        FreeBlocks   int64
        WALSize      string
        MemoryUsage  string
        MemoryLimit  string
}

type MemoryStats struct {
        DatabaseName string
        DatabaseSize int64
        BlockSize    int64
        TotalBlocks  int64
        UsedBlocks   int64
        FreeBlocks   int64
        WALSize      int64
        MemoryUsage  int64
        MemoryLimit  int64
}

func GetDuckDBMemoryStats(conn *sql.Conn) ([]MemoryStats, error) <span class="cov0" title="0">{
        rows, err := conn.QueryContext(context.Background(), "PRAGMA database_size")
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()

        var stats []returnedMemoryStats
        for rows.Next() </span><span class="cov0" title="0">{
                var stat returnedMemoryStats
                if err := rows.Scan(&amp;stat.DatabaseName, &amp;stat.DatabaseSize, &amp;stat.BlockSize, &amp;stat.TotalBlocks, &amp;stat.UsedBlocks, &amp;stat.FreeBlocks, &amp;stat.WALSize, &amp;stat.MemoryUsage, &amp;stat.MemoryLimit); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">stats = append(stats, stat)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">ret := make([]MemoryStats, len(stats))
        for _, stat := range stats </span><span class="cov0" title="0">{
                ret = append(ret, MemoryStats{
                        DatabaseName: stat.DatabaseName,
                        DatabaseSize: parseSize(stat.DatabaseSize),
                        BlockSize:    stat.BlockSize,
                        TotalBlocks:  stat.TotalBlocks,
                        UsedBlocks:   stat.UsedBlocks,
                        FreeBlocks:   stat.FreeBlocks,
                        WALSize:      parseSize(stat.WALSize),
                        MemoryUsage:  parseSize(stat.MemoryUsage),
                        MemoryLimit:  parseSize(stat.MemoryLimit),
                })
        }</span>

        <span class="cov0" title="0">return ret, nil</span>
}

// Parse strings like "0 bytes", "1.2 MB, "3.1 GiB" into int64 bytes.
func parseSize(sizeStr string) int64 <span class="cov0" title="0">{
        parts := strings.Split(sizeStr, " ")
        if len(parts) == 0 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov0" title="0">if len(parts) == 1 </span><span class="cov0" title="0">{
                v, err := strconv.ParseFloat(parts[0], 64)
                if err != nil </span><span class="cov0" title="0">{
                        return 0
                }</span>
                <span class="cov0" title="0">return int64(v)</span>
        }

        <span class="cov0" title="0">value, err := strconv.ParseFloat(parts[0], 64)
        if err != nil </span><span class="cov0" title="0">{
                return 0
        }</span>

        <span class="cov0" title="0">unit := strings.ToLower(parts[1])
        switch unit </span>{
        case "bytes", "byte":<span class="cov0" title="0">
                return int64(value)</span>
        case "KiB":<span class="cov0" title="0">
                return int64(value * 1024)</span>
        case "MiB":<span class="cov0" title="0">
                return int64(value * 1024 * 1024)</span>
        case "GiB":<span class="cov0" title="0">
                return int64(value * 1024 * 1024 * 1024)</span>
        case "TiB":<span class="cov0" title="0">
                return int64(value * 1024 * 1024 * 1024 * 1024)</span>
        case "PiB":<span class="cov0" title="0">
                return int64(value * 1024 * 1024 * 1024 * 1024 * 1024)</span>
        default:<span class="cov0" title="0">
                return 0</span>
        }
}
</pre>
		
		<pre class="file" id="file66" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package duckdbx

import (
        "context"
        "time"

        "log/slog"

        "go.opentelemetry.io/otel"
        "go.opentelemetry.io/otel/attribute"
        "go.opentelemetry.io/otel/metric"
)

var (
        logger = slog.Default()
        meter  = otel.Meter("github.com/cardinalhq/lakerunner/duckdbx")
)

func (d *DB) pollMemoryMetrics(ctx context.Context) <span class="cov0" title="0">{
        dbSizeGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.database_size",
                metric.WithDescription("DuckDB database size"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create database_size metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">blockSizeGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.block_size",
                metric.WithDescription("DuckDB block size"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create block_size metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">totalBlocksGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.total_blocks",
                metric.WithDescription("DuckDB total blocks"),
                metric.WithUnit("1"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create total_blocks metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">usedBlocksGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.used_blocks",
                metric.WithDescription("DuckDB used blocks"),
                metric.WithUnit("1"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create used_blocks metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">freeBlocksGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.free_blocks",
                metric.WithDescription("DuckDB free blocks"),
                metric.WithUnit("1"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create free_blocks metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">walSizeGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.wal_size",
                metric.WithDescription("DuckDB WAL size"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create wal_size metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">memoryUsageGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.memory_usage",
                metric.WithDescription("DuckDB memory usage"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create memory_usage metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">memoryLimitGauge, err := meter.Int64Gauge("lakerunner.duckdb.memory.memory_limit",
                metric.WithDescription("DuckDB memory limit"),
                metric.WithUnit("By"),
        )
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("failed to create memory_limit metric", "error", err)
                return
        }</span>

        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                conn, err := d.db.Conn(ctx)
                if err != nil </span><span class="cov0" title="0">{
                        if err.Error() == "sql: database is closed" </span><span class="cov0" title="0">{
                                logger.Info("database is closed, stopping memory metrics polling")
                                return
                        }</span>
                        <span class="cov0" title="0">logger.Error("failed to get connection for memory metrics", "error", err)
                        return</span>
                }

                <span class="cov0" title="0">stats, err := GetDuckDBMemoryStats(conn)
                conn.Close()
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error("failed to get memory stats", "error", err)
                        return
                }</span>

                <span class="cov0" title="0">for _, stat := range stats </span><span class="cov0" title="0">{
                        attributes := []attribute.KeyValue{
                                attribute.String("database_name", stat.DatabaseName),
                                attribute.String("database_type", "duckdb"),
                        }
                        attr := metric.WithAttributeSet(attribute.NewSet(attributes...))
                        dbSizeGauge.Record(ctx, stat.DatabaseSize, attr)
                        blockSizeGauge.Record(ctx, stat.BlockSize, attr)
                        totalBlocksGauge.Record(ctx, stat.TotalBlocks, attr)
                        usedBlocksGauge.Record(ctx, stat.UsedBlocks, attr)
                        freeBlocksGauge.Record(ctx, stat.FreeBlocks, attr)
                        walSizeGauge.Record(ctx, stat.WALSize, attr)
                        memoryUsageGauge.Record(ctx, stat.MemoryUsage, attr)
                        memoryLimitGauge.Record(ctx, stat.MemoryLimit, attr)
                }</span>

                <span class="cov0" title="0">select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>
                case &lt;-time.After(d.config.MetricsPeriod):<span class="cov0" title="0"></span>
                }
        }
}
</pre>
		
		<pre class="file" id="file67" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package estimator

import (
        "context"
        "log/slog"
        "sync"
        "time"

        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/lrdb"
)

type EstimationQuerier interface {
        MetricSegEstimator(ctx context.Context, params lrdb.MetricSegEstimatorParams) ([]lrdb.MetricSegEstimatorRow, error)
        LogSegEstimator(ctx context.Context, params lrdb.LogSegEstimatorParams) ([]lrdb.LogSegEstimatorRow, error)
}

type Estimator interface {
        Get(organizationID uuid.UUID, instanceNum int16, signal lrdb.SignalEnum) Estimate
}

type Estimate struct {
        EstimatedRecordCount int64
}

type estimatorKey struct {
        OrganizationID uuid.UUID
        InstanceNum    int16
        Signal         lrdb.SignalEnum
}

type estimator struct {
        sync.RWMutex
        currentEstimates map[estimatorKey]Estimate
        updateEvery      time.Duration
        lookback         time.Duration
        timeout          time.Duration
        defaultGuess     int64
}

// NewEstimator creates a new Estimator instance that periodically updates its estimates
// based on the data from the database.
// It will stop updating when the doneCtx is canceled.
// NewEstimator also initializes the estimates based on the current data in the database,
// returning an error if the initial fetch fails.
func NewEstimator(doneCtx context.Context, mdb EstimationQuerier) (Estimator, error) <span class="cov8" title="1">{
        e := &amp;estimator{
                currentEstimates: map[estimatorKey]Estimate{},
                updateEvery:      30 * time.Minute,
                lookback:         6 * time.Hour,
                timeout:          30 * time.Second,
                defaultGuess:     40_000,
        }
        if err := e.updateEstimates(doneCtx, mdb); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">go e.run(doneCtx, mdb)
        return e, nil</span>
}

func (e *estimator) Get(org uuid.UUID, inst int16, sig lrdb.SignalEnum) Estimate <span class="cov8" title="1">{
        e.RLock()
        snap := e.currentEstimates
        e.RUnlock()

        key := estimatorKey{org, inst, sig}

        // 1. Try exact match for this organization + instance + signal.
        //    If we have a positive estimate for this exact key, return it immediately.
        if est, ok := snap[key]; ok &amp;&amp; est.EstimatedRecordCount &gt; 0 </span><span class="cov8" title="1">{
                return est
        }</span>

        // If exact exists but is non-positive (shouldn't happen after filtering),
        // mark it so we can explicitly exclude it from all broader fallback tiers.
        <span class="cov8" title="1">excludeExact := false
        if est, ok := snap[key]; ok &amp;&amp; est.EstimatedRecordCount &lt;= 0 </span><span class="cov8" title="1">{
                excludeExact = true
        }</span>

        // avg runs over all entries in the snapshot, selecting only those
        // that match the filter. Non-positive estimates are ignored entirely.
        // If excludeExact is true, the exact key is skipped even if it would
        // otherwise match the filter.
        <span class="cov8" title="1">avg := func(filter func(k estimatorKey) bool) (int64, bool) </span><span class="cov8" title="1">{
                var sum, n int64
                for k, v := range snap </span><span class="cov8" title="1">{
                        if excludeExact &amp;&amp; k == key </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        <span class="cov8" title="1">if filter(k) &amp;&amp; v.EstimatedRecordCount &gt; 0 </span><span class="cov8" title="1">{
                                sum += v.EstimatedRecordCount
                                n++
                        }</span>
                }
                <span class="cov8" title="1">if n == 0 </span><span class="cov8" title="1">{
                        return 0, false
                }</span>
                <span class="cov8" title="1">return sum / n, true</span>
        }

        // Try all entries for the same organization and signal, across ANY instance number.
        <span class="cov8" title="1">if a, ok := avg(func(k estimatorKey) bool </span><span class="cov8" title="1">{
                return k.OrganizationID == org &amp;&amp; k.Signal == sig
        }</span>); ok <span class="cov8" title="1">{
                return Estimate{EstimatedRecordCount: a}
        }</span>

        // Try all entries for the same signal, across ALL organizations and instances.
        <span class="cov8" title="1">if a, ok := avg(func(k estimatorKey) bool </span><span class="cov8" title="1">{
                return k.Signal == sig
        }</span>); ok <span class="cov8" title="1">{
                return Estimate{EstimatedRecordCount: a}
        }</span>

        // Try all entries in the snapshot, regardless of organization, instance, or signal.
        <span class="cov8" title="1">if a, ok := avg(func(_ estimatorKey) bool </span><span class="cov8" title="1">{ return true }</span>); ok <span class="cov8" title="1">{
                return Estimate{EstimatedRecordCount: a}
        }</span>

        // If no data was available at any tier, return the static default guess.
        <span class="cov8" title="1">return Estimate{EstimatedRecordCount: e.defaultGuess}</span>
}

func (e *estimator) run(doneCtx context.Context, mdb EstimationQuerier) <span class="cov8" title="1">{
        ticker := time.NewTicker(e.updateEvery)
        defer ticker.Stop()
        for </span><span class="cov8" title="1">{
                select </span>{
                case &lt;-doneCtx.Done():<span class="cov8" title="1">
                        return</span>
                case &lt;-ticker.C:<span class="cov0" title="0">
                        if err := e.updateEstimates(doneCtx, mdb); err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to update estimates", "error", err)
                        }</span>
                }
        }
}

func (e *estimator) updateEstimates(parent context.Context, mdb EstimationQuerier) error <span class="cov8" title="1">{
        ctx, cancel := context.WithTimeout(parent, e.timeout)
        defer cancel()

        now := time.Now().UTC()
        low := now.Add(-e.lookback)

        mp := lrdb.MetricSegEstimatorParams{
                DateintLow:  dateint(low),
                DateintHigh: dateint(now),
                MsLow:       low.UnixMilli(),
                MsHigh:      now.UnixMilli(),
        }
        metricRows, err := mdb.MetricSegEstimator(ctx, mp)
        if err != nil </span><span class="cov0" title="0">{
                slog.Warn("MetricSegEstimator failed", "error", err)
                metricRows = nil
        }</span>

        <span class="cov8" title="1">lp := lrdb.LogSegEstimatorParams{
                DateintLow:  dateint(low),
                DateintHigh: dateint(now),
                MsLow:       low.UnixMilli(),
                MsHigh:      now.UnixMilli(),
        }
        logRows, err := mdb.LogSegEstimator(ctx, lp)
        if err != nil </span><span class="cov0" title="0">{
                slog.Warn("LogSegEstimator failed", "error", err)
                logRows = nil
        }</span>

        <span class="cov8" title="1">if len(metricRows) == 0 &amp;&amp; len(logRows) == 0 </span><span class="cov0" title="0">{
                slog.Warn("no estimates found in database, will keep trying")
                return nil
        }</span>

        // Build new map with only positive estimates.
        <span class="cov8" title="1">next := make(map[estimatorKey]Estimate, len(metricRows)+len(logRows))
        var kept, dropped int

        for _, r := range metricRows </span><span class="cov8" title="1">{
                if r.EstimatedRecords &lt;= 0 </span><span class="cov0" title="0">{
                        dropped++
                        slog.Warn("dropping non-positive metric estimate", "org", r.OrganizationID, "inst", r.InstanceNum, "est", r.EstimatedRecords)
                        continue</span>
                }
                <span class="cov8" title="1">next[estimatorKey{r.OrganizationID, r.InstanceNum, lrdb.SignalEnumMetrics}] =
                        Estimate{EstimatedRecordCount: r.EstimatedRecords}
                kept++</span>
        }

        <span class="cov8" title="1">for _, r := range logRows </span><span class="cov8" title="1">{
                if r.EstimatedRecords &lt;= 0 </span><span class="cov0" title="0">{
                        dropped++
                        slog.Warn("dropping non-positive log estimate", "org", r.OrganizationID, "inst", r.InstanceNum, "est", r.EstimatedRecords)
                        continue</span>
                }
                <span class="cov8" title="1">next[estimatorKey{r.OrganizationID, r.InstanceNum, lrdb.SignalEnumLogs}] =
                        Estimate{EstimatedRecordCount: r.EstimatedRecords}
                kept++</span>
        }

        <span class="cov8" title="1">if kept == 0 </span><span class="cov0" title="0">{
                slog.Warn("all estimates were non-positive; keeping previous snapshot", "dropped", dropped)
                return nil
        }</span>

        <span class="cov8" title="1">e.Lock()
        e.currentEstimates = next
        e.Unlock()

        return nil</span>
}

func dateint(t time.Time) int32 <span class="cov8" title="1">{
        y, m, d := t.Date()
        return int32(y*10000 + int(m)*100 + d)
}</span>
</pre>
		
		<pre class="file" id="file68" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package filecrunch

import (
        "fmt"
        "os"

        "github.com/parquet-go/parquet-go"
        "github.com/parquet-go/parquet-go/compress/zstd"
        "github.com/parquet-go/parquet-go/format"
)

type FileHandle struct {
        File        *os.File
        Size        int64
        Schema      *parquet.Schema
        ParquetFile *parquet.File
        Nodes       map[string]parquet.Node
}

func (fh *FileHandle) Close() error <span class="cov0" title="0">{
        if err := fh.File.Close(); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return nil</span>
}

func LoadSchemaForFile(filename string) (*FileHandle, error) <span class="cov8" title="1">{
        fh, err := openfile(filename)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov8" title="1">if err := loadSchema(fh); err != nil </span><span class="cov0" title="0">{
                _ = fh.File.Close()
                return nil, err
        }</span>

        <span class="cov8" title="1">return fh, nil</span>
}

func openfile(file string) (*FileHandle, error) <span class="cov8" title="1">{
        f, err := os.Open(file)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">stat, err := f.Stat()
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">return &amp;FileHandle{
                File: f,
                Size: stat.Size(),
        }, nil</span>
}

func loadSchema(fh *FileHandle) error <span class="cov8" title="1">{
        f, err := parquet.OpenFile(fh.File, fh.Size)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">fh.ParquetFile = f

        md := f.Metadata()
        fh.Nodes = map[string]parquet.Node{}
        for _, schema := range md.Schema </span><span class="cov8" title="1">{
                if schema.Type == nil </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">typ := schema.Type.String()
                logicalType := ""
                if schema.LogicalType != nil </span><span class="cov8" title="1">{
                        logicalType = schema.LogicalType.String()
                }</span>

                <span class="cov8" title="1">stype, err := schemaTypeToNode(typ, logicalType)
                if err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov8" title="1">if currentNode, ok := fh.Nodes[schema.Name]; ok </span><span class="cov0" title="0">{
                        if !parquet.EqualNodes(currentNode, stype) </span><span class="cov0" title="0">{
                                return fmt.Errorf("schema mismatch: %s (%s vs %s)", schema.Name, currentNode.String(), stype.String())
                        }</span>
                } else<span class="cov8" title="1"> {
                        fh.Nodes[schema.Name] = stype
                }</span>
        }

        <span class="cov8" title="1">fh.Schema = parquet.NewSchema(fh.File.Name(), parquet.Group(fh.Nodes))

        return nil</span>
}

func wrapP(n parquet.Node) parquet.Node <span class="cov8" title="1">{
        n = parquet.Compressed(n, enc)
        if n.Leaf() </span><span class="cov8" title="1">{
                n = parquet.Encoded(n, parquet.LookupEncoding(format.Encoding(format.RLEDictionary)))
        }</span>
        <span class="cov8" title="1">n = parquet.Optional(n)
        return n</span>
}

var (
        enc         = &amp;zstd.Codec{Level: zstd.SpeedBetterCompression}
        NodeTypeMap = map[string]parquet.Node{
                "INT8":       wrapP(parquet.Int(8)),
                "INT16":      wrapP(parquet.Int(16)),
                "INT32":      wrapP(parquet.Int(32)),
                "INT64":      wrapP(parquet.Int(64)),
                "DOUBLE":     wrapP(parquet.Leaf(parquet.DoubleType)),
                "BOOLEAN":    wrapP(parquet.Leaf(parquet.BooleanType)),
                "BYTE_ARRAY": wrapP(parquet.Leaf(parquet.ByteArrayType)),
        }
        logicalNodes = map[string]parquet.Node{
                "STRING": wrapP(parquet.String()),
        }
)

func schemaTypeToNode(typ, logical string) (parquet.Node, error) <span class="cov8" title="1">{
        if node, ok := logicalNodes[logical]; ok </span><span class="cov8" title="1">{
                return node, nil
        }</span>
        <span class="cov8" title="1">if node, ok := NodeTypeMap[typ]; ok </span><span class="cov8" title="1">{
                return node, nil
        }</span>
        <span class="cov0" title="0">return nil, fmt.Errorf("unsupported type: %s, logical %s", typ, logical)</span>
}
</pre>
		
		<pre class="file" id="file69" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package filecrunch

import (
        "fmt"

        "github.com/parquet-go/parquet-go"
)

func MergeNodes(fh *FileHandle, mergedNodes map[string]parquet.Node) error <span class="cov0" title="0">{
        for k, v := range fh.Nodes </span><span class="cov0" title="0">{
                if newNode, ok := mergedNodes[k]; ok </span><span class="cov0" title="0">{
                        if newNode != v </span><span class="cov0" title="0">{
                                return fmt.Errorf("schema mismatch: %s, currentType %s, newType %s", k, v, newNode)
                        }</span>
                } else<span class="cov0" title="0"> {
                        mergedNodes[k] = v
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

func SchemaFromNodes(nodes map[string]parquet.Node) *parquet.Schema <span class="cov0" title="0">{
        return parquet.NewSchema("merged", parquet.Group(nodes))
}</span>
</pre>
		
		<pre class="file" id="file70" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package helpers

import (
        "golang.org/x/sys/unix"
)

// FSUsage holds the on-disk usage stats for a given filesystem.
type FSUsage struct {
        // Bytes
        TotalBytes uint64 // total capacity (in bytes)
        FreeBytes  uint64 // bytes available to non-root users
        UsedBytes  uint64 // bytes currently in use  (TotalBytes - FreeBytes)

        // Inodes
        TotalInodes uint64 // total number of inodes
        FreeInodes  uint64 // number of free inodes
        UsedInodes  uint64 // number of used inodes (TotalInodes - FreeInodes)
}

// DiskUsage returns FSUsage for the filesystem that contains 'path'.
// It fills in total/free/used for both bytes and inodes.
// If an error occurs (e.g. path doesn’t exist), err will be non-nil.
func DiskUsage(path string) (FSUsage, error) <span class="cov0" title="0">{
        var st unix.Statfs_t
        if err := unix.Statfs(path, &amp;st); err != nil </span><span class="cov0" title="0">{
                return FSUsage{}, err
        }</span>

        <span class="cov0" title="0">totalBytes := st.Blocks * uint64(st.Bsize)
        freeBytes := st.Bavail * uint64(st.Bsize)
        usedBytes := totalBytes - freeBytes

        totalInodes := st.Files
        freeInodes := st.Ffree
        usedInodes := totalInodes - freeInodes

        return FSUsage{
                TotalBytes:  totalBytes,
                FreeBytes:   freeBytes,
                UsedBytes:   usedBytes,
                TotalInodes: totalInodes,
                FreeInodes:  freeInodes,
                UsedInodes:  usedInodes,
        }, nil</span>
}
</pre>
		
		<pre class="file" id="file71" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package helpers

import (
        "fmt"
        "path"
        "strconv"

        "github.com/google/uuid"
)

const DBPrefix = "db"

func MakeDBObjectID(
        orgID uuid.UUID,
        collectorName string,
        dateint int32,
        hour int16,
        segmentID int64,
        ttype string,
) string <span class="cov8" title="1">{
        return path.Join(
                DBPrefix,
                orgID.String(),
                collectorName,
                strconv.Itoa(int(dateint)),
                ttype,
                fmt.Sprintf("%02d", hour),
                fmt.Sprintf("tbl_%d.parquet", segmentID),
        )
}</span>

func MakeDBObjectIDbad(
        orgID uuid.UUID,
        collectorName string,
        dateint int32,
        hour int16,
        segmentID int64,
        ttype string,
) string <span class="cov0" title="0">{
        return path.Join(
                DBPrefix,
                orgID.String(),
                collectorName,
                strconv.Itoa(int(dateint)),
                ttype,
                fmt.Sprintf("%d", hour),
                fmt.Sprintf("tbl_%d.parquet", segmentID),
        )
}</span>
</pre>
		
		<pre class="file" id="file72" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package helpers

import (
        "log/slog"
        "os"
        "path/filepath"
)

func CleanTempDir() <span class="cov0" title="0">{
        slog.Info("Cleaning temp dir", "path", os.TempDir())
        temp := os.TempDir()
        entries, err := os.ReadDir(temp)
        if err != nil </span><span class="cov0" title="0">{
                slog.Info("Failed to read temp dir (ignoring)", slog.String("path", temp), slog.Any("error", err))
                return
        }</span>

        <span class="cov0" title="0">for _, entry := range entries </span><span class="cov0" title="0">{
                path := filepath.Join(temp, entry.Name())
                _ = os.RemoveAll(path)
        }</span>
}
</pre>
		
		<pre class="file" id="file73" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package helpers

import (
        "encoding/json"
        "fmt"
        "hash/fnv"
        "sort"
)

func ComputeTID(metricName string, tags map[string]any) int64 <span class="cov0" title="0">{
        keys := make([]string, 0, len(tags))
        for k, v := range tags </span><span class="cov0" title="0">{
                if v == "" || k[0] == '_' </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">keys = append(keys, k)</span>
        }
        <span class="cov0" title="0">sort.Strings(keys)
        h := fnv.New64a()
        _, _ = h.Write([]byte(metricName))
        for _, k := range keys </span><span class="cov0" title="0">{
                switch v := tags[k].(type) </span>{
                case string:<span class="cov0" title="0">
                        _, _ = h.Write([]byte(k + "=" + v + "|"))</span>
                default:<span class="cov0" title="0">
                        _, _ = h.Write([]byte(k + fmt.Sprintf("=%v|", v)))</span>
                }
        }
        <span class="cov0" title="0">return int64(h.Sum64())</span>
}

func MatchTags(existing, new map[string]any) map[string][]any <span class="cov8" title="1">{
        mismatches := make(map[string][]any)

        for k, v := range existing </span><span class="cov8" title="1">{
                if nv, ok := new[k]; !ok || nv != v </span><span class="cov8" title="1">{
                        mismatches[k] = []any{v, new[k]}
                }</span>
        }

        <span class="cov8" title="1">for k, v := range new </span><span class="cov8" title="1">{
                if _, ok := existing[k]; !ok </span><span class="cov8" title="1">{
                        mismatches[k] = []any{nil, v}
                }</span>
        }

        <span class="cov8" title="1">return mismatches</span>
}

func GetFloat64Value(m map[string]any, key string) (float64, bool) <span class="cov0" title="0">{
        val, ok := m[key]
        if !ok || val == nil </span><span class="cov0" title="0">{
                return 0, false
        }</span>
        <span class="cov0" title="0">floatVal, ok := val.(float64)
        if !ok </span><span class="cov0" title="0">{
                return 0, false
        }</span>
        <span class="cov0" title="0">return floatVal, true</span>
}

func GetStringValue(m map[string]any, key string) (string, bool) <span class="cov0" title="0">{
        val, ok := m[key]
        if !ok || val == nil </span><span class="cov0" title="0">{
                return "", false
        }</span>
        <span class="cov0" title="0">strVal, ok := val.(string)
        if !ok </span><span class="cov0" title="0">{
                return "", false
        }</span>
        <span class="cov0" title="0">return strVal, true</span>
}

func GetInt64Value(m map[string]any, key string) (int64, bool) <span class="cov0" title="0">{
        val, ok := m[key]
        if !ok || val == nil </span><span class="cov0" title="0">{
                return 0, false
        }</span>
        <span class="cov0" title="0">intVal, ok := val.(int64)
        if !ok </span><span class="cov0" title="0">{
                return 0, false
        }</span>
        <span class="cov0" title="0">return intVal, true</span>
}

func MakeTags(rec map[string]any) map[string]any <span class="cov8" title="1">{
        tags := make(map[string]any)
        for k, v := range rec </span><span class="cov8" title="1">{
                if v == nil || k == "" || fmt.Sprintf("%v", v) == "" </span><span class="cov8" title="1">{
                        continue</span>
                }
                <span class="cov8" title="1">if k[0] == '_' </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">tags[k] = v</span>
        }
        <span class="cov8" title="1">return tags</span>
}

func GetFloat64SliceJSON(m map[string]any, key string) ([]float64, bool) <span class="cov0" title="0">{
        val, ok := m[key]
        if !ok || val == nil </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov0" title="0">sliceString, ok := val.(string)
        if !ok </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov0" title="0">var floatSlice []float64
        if err := json.Unmarshal([]byte(sliceString), &amp;floatSlice); err != nil </span><span class="cov0" title="0">{
                return nil, false
        }</span>
        <span class="cov0" title="0">return floatSlice, true</span>
}
</pre>
		
		<pre class="file" id="file74" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package helpers

import "time"

// Converts milliseconds since epoch to (dateint, hour)
func MSToDateintHour(ms int64) (int32, int16) <span class="cov0" title="0">{
        t := UnixMillisToTime(ms).UTC()
        dateint := int32(t.Year()*10000 + int(t.Month())*100 + t.Day())
        hour := int16(t.Hour())
        return dateint, hour
}</span>

// Helper to convert ms since epoch to time.Time
func UnixMillisToTime(ms int64) time.Time <span class="cov0" title="0">{
        sec := ms / 1000
        nsec := (ms % 1000) * 1e6
        return time.Unix(sec, nsec).UTC()
}</span>
</pre>
		
		<pre class="file" id="file75" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package idgen

import (
        "errors"
        "math/rand/v2"
        "time"

        "github.com/sony/sonyflake"
)

var DefaultFlakeGenerator *SonyFlakeGenerator

func init() <span class="cov8" title="1">{
        var err error
        DefaultFlakeGenerator, err = NewFlakeGenerator()
        if err != nil </span><span class="cov0" title="0">{
                panic(err)</span>
        }
}

type SonyFlakeGenerator struct {
        sf *sonyflake.Sonyflake
}

func NewFlakeGenerator() (*SonyFlakeGenerator, error) <span class="cov8" title="1">{
        settings := sonyflake.Settings{
                StartTime: time.Date(2020, 1, 1, 0, 0, 0, 0, time.UTC),
        }

        sf, err := sonyflake.New(settings)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">if sf == nil </span><span class="cov0" title="0">{
                return nil, errors.New("failed to create Sonyflake instance")
        }</span>
        <span class="cov8" title="1">return &amp;SonyFlakeGenerator{sf: sf}, nil</span>
}

// NextID returns a positive int64 that'll increase roughly in time order.
func (sf *SonyFlakeGenerator) NextID() int64 <span class="cov8" title="1">{
        v, err := sf.sf.NextID()
        if err != nil </span><span class="cov0" title="0">{
                return rand.Int64()
        }</span>
        <span class="cov8" title="1">return int64(v)</span>
}
</pre>
		
		<pre class="file" id="file76" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package idgen

import (
        crand "crypto/rand"
        "time"

        "github.com/oklog/ulid/v2"
)

type InlineULIDGenerator struct{}

var _ IDGenerator = &amp;InlineULIDGenerator{}

func (i *InlineULIDGenerator) Make(_ time.Time) string <span class="cov0" title="0">{
        return ulid.Make().String()
}</span>

type ULIDGenerator struct {
        entropy *ulid.MonotonicEntropy
}

var _ IDGenerator = &amp;ULIDGenerator{}

func NewULIDGenerator() *ULIDGenerator <span class="cov0" title="0">{
        return &amp;ULIDGenerator{
                entropy: ulid.Monotonic(crand.Reader, 0),
        }
}</span>

func (u *ULIDGenerator) Make(t time.Time) string <span class="cov0" title="0">{
        return ulid.MustNew(ulid.Timestamp(t), u.entropy).String()
}</span>
</pre>
		
		<pre class="file" id="file77" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package logcrunch

import (
        "fmt"

        "github.com/cardinalhq/lakerunner/lrdb"
)

// PackSegments groups segments into packs such that the sum of RecordCount in each
// pack is &lt;= estimatedRecordCount (greedy, one-or-more per pack).
// NOTE: segments must all lie within the same UTC day and must be sorted by StartTs ascending.
func PackSegments(segments []lrdb.GetLogSegmentsForCompactionRow, estimatedRecordCount int64) ([][]lrdb.GetLogSegmentsForCompactionRow, error) <span class="cov8" title="1">{
        if estimatedRecordCount &lt;= 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("estimatedRecordCount must be positive, got %d", estimatedRecordCount)
        }</span>
        <span class="cov8" title="1">if len(segments) == 0 </span><span class="cov0" title="0">{
                return [][]lrdb.GetLogSegmentsForCompactionRow{}, nil
        }</span>

        // 1) Drop zero-record segments up front.
        <span class="cov8" title="1">segments = filterSegments(segments)
        if len(segments) == 0 </span><span class="cov0" title="0">{
                return [][]lrdb.GetLogSegmentsForCompactionRow{}, nil
        }</span>

        // 2) Validate same-day and basic time sanity.
        <span class="cov8" title="1">day := dayFromMillis(segments[0].StartTs)
        for _, seg := range segments </span><span class="cov8" title="1">{
                if seg.StartTs &gt;= seg.EndTs </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("invalid segment time range: [%d,%d)", seg.StartTs, seg.EndTs)
                }</span>
                // Use end-1 to keep [start,end) semantics in the same day
                <span class="cov8" title="1">endMinusOne := seg.EndTs - 1
                // Guard (very defensive)
                if seg.EndTs == -9223372036854775808 </span><span class="cov0" title="0">{ // math.MinInt64, inline to avoid import
                        return nil, fmt.Errorf("invalid EndTs (MinInt64) for segment starting at %d", seg.StartTs)
                }</span>
                <span class="cov8" title="1">if dayFromMillis(seg.StartTs) != day || dayFromMillis(endMinusOne) != day </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("segments must be from the same UTC day; offending start=%d end=%d", seg.StartTs, seg.EndTs)
                }</span>
        }

        // 3) Greedy packing by record count threshold.
        <span class="cov8" title="1">groups := make([][]lrdb.GetLogSegmentsForCompactionRow, 0, len(segments)/2+1)
        current := make([]lrdb.GetLogSegmentsForCompactionRow, 0, 8)
        var sumRecords int64

        for _, seg := range segments </span><span class="cov8" title="1">{
                rc := seg.RecordCount
                if len(current) == 0 || sumRecords+rc &lt;= estimatedRecordCount </span><span class="cov8" title="1">{
                        current = append(current, seg)
                        sumRecords += rc
                        continue</span>
                }
                <span class="cov8" title="1">groups = append(groups, current)
                current = []lrdb.GetLogSegmentsForCompactionRow{seg}
                sumRecords = rc</span>
        }
        <span class="cov8" title="1">if len(current) &gt; 0 </span><span class="cov8" title="1">{
                groups = append(groups, current)
        }</span>
        <span class="cov8" title="1">return groups, nil</span>
}

func filterSegments(segs []lrdb.GetLogSegmentsForCompactionRow) []lrdb.GetLogSegmentsForCompactionRow <span class="cov8" title="1">{
        j := 0
        for _, s := range segs </span><span class="cov8" title="1">{
                if s.RecordCount &gt; 0 </span><span class="cov8" title="1">{
                        segs[j] = s
                        j++
                }</span>
        }
        <span class="cov8" title="1">return segs[:j]</span>
}

const msPerDay int64 = 86_400_000

func dayFromMillis(millis int64) int64 <span class="cov8" title="1">{
        return millis / msPerDay
}</span>
</pre>
		
		<pre class="file" id="file78" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package logcrunch

import (
        "slices"

        mapset "github.com/deckarep/golang-set/v2"
)

const (
        ExistsRegex = ".*"
)

var (
        InfraDimensions = []string{
                "resource.k8s.namespace.name",
                "resource.service.name",
                "resource.file",
        }
        DimensionsToIndex = append([]string{
                //"_cardinalhq.telemetry_type",
                "_cardinalhq.name",
                "_cardinalhq.level",
                //"_cardinalhq.message",
                "_cardinalhq.span_trace_id",
        }, InfraDimensions...)
        IndexFullValueDimensions = []string{"resource.file"}
)

// ToFingerprints converts a map of tagName → slice of tagValues into a set of fingerprints.
func ToFingerprints(tagValuesByName map[string]mapset.Set[string]) mapset.Set[int64] <span class="cov8" title="1">{
        fingerprints := mapset.NewSet[int64]()

        for tagName, values := range tagValuesByName </span><span class="cov8" title="1">{
                if !slices.Contains(DimensionsToIndex, tagName) </span><span class="cov8" title="1">{
                        fp := ComputeFingerprint(tagName, ExistsRegex)
                        fingerprints.Add(fp)
                        continue</span>
                }

                <span class="cov8" title="1">if slices.Contains(IndexFullValueDimensions, tagName) </span><span class="cov8" title="1">{
                        fingerprints.Add(ComputeFingerprint(tagName, ExistsRegex))
                        for _, tagValue := range values.ToSlice() </span><span class="cov8" title="1">{
                                fingerprints.Add(ComputeFingerprint(tagName, tagValue))
                        }</span>
                        <span class="cov8" title="1">continue</span>
                }

                // looks like full trigrams
                <span class="cov8" title="1">for _, tagValue := range values.ToSlice() </span><span class="cov8" title="1">{
                        trigrams := ToTrigrams(tagValue)
                        for _, trigram := range trigrams </span><span class="cov8" title="1">{
                                fp := ComputeFingerprint(tagName, trigram)
                                fingerprints.Add(fp)
                        }</span>
                }
        }

        <span class="cov8" title="1">return fingerprints</span>
}

// ToTrigrams builds the set of 3-character substrings plus the wildcard.
func ToTrigrams(str string) []string <span class="cov8" title="1">{
        ngrams := mapset.NewSet[string]()
        runes := []rune(str)
        for i := 0; i+3 &lt;= len(runes); i++ </span><span class="cov8" title="1">{
                ngram := string(runes[i : i+3])
                ngrams.Add(ngram)
        }</span>
        <span class="cov8" title="1">ngrams.Add(ExistsRegex)
        return ngrams.ToSlice()</span>
}

// ComputeFingerprint combines fieldName and trigram and hashes them.
func ComputeFingerprint(fieldName, trigram string) int64 <span class="cov8" title="1">{
        s := fieldName + ":" + trigram
        return ComputeHash(s)
}</span>

func ComputeHash(str string) int64 <span class="cov8" title="1">{
        var h int64
        length := len(str)
        i := 0

        for i+3 &lt; length </span><span class="cov8" title="1">{
                h = 31*31*31*31*h +
                        31*31*31*int64(str[i]) +
                        31*31*int64(str[i+1]) +
                        31*int64(str[i+2]) +
                        int64(str[i+3])
                i += 4
        }</span>
        <span class="cov8" title="1">for ; i &lt; length; i++ </span><span class="cov8" title="1">{
                h = 31*h + int64(str[i])
        }</span>

        <span class="cov8" title="1">return h</span>
}
</pre>
		
		<pre class="file" id="file79" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package logcrunch

import (
        "container/heap"
        "encoding/gob"
        "errors"
        "fmt"
        "io"
        "log/slog"
        "os"
        "slices"
        "sort"

        mapset "github.com/deckarep/golang-set/v2"
        "github.com/parquet-go/parquet-go"

        "github.com/cardinalhq/lakerunner/internal/buffet"
        "github.com/cardinalhq/lakerunner/internal/filecrunch"
        "github.com/cardinalhq/lakerunner/internal/helpers"
)

const maxRowsSortBuffer = 5000

type SplitKey struct {
        DateInt       int32
        IngestDateint int32
}

type HourlyResult struct {
        FileName     string
        FileSize     int64
        RecordCount  int64
        Fingerprints mapset.Set[int64]
        FirstTS      int64
        LastTS       int64
}

type gs struct {
        chunks  []string
        buf     []map[string]any
        prints  mapset.Set[int64]
        firstTS int64
        lastTS  int64
}

// ProcessAndSplit reads every record from fh, groups rows by dateint,
// fingerprints them, buffers each group to disk, sorts each buffer by
// `_cardinalhq.timestamp`, and finally merge-sorts the buffers into Parquet
// files in time order.
func ProcessAndSplit(ll *slog.Logger, fh *filecrunch.FileHandle, tmpdir string, ingestDateint int32, rpfEstimate int64) (map[SplitKey]HourlyResult, error) <span class="cov8" title="1">{
        groups := make(map[SplitKey]*gs)

        // 1st pass: read input and write sorted chunks to disk per group.
        reader := parquet.NewReader(fh.File, fh.Schema)
        defer reader.Close()
        for </span><span class="cov8" title="1">{
                rec := map[string]any{}
                if err := reader.Read(&amp;rec); err != nil </span><span class="cov8" title="1">{
                        if errors.Is(err, io.EOF) </span><span class="cov8" title="1">{
                                break</span>
                        }
                        <span class="cov0" title="0">return nil, fmt.Errorf("reading parquet: %w", err)</span>
                }
                <span class="cov8" title="1">tsRaw, ok := rec["_cardinalhq.timestamp"]
                if !ok || tsRaw == nil </span><span class="cov0" title="0">{
                        ll.Warn("Skipping record without timestamp", slog.Any("record", rec))
                        continue</span>
                }
                <span class="cov8" title="1">ms := getMS(tsRaw)
                dateint, _ := helpers.MSToDateintHour(ms)
                key := SplitKey{DateInt: dateint, IngestDateint: ingestDateint}

                st, exists := groups[key]
                if !exists </span><span class="cov8" title="1">{
                        st = &amp;gs{
                                buf:    make([]map[string]any, 0, maxRowsSortBuffer),
                                prints: mapset.NewSet[int64](),
                        }
                        groups[key] = st
                }</span>
                // copy row for buffering
                <span class="cov8" title="1">row := make(map[string]any, len(rec))
                for k, v := range rec </span><span class="cov8" title="1">{
                        row[k] = v
                }</span>
                <span class="cov8" title="1">st.buf = append(st.buf, row)
                if len(st.buf) &gt;= maxRowsSortBuffer </span><span class="cov8" title="1">{
                        if err := flushChunk(st, tmpdir); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                }
                <span class="cov8" title="1">if st.firstTS == 0 || ms &lt; st.firstTS </span><span class="cov8" title="1">{
                        st.firstTS = ms
                }</span>
                <span class="cov8" title="1">if ms &gt; st.lastTS </span><span class="cov8" title="1">{
                        st.lastTS = ms
                }</span>

                <span class="cov8" title="1">addfp(fh.Schema, row, st.prints)</span>
        }

        // flush remaining buffers
        <span class="cov8" title="1">for _, st := range groups </span><span class="cov8" title="1">{
                if len(st.buf) &gt; 0 </span><span class="cov8" title="1">{
                        if err := flushChunk(st, tmpdir); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                }
        }

        // 2nd pass: merge chunks into Parquet files.
        <span class="cov8" title="1">results := make(map[SplitKey]HourlyResult, len(groups))
        for key, st := range groups </span><span class="cov8" title="1">{
                if len(st.chunks) == 0 </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">w, err := buffet.NewWriter(fh.File.Name(), tmpdir, fh.Nodes, rpfEstimate)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">res, err := mergeChunks(w, st.chunks)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">if len(res) == 0 </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">results[key] = HourlyResult{
                        FileName:     res[0].FileName,
                        RecordCount:  res[0].RecordCount,
                        FileSize:     res[0].FileSize,
                        Fingerprints: st.prints,
                        FirstTS:      st.firstTS,
                        LastTS:       st.lastTS,
                }</span>
        }
        <span class="cov8" title="1">return results, nil</span>
}

func getMS(v any) int64 <span class="cov8" title="1">{
        switch ts := v.(type) </span>{
        case int64:<span class="cov8" title="1">
                return ts</span>
        case float64:<span class="cov0" title="0">
                return int64(ts)</span>
        default:<span class="cov0" title="0">
                return 0</span>
        }
}

func flushChunk(st *gs, tmpdir string) error <span class="cov8" title="1">{
        sort.Slice(st.buf, func(i, j int) bool </span><span class="cov8" title="1">{
                return getMS(st.buf[i]["_cardinalhq.timestamp"]) &lt; getMS(st.buf[j]["_cardinalhq.timestamp"])
        }</span>)
        <span class="cov8" title="1">f, err := os.CreateTemp(tmpdir, "tschunk-*.gob")
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">enc := gob.NewEncoder(f)
        for _, r := range st.buf </span><span class="cov8" title="1">{
                if err := enc.Encode(r); err != nil </span><span class="cov0" title="0">{
                        _ = f.Close()
                        return err
                }</span>
        }
        <span class="cov8" title="1">if err := f.Close(); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov8" title="1">st.chunks = append(st.chunks, f.Name())
        st.buf = st.buf[:0]
        return nil</span>
}

type chunkReader struct {
        f   *os.File
        dec *gob.Decoder
        row map[string]any
}

func newChunkReader(path string) (*chunkReader, error) <span class="cov8" title="1">{
        f, err := os.Open(path)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov8" title="1">cr := &amp;chunkReader{f: f, dec: gob.NewDecoder(f)}
        if err := cr.next(); err != nil </span><span class="cov0" title="0">{
                if errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                        _ = f.Close()
                        return nil, nil
                }</span>
                <span class="cov0" title="0">_ = f.Close()
                return nil, err</span>
        }
        <span class="cov8" title="1">return cr, nil</span>
}

func (c *chunkReader) next() error <span class="cov8" title="1">{
        var m map[string]any
        if err := c.dec.Decode(&amp;m); err != nil </span><span class="cov8" title="1">{
                return err
        }</span>
        <span class="cov8" title="1">c.row = m
        return nil</span>
}

func (c *chunkReader) Close() error <span class="cov8" title="1">{ return c.f.Close() }</span>

type chunkHeap []*chunkReader

func (h chunkHeap) Len() int <span class="cov8" title="1">{ return len(h) }</span>
func (h chunkHeap) Less(i, j int) bool <span class="cov8" title="1">{
        return getMS(h[i].row["_cardinalhq.timestamp"]) &lt; getMS(h[j].row["_cardinalhq.timestamp"])
}</span>
func (h chunkHeap) Swap(i, j int) <span class="cov8" title="1">{ h[i], h[j] = h[j], h[i] }</span>

func (h *chunkHeap) Push(x any) <span class="cov8" title="1">{
        *h = append(*h, x.(*chunkReader))
}</span>

func (h *chunkHeap) Pop() any <span class="cov8" title="1">{
        old := *h
        n := len(old)
        x := old[n-1]
        *h = old[:n-1]
        return x
}</span>

func mergeChunks(w *buffet.Writer, paths []string) ([]buffet.Result, error) <span class="cov8" title="1">{
        h := &amp;chunkHeap{}
        for _, p := range paths </span><span class="cov8" title="1">{
                cr, err := newChunkReader(p)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov8" title="1">if cr != nil </span><span class="cov8" title="1">{
                        heap.Push(h, cr)
                }</span>
        }
        <span class="cov8" title="1">for h.Len() &gt; 0 </span><span class="cov8" title="1">{
                cr := heap.Pop(h).(*chunkReader)
                if err := w.Write(cr.row); err != nil </span><span class="cov0" title="0">{
                        _ = cr.Close()
                        return nil, err
                }</span>
                <span class="cov8" title="1">if err := cr.next(); err != nil </span><span class="cov8" title="1">{
                        if !errors.Is(err, io.EOF) </span><span class="cov0" title="0">{
                                _ = cr.Close()
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">_ = cr.Close()</span>
                } else<span class="cov8" title="1"> {
                        heap.Push(h, cr)
                }</span>
        }
        <span class="cov8" title="1">res, err := w.Close()
        for _, p := range paths </span><span class="cov8" title="1">{
                _ = os.Remove(p)
        }</span>
        <span class="cov8" title="1">return res, err</span>
}

func addfp(schema *parquet.Schema, row map[string]any, accum mapset.Set[int64]) <span class="cov8" title="1">{
        vals := make(map[string]mapset.Set[string])
        for _, cols := range schema.Columns() </span><span class="cov8" title="1">{
                for _, col := range cols </span><span class="cov8" title="1">{
                        vals[col] = mapset.NewSet[string]()
                }</span>
        }

        <span class="cov8" title="1">seenrows := map[string]struct{}{}
        for k, v := range row </span><span class="cov8" title="1">{
                if v != nil </span><span class="cov8" title="1">{
                        if !slices.Contains(DimensionsToIndex, k) &amp;&amp; asString(v) != "" </span><span class="cov8" title="1">{
                                vals[k].Add(ExistsRegex)
                                seenrows[k] = struct{}{}
                                continue</span>
                        }
                        <span class="cov8" title="1">s := asString(v)
                        if s == "" </span><span class="cov8" title="1">{
                                continue</span>
                        }
                        <span class="cov8" title="1">vals[k].Add(s)
                        seenrows[k] = struct{}{}</span>

                }
        }

        // remove any columns in vals that are not in seenrows
        <span class="cov8" title="1">for k := range vals </span><span class="cov8" title="1">{
                if _, ok := seenrows[k]; !ok </span><span class="cov8" title="1">{
                        delete(vals, k)
                }</span>
        }

        <span class="cov8" title="1">for f := range ToFingerprints(vals).Iter() </span><span class="cov8" title="1">{
                accum.Add(f)
        }</span>
}

func asString(v any) string <span class="cov8" title="1">{
        if v == nil </span><span class="cov0" title="0">{
                return ""
        }</span>
        <span class="cov8" title="1">switch val := v.(type) </span>{
        case string:<span class="cov8" title="1">
                return val</span>
        case int, int8, int16, int32, int64:<span class="cov8" title="1">
                return fmt.Sprintf("%d", val)</span>
        case float32, float64:<span class="cov0" title="0">
                return fmt.Sprintf("%f", val)</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("%v", v)</span>
        }
}
</pre>
		
		<pre class="file" id="file80" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package storageprofile

import (
        "context"

        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/internal/configdb"
)

type databaseProvider struct {
        cdb ConfigDBStoreageProfileFetcher
}

var _ StorageProfileProvider = (*databaseProvider)(nil)

type ConfigDBStoreageProfileFetcher interface {
        GetStorageProfile(ctx context.Context, params configdb.GetStorageProfileParams) (configdb.GetStorageProfileRow, error)
        GetStorageProfileByCollectorName(ctx context.Context, params configdb.GetStorageProfileByCollectorNameParams) (configdb.GetStorageProfileByCollectorNameRow, error)
        GetStorageProfilesByBucketName(ctx context.Context, bucketName string) ([]configdb.GetStorageProfilesByBucketNameRow, error)
}

func NewDatabaseProvider(cdb ConfigDBStoreageProfileFetcher) StorageProfileProvider <span class="cov8" title="1">{
        return &amp;databaseProvider{
                cdb: cdb,
        }
}</span>

func (p *databaseProvider) Get(ctx context.Context, organizationID uuid.UUID, instanceNum int16) (StorageProfile, error) <span class="cov8" title="1">{
        profile, err := p.cdb.GetStorageProfile(ctx, configdb.GetStorageProfileParams{
                OrganizationID: organizationID,
                InstanceNum:    instanceNum,
        })
        if err != nil </span><span class="cov8" title="1">{
                return StorageProfile{}, err
        }</span>
        <span class="cov8" title="1">ret := StorageProfile{
                OrganizationID: profile.OrganizationID,
                InstanceNum:    profile.InstanceNum,
                CollectorName:  profile.ExternalID,
                CloudProvider:  profile.CloudProvider,
                Region:         profile.Region,
                Bucket:         profile.Bucket,
                Hosted:         profile.Hosted,
        }
        if profile.Role != nil </span><span class="cov8" title="1">{
                ret.Role = *profile.Role
        }</span>
        <span class="cov8" title="1">return ret, nil</span>
}

func (p *databaseProvider) GetByCollectorName(ctx context.Context, organizationID uuid.UUID, collectorName string) (StorageProfile, error) <span class="cov0" title="0">{
        profile, err := p.cdb.GetStorageProfileByCollectorName(ctx, configdb.GetStorageProfileByCollectorNameParams{
                OrganizationID: organizationID,
                CollectorName:  collectorName,
        })
        if err != nil </span><span class="cov0" title="0">{
                return StorageProfile{}, err
        }</span>
        <span class="cov0" title="0">ret := StorageProfile{
                OrganizationID: profile.OrganizationID,
                InstanceNum:    profile.InstanceNum,
                CollectorName:  profile.ExternalID,
                CloudProvider:  profile.CloudProvider,
                Region:         profile.Region,
                Bucket:         profile.Bucket,
                Hosted:         profile.Hosted,
        }
        if profile.Role != nil </span><span class="cov0" title="0">{
                ret.Role = *profile.Role
        }</span>
        <span class="cov0" title="0">return ret, nil</span>
}

func (p *databaseProvider) GetStorageProfilesByBucketName(ctx context.Context, bucketName string) ([]StorageProfile, error) <span class="cov0" title="0">{
        profiles, err := p.cdb.GetStorageProfilesByBucketName(ctx, bucketName)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">ret := make([]StorageProfile, len(profiles))
        for i, p := range profiles </span><span class="cov0" title="0">{
                ret[i] = StorageProfile{
                        OrganizationID: p.OrganizationID,
                        InstanceNum:    p.InstanceNum,
                        CollectorName:  p.ExternalID,
                        CloudProvider:  p.CloudProvider,
                        Region:         p.Region,
                        Bucket:         p.Bucket,
                        Hosted:         p.Hosted,
                }
                if p.Role != nil </span><span class="cov0" title="0">{
                        ret[i].Role = *p.Role
                }</span>
        }
        <span class="cov0" title="0">return ret, nil</span>
}
</pre>
		
		<pre class="file" id="file81" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package storageprofile

import (
        "bytes"
        "context"
        "fmt"
        "os"
        "strings"

        "github.com/google/uuid"
        "gopkg.in/yaml.v3"
)

type fileProvider struct {
        profiles []StorageProfile
}

var _ StorageProfileProvider = (*fileProvider)(nil)

func NewFileProvider(filename string) (StorageProfileProvider, error) <span class="cov8" title="1">{
        if after, ok := strings.CutPrefix(filename, "env:"); ok </span><span class="cov8" title="1">{
                envVar := after
                contents := os.Getenv(envVar)
                if contents == "" </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("environment variable %s is not set", envVar)
                }</span>
                <span class="cov8" title="1">return newFileProviderFromContents(filename, []byte(contents))</span>
        }

        <span class="cov0" title="0">contents, err := os.ReadFile(filename)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to read storage profiles from file %s: %w", filename, err)
        }</span>

        <span class="cov0" title="0">return newFileProviderFromContents(filename, contents)</span>
}

func newFileProviderFromContents(filename string, contents []byte) (StorageProfileProvider, error) <span class="cov8" title="1">{
        var profiles []StorageProfile

        dec := yaml.NewDecoder(bytes.NewReader(contents))
        dec.KnownFields(true)
        if err := dec.Decode(&amp;profiles); err != nil </span><span class="cov8" title="1">{
                return nil, fmt.Errorf("failed to unmarshal storage profiles from file %s: %w", filename, err)
        }</span>

        // if there is no role, set hosted to true
        <span class="cov8" title="1">for i := range profiles </span><span class="cov8" title="1">{
                if profiles[i].Role == "" </span><span class="cov0" title="0">{
                        profiles[i].Hosted = true
                }</span>
        }

        <span class="cov8" title="1">p := &amp;fileProvider{
                profiles: profiles,
        }

        return p, nil</span>
}

func (p *fileProvider) Get(ctx context.Context, organizationID uuid.UUID, instanceNum int16) (StorageProfile, error) <span class="cov8" title="1">{
        for _, profile := range p.profiles </span><span class="cov8" title="1">{
                if profile.OrganizationID == organizationID &amp;&amp; profile.InstanceNum == instanceNum </span><span class="cov8" title="1">{
                        return profile, nil
                }</span>
        }
        <span class="cov8" title="1">return StorageProfile{}, fmt.Errorf("storage profile not found for organization %s and instance %d", organizationID, instanceNum)</span>
}

func (p *fileProvider) GetByCollectorName(ctx context.Context, organizationID uuid.UUID, collectorName string) (StorageProfile, error) <span class="cov0" title="0">{
        for _, profile := range p.profiles </span><span class="cov0" title="0">{
                if profile.OrganizationID == organizationID &amp;&amp; profile.CollectorName == collectorName </span><span class="cov0" title="0">{
                        return profile, nil
                }</span>
        }
        <span class="cov0" title="0">return StorageProfile{}, fmt.Errorf("storage profile not found for organization %s and collector name %s", organizationID, collectorName)</span>
}

func (p *fileProvider) GetStorageProfilesByBucketName(ctx context.Context, bucketName string) ([]StorageProfile, error) <span class="cov0" title="0">{
        ret := []StorageProfile{}
        for _, profile := range p.profiles </span><span class="cov0" title="0">{
                if profile.Bucket == bucketName </span><span class="cov0" title="0">{
                        ret = append(ret, profile)
                }</span>
        }
        <span class="cov0" title="0">return ret, nil</span>
}
</pre>
		
		<pre class="file" id="file82" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package storageprofile

import (
        "context"
        "errors"
        "log/slog"
        "os"

        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/cmd/dbopen"
)

type StorageProfile struct {
        OrganizationID uuid.UUID `json:"organization_id" yaml:"organization_id"`
        InstanceNum    int16     `json:"instance_num" yaml:"instance_num"`
        CollectorName  string    `json:"collector_name" yaml:"collector_name"`
        CloudProvider  string    `json:"cloud_provider" yaml:"cloud_provider"`
        Region         string    `json:"region" yaml:"region"`
        Role           string    `json:"role,omitempty" yaml:"role,omitempty"`
        Bucket         string    `json:"bucket" yaml:"bucket"`
        Hosted         bool      `json:"hosted,omitempty" yaml:"hosted,omitempty"`
        Endpoint       string    `json:"endpoint,omitempty" yaml:"endpoint,omitempty"`
        InsecureTLS    bool      `json:"insecure_tls,omitempty" yaml:"insecure_tls,omitempty"`
        UsePathStyle   bool      `json:"use_path_style,omitempty" yaml:"use_path_style,omitempty"`
        UseSSL         bool      `json:"use_ssl,omitempty" yaml:"use_ssl,omitempty"`
}

type StorageProfileProvider interface {
        Get(ctx context.Context, organizationID uuid.UUID, instanceNum int16) (StorageProfile, error)
        GetStorageProfilesByBucketName(ctx context.Context, bucketName string) ([]StorageProfile, error)
        GetByCollectorName(ctx context.Context, organizationID uuid.UUID, collectorName string) (StorageProfile, error)
}

func SetupStorageProfiles() (StorageProfileProvider, error) <span class="cov0" title="0">{
        cdb, err := dbopen.ConfigDBStore(context.Background())
        if err == nil </span><span class="cov0" title="0">{
                sp := NewDatabaseProvider(cdb)
                slog.Info("Using database storage profile provider")
                return sp, nil
        }</span>
        <span class="cov0" title="0">if !errors.Is(err, dbopen.ErrDatabaseNotConfigured) </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">slog.Info("Database storage profile provider not configured, falling back to file provider", "error", err)

        storagePath := os.Getenv("STORAGE_PROFILE_FILE")
        if storagePath == "" </span><span class="cov0" title="0">{
                storagePath = "/app/config/storage_profiles.yaml"
        }</span>
        <span class="cov0" title="0">slog.Info("Using file storage profile provider", "path", storagePath)
        return NewFileProvider(storagePath)</span>
}
</pre>
		
		<pre class="file" id="file83" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lockmgr

import (
        "log/slog"
        "time"
)

type Options interface {
        apply(m *wqManager)
}

type heartbeatIntervalOption struct {
        d time.Duration
}

func (h *heartbeatIntervalOption) apply(m *wqManager) <span class="cov8" title="1">{
        if h.d &lt;= 10*time.Second </span><span class="cov8" title="1">{
                h.d = 10 * time.Second
        }</span>
        <span class="cov8" title="1">m.heartbeatInterval = h.d</span>
}

// WithHeartbeatInterval sets the interval for heartbeating work items.
// Without this option, the default is 1 minute.
// If the interval is set to less than 10 seconds, it will be adjusted to 10 seconds.
func WithHeartbeatInterval(d time.Duration) Options <span class="cov8" title="1">{
        return &amp;heartbeatIntervalOption{d: d}
}</span>

type loggerOption struct {
        ll *slog.Logger
}

func (l *loggerOption) apply(m *wqManager) <span class="cov8" title="1">{
        m.ll = l.ll
}</span>

func WithLogger(ll *slog.Logger) Options <span class="cov8" title="1">{
        return &amp;loggerOption{ll: ll}
}</span>
</pre>
		
		<pre class="file" id="file84" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lockmgr

import (
        "errors"
        "time"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5/pgtype"

        "github.com/cardinalhq/lakerunner/lrdb"
)

// WorkItem represents a single row pulled from work_queue.
type WorkItem struct {
        id          int64
        orgId       uuid.UUID
        instanceNum int16
        dateint     int32
        frequencyMs int32
        signal      lrdb.SignalEnum
        tries       int32
        action      lrdb.ActionEnum
        tsRange     pgtype.Range[pgtype.Timestamptz]
        priority    int32
        runnableAt  time.Time

        closed bool
        mgr    *wqManager
}

type Workable interface {
        Complete() error
        Fail() error
        ID() int64
        OrganizationID() uuid.UUID
        InstanceNum() int16
        Dateint() int32
        FrequencyMs() int32
        Signal() lrdb.SignalEnum
        Tries() int32
        Action() lrdb.ActionEnum
        TsRange() pgtype.Range[pgtype.Timestamptz]
        Priority() int32
        AsMap() map[string]any
        RunnableAt() time.Time
}

var _ Workable = (*WorkItem)(nil)

// Complete marks the work item as done, removes it from acquiredIDs, and calls the DB stored proc.
func (w *WorkItem) Complete() error <span class="cov0" title="0">{
        if w.closed </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">w.closed = true

        if w.mgr == nil </span><span class="cov0" title="0">{
                return errors.New("work item manager is nil")
        }</span>

        <span class="cov0" title="0">req := &amp;workCompleteRequest{
                WorkItem: w,
                resp:     make(chan error, 1),
        }
        w.mgr.completeWork &lt;- req
        return &lt;-req.resp</span>
}

// Fail indicates that the work item failed; it removes it from acquiredIDs and calls WorkQueueFail.
func (w *WorkItem) Fail() error <span class="cov0" title="0">{
        if w.closed </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">w.closed = true

        if w.mgr == nil </span><span class="cov0" title="0">{
                return errors.New("work item manager is nil")
        }</span>

        <span class="cov0" title="0">req := &amp;workFailRequest{
                WorkItem: w,
                resp:     make(chan error, 1),
        }
        w.mgr.failWork &lt;- req
        return &lt;-req.resp</span>
}

// ID returns the unique identifier for the work item.
func (w *WorkItem) ID() int64 <span class="cov0" title="0">{
        return w.id
}</span>

// OrganizationID returns the organization ID associated with the work item.
func (w *WorkItem) OrganizationID() uuid.UUID <span class="cov0" title="0">{
        return w.orgId
}</span>

// InstanceNum returns the instance number associated with the work item.
func (w *WorkItem) InstanceNum() int16 <span class="cov0" title="0">{
        return w.instanceNum
}</span>

// Dateint returns the date integer associated with the work item.

func (w *WorkItem) Dateint() int32 <span class="cov0" title="0">{
        return w.dateint
}</span>

// FrequencyMs returns the frequency in milliseconds for the work item.

func (w *WorkItem) FrequencyMs() int32 <span class="cov0" title="0">{
        return w.frequencyMs
}</span>

// Signal returns the signal type for the work item.
func (w *WorkItem) Signal() lrdb.SignalEnum <span class="cov0" title="0">{
        return w.signal
}</span>

// Tries returns the number of tries for the work item.
func (w *WorkItem) Tries() int32 <span class="cov0" title="0">{
        return w.tries
}</span>

// Action returns the action type for the work item.
func (w *WorkItem) Action() lrdb.ActionEnum <span class="cov0" title="0">{
        return w.action
}</span>

// TsRange returns the timestamp range for the work item.
func (w *WorkItem) TsRange() pgtype.Range[pgtype.Timestamptz] <span class="cov0" title="0">{
        return w.tsRange
}</span>

// Priority returns the priority of the work item.
func (w *WorkItem) Priority() int32 <span class="cov0" title="0">{
        return w.priority
}</span>

// RunnableAt returns the time when the work item is runnable.
func (w *WorkItem) RunnableAt() time.Time <span class="cov0" title="0">{
        return w.runnableAt
}</span>

// AsMap converts the work item to a map representation.
func (w *WorkItem) AsMap() map[string]any <span class="cov0" title="0">{
        return map[string]any{
                "id":          w.id,
                "orgId":       w.orgId,
                "instanceNum": w.instanceNum,
                "dateint":     w.dateint,
                "frequencyMs": w.frequencyMs,
                "signal":      w.signal,
                "tries":       w.tries,
                "action":      w.action,
                "tsRange":     w.tsRange,
                "priority":    w.priority,
                "runnableAt":  w.runnableAt,
        }
}</span>
</pre>
		
		<pre class="file" id="file85" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lockmgr

import (
        "context"
        "errors"
        "log/slog"
        "slices"
        "strings"
        "time"

        "github.com/jackc/pgx/v5"

        "github.com/cardinalhq/lakerunner/lrdb"
)

// wqManager drives fetching items from the DB and heartbeating them.
type wqManager struct {
        // constructor parameters
        mdb             lrdb.StoreFull
        workerID        int64
        signal          lrdb.SignalEnum
        action          lrdb.ActionEnum
        frequencies     []int32
        minimumPriority int32

        // defaults but set via options
        heartbeatInterval time.Duration
        ll                *slog.Logger

        // currently acquired work item IDs
        acquiredIDs []int64

        // channels for internal processing
        getWork      chan *workRequest
        completeWork chan *workCompleteRequest
        failWork     chan *workFailRequest
}

type workCompleteRequest struct {
        WorkItem *WorkItem
        resp     chan error
}

func (m *wqManager) completeWorkItem(ctx context.Context, w *WorkItem) error <span class="cov0" title="0">{
        m.acquiredIDs = slices.DeleteFunc(m.acquiredIDs, func(id int64) bool </span><span class="cov0" title="0">{
                return id == w.id
        }</span>)

        <span class="cov0" title="0">err := m.mdb.WorkQueueComplete(ctx, lrdb.WorkQueueCompleteParams{
                ID:       w.id,
                WorkerID: m.workerID,
        })
        return err</span>
}

type workFailRequest struct {
        WorkItem *WorkItem
        resp     chan error
}

func (m *wqManager) failWorkItem(ctx context.Context, w *WorkItem) error <span class="cov0" title="0">{
        m.acquiredIDs = slices.DeleteFunc(m.acquiredIDs, func(id int64) bool </span><span class="cov0" title="0">{
                return id == w.id
        }</span>)
        <span class="cov0" title="0">err := m.mdb.WorkQueueFail(ctx, lrdb.WorkQueueFailParams{
                ID:       w.id,
                WorkerID: m.workerID,
        })
        return err</span>
}

// NewWorkQueueManager constructs a manager to manage obtaining and completing work items.
// The work items are automatically heartbeated to retain ownership of the work items.
func NewWorkQueueManager(
        mdb lrdb.StoreFull,
        workerID int64,
        sig lrdb.SignalEnum,
        act lrdb.ActionEnum,
        frequencies []int32,
        minimumPriority int32,
        opts ...Options,
) WorkQueueManager <span class="cov0" title="0">{
        m := &amp;wqManager{
                mdb:               mdb,
                workerID:          workerID,
                signal:            sig,
                action:            act,
                frequencies:       frequencies,
                minimumPriority:   minimumPriority,
                getWork:           make(chan *workRequest, 5),
                completeWork:      make(chan *workCompleteRequest, 5),
                failWork:          make(chan *workFailRequest, 5),
                heartbeatInterval: time.Minute,
        }
        for _, opt := range opts </span><span class="cov0" title="0">{
                opt.apply(m)
        }</span>
        <span class="cov0" title="0">return m</span>
}

type WorkQueueManager interface {
        // Run starts the background goroutine that processes work requests.
        Run(ctx context.Context)
        // RequestWork requests the next work item, returning nil if no work is available.
        RequestWork() (*WorkItem, error)
}

var _ WorkQueueManager = (*wqManager)(nil)

// Run starts a background goroutine that listens for work‐requests (on getWork) and
// periodically heartbeats all acquired IDs.  When ctx is canceled, the loop exits.
func (m *wqManager) Run(ctx context.Context) <span class="cov0" title="0">{
        go m.runLoop(ctx)
}</span>

// runLoop is the internal processing loop.
func (m *wqManager) runLoop(ctx context.Context) <span class="cov0" title="0">{
        if m.ll == nil </span><span class="cov0" title="0">{
                m.ll = slog.Default()
        }</span>

        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return</span>

                case req := &lt;-m.getWork:<span class="cov0" title="0">
                        work, err := m.getWorkItem(ctx)
                        req.resp &lt;- &amp;workRequestResponse{
                                work: work,
                                err:  err,
                        }</span>

                case req := &lt;-m.completeWork:<span class="cov0" title="0">
                        req.resp &lt;- m.completeWorkItem(ctx, req.WorkItem)</span>

                case req := &lt;-m.failWork:<span class="cov0" title="0">
                        req.resp &lt;- m.failWorkItem(ctx, req.WorkItem)</span>

                case &lt;-time.Tick(m.heartbeatInterval):<span class="cov0" title="0">
                        m.heartbeat(ctx)</span>
                }
        }
}

// GetWork queries the DB for the next row and records its ID in acquiredIDs.
func (m *wqManager) getWorkItem(ctx context.Context) (*WorkItem, error) <span class="cov0" title="0">{
        row, err := m.mdb.WorkQueueClaim(ctx, lrdb.WorkQueueClaimParams{
                WorkerID:    m.workerID,
                Signal:      m.signal,
                Action:      m.action,
                TargetFreqs: m.frequencies,
                MinPriority: m.minimumPriority,
        })
        if err != nil </span><span class="cov0" title="0">{
                if errors.Is(err, pgx.ErrNoRows) </span><span class="cov0" title="0">{
                        return nil, nil
                }</span>
                <span class="cov0" title="0">if strings.Contains(err.Error(), "23P01") </span><span class="cov0" title="0">{ // constraint violation, ignore for now
                        return nil, nil
                }</span>
                <span class="cov0" title="0">return nil, err</span>
        }

        <span class="cov0" title="0">work := &amp;WorkItem{
                id:          row.ID,
                orgId:       row.OrganizationID,
                instanceNum: row.InstanceNum,
                dateint:     row.Dateint,
                frequencyMs: row.FrequencyMs,
                signal:      row.Signal,
                tries:       row.Tries,
                action:      row.Action,
                tsRange:     row.TsRange,
                priority:    row.Priority,
                runnableAt:  row.RunnableAt,
                mgr:         m,
        }

        m.acquiredIDs = append(m.acquiredIDs, work.id)
        return work, nil</span>
}

func (m *wqManager) heartbeat(ctx context.Context) <span class="cov0" title="0">{
        err := m.mdb.WorkQueueHeartbeat(ctx, lrdb.WorkQueueHeartbeatParams{
                Ids:      m.acquiredIDs,
                WorkerID: m.workerID,
        })
        if err != nil </span><span class="cov0" title="0">{
                m.ll.Error("failed to heartbeat work queue (continuing)", "error", err)
                return
        }</span>
}

// workRequest is used internally to request a work item and receive the result.
type workRequest struct {
        resp chan *workRequestResponse
}

type workRequestResponse struct {
        work *WorkItem
        err  error
}

// RequestWork requests the next work item, returning nil if no work is available.
func (m *wqManager) RequestWork() (*WorkItem, error) <span class="cov0" title="0">{
        req := &amp;workRequest{
                resp: make(chan *workRequestResponse, 1),
        }

        m.getWork &lt;- req
        work := &lt;-req.resp
        return work.work, work.err
}</span>
</pre>
		
		<pre class="file" id="file86" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: batch.go

package lrdb

import (
        "context"
        "errors"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5"
)

var (
        ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const batchDeleteMetricSegs = `-- name: BatchDeleteMetricSegs :batchexec
DELETE FROM public.metric_seg
 WHERE organization_id = $1
   AND dateint         = $2
   AND frequency_ms    = $3
   AND segment_id      = $4
   AND instance_num    = $5
   AND tid_partition   = $6
`

type BatchDeleteMetricSegsBatchResults struct {
        br     pgx.BatchResults
        tot    int
        closed bool
}

type BatchDeleteMetricSegsParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        FrequencyMs    int32     `json:"frequency_ms"`
        SegmentID      int64     `json:"segment_id"`
        InstanceNum    int16     `json:"instance_num"`
        TidPartition   int16     `json:"tid_partition"`
}

func (q *Queries) BatchDeleteMetricSegs(ctx context.Context, arg []BatchDeleteMetricSegsParams) *BatchDeleteMetricSegsBatchResults <span class="cov0" title="0">{
        batch := &amp;pgx.Batch{}
        for _, a := range arg </span><span class="cov0" title="0">{
                vals := []interface{}{
                        a.OrganizationID,
                        a.Dateint,
                        a.FrequencyMs,
                        a.SegmentID,
                        a.InstanceNum,
                        a.TidPartition,
                }
                batch.Queue(batchDeleteMetricSegs, vals...)
        }</span>
        <span class="cov0" title="0">br := q.db.SendBatch(ctx, batch)
        return &amp;BatchDeleteMetricSegsBatchResults{br, len(arg), false}</span>
}

func (b *BatchDeleteMetricSegsBatchResults) Exec(f func(int, error)) <span class="cov0" title="0">{
        defer b.br.Close()
        for t := 0; t &lt; b.tot; t++ </span><span class="cov0" title="0">{
                if b.closed </span><span class="cov0" title="0">{
                        if f != nil </span><span class="cov0" title="0">{
                                f(t, ErrBatchAlreadyClosed)
                        }</span>
                        <span class="cov0" title="0">continue</span>
                }
                <span class="cov0" title="0">_, err := b.br.Exec()
                if f != nil </span><span class="cov0" title="0">{
                        f(t, err)
                }</span>
        }
}

func (b *BatchDeleteMetricSegsBatchResults) Close() error <span class="cov0" title="0">{
        b.closed = true
        return b.br.Close()
}</span>

const batchInsertMetricSegs = `-- name: BatchInsertMetricSegs :batchexec
INSERT INTO metric_seg (
  organization_id,
  dateint,
  ingest_dateint,
  frequency_ms,
  segment_id,
  instance_num,
  tid_partition,
  ts_range,
  record_count,
  file_size,
  tid_count,
  published,
  created_by,
  rolledup
)
VALUES (
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  $7,
  int8range($8, $9, '[)'),
  $10,
  $11,
  $12,
  $13,
  $14,
  $15
)
`

type BatchInsertMetricSegsBatchResults struct {
        br     pgx.BatchResults
        tot    int
        closed bool
}

type BatchInsertMetricSegsParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        IngestDateint  int32     `json:"ingest_dateint"`
        FrequencyMs    int32     `json:"frequency_ms"`
        SegmentID      int64     `json:"segment_id"`
        InstanceNum    int16     `json:"instance_num"`
        TidPartition   int16     `json:"tid_partition"`
        StartTs        int64     `json:"start_ts"`
        EndTs          int64     `json:"end_ts"`
        RecordCount    int64     `json:"record_count"`
        FileSize       int64     `json:"file_size"`
        TidCount       int32     `json:"tid_count"`
        Published      bool      `json:"published"`
        CreatedBy      CreatedBy `json:"created_by"`
        Rolledup       bool      `json:"rolledup"`
}

func (q *Queries) BatchInsertMetricSegs(ctx context.Context, arg []BatchInsertMetricSegsParams) *BatchInsertMetricSegsBatchResults <span class="cov0" title="0">{
        batch := &amp;pgx.Batch{}
        for _, a := range arg </span><span class="cov0" title="0">{
                vals := []interface{}{
                        a.OrganizationID,
                        a.Dateint,
                        a.IngestDateint,
                        a.FrequencyMs,
                        a.SegmentID,
                        a.InstanceNum,
                        a.TidPartition,
                        a.StartTs,
                        a.EndTs,
                        a.RecordCount,
                        a.FileSize,
                        a.TidCount,
                        a.Published,
                        a.CreatedBy,
                        a.Rolledup,
                }
                batch.Queue(batchInsertMetricSegs, vals...)
        }</span>
        <span class="cov0" title="0">br := q.db.SendBatch(ctx, batch)
        return &amp;BatchInsertMetricSegsBatchResults{br, len(arg), false}</span>
}

func (b *BatchInsertMetricSegsBatchResults) Exec(f func(int, error)) <span class="cov0" title="0">{
        defer b.br.Close()
        for t := 0; t &lt; b.tot; t++ </span><span class="cov0" title="0">{
                if b.closed </span><span class="cov0" title="0">{
                        if f != nil </span><span class="cov0" title="0">{
                                f(t, ErrBatchAlreadyClosed)
                        }</span>
                        <span class="cov0" title="0">continue</span>
                }
                <span class="cov0" title="0">_, err := b.br.Exec()
                if f != nil </span><span class="cov0" title="0">{
                        f(t, err)
                }</span>
        }
}

func (b *BatchInsertMetricSegsBatchResults) Close() error <span class="cov0" title="0">{
        b.closed = true
        return b.br.Close()
}</span>

const batchMarkMetricSegsRolledup = `-- name: BatchMarkMetricSegsRolledup :batchexec
UPDATE public.metric_seg
   SET rolledup = true
 WHERE organization_id = $1
   AND dateint         = $2
   AND frequency_ms    = $3
   AND segment_id      = $4
   AND instance_num    = $5
   AND tid_partition   = $6
`

type BatchMarkMetricSegsRolledupBatchResults struct {
        br     pgx.BatchResults
        tot    int
        closed bool
}

type BatchMarkMetricSegsRolledupParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        FrequencyMs    int32     `json:"frequency_ms"`
        SegmentID      int64     `json:"segment_id"`
        InstanceNum    int16     `json:"instance_num"`
        TidPartition   int16     `json:"tid_partition"`
}

func (q *Queries) BatchMarkMetricSegsRolledup(ctx context.Context, arg []BatchMarkMetricSegsRolledupParams) *BatchMarkMetricSegsRolledupBatchResults <span class="cov0" title="0">{
        batch := &amp;pgx.Batch{}
        for _, a := range arg </span><span class="cov0" title="0">{
                vals := []interface{}{
                        a.OrganizationID,
                        a.Dateint,
                        a.FrequencyMs,
                        a.SegmentID,
                        a.InstanceNum,
                        a.TidPartition,
                }
                batch.Queue(batchMarkMetricSegsRolledup, vals...)
        }</span>
        <span class="cov0" title="0">br := q.db.SendBatch(ctx, batch)
        return &amp;BatchMarkMetricSegsRolledupBatchResults{br, len(arg), false}</span>
}

func (b *BatchMarkMetricSegsRolledupBatchResults) Exec(f func(int, error)) <span class="cov0" title="0">{
        defer b.br.Close()
        for t := 0; t &lt; b.tot; t++ </span><span class="cov0" title="0">{
                if b.closed </span><span class="cov0" title="0">{
                        if f != nil </span><span class="cov0" title="0">{
                                f(t, ErrBatchAlreadyClosed)
                        }</span>
                        <span class="cov0" title="0">continue</span>
                }
                <span class="cov0" title="0">_, err := b.br.Exec()
                if f != nil </span><span class="cov0" title="0">{
                        f(t, err)
                }</span>
        }
}

func (b *BatchMarkMetricSegsRolledupBatchResults) Close() error <span class="cov0" title="0">{
        b.closed = true
        return b.br.Close()
}</span>
</pre>
		
		<pre class="file" id="file87" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0

package lrdb

import (
        "context"

        "github.com/jackc/pgx/v5"
        "github.com/jackc/pgx/v5/pgconn"
)

type DBTX interface {
        Exec(context.Context, string, ...interface{}) (pgconn.CommandTag, error)
        Query(context.Context, string, ...interface{}) (pgx.Rows, error)
        QueryRow(context.Context, string, ...interface{}) pgx.Row
        SendBatch(context.Context, *pgx.Batch) pgx.BatchResults
}

func New(db DBTX) *Queries <span class="cov0" title="0">{
        return &amp;Queries{db: db}
}</span>

type Queries struct {
        db DBTX
}

func (q *Queries) WithTx(tx pgx.Tx) *Queries <span class="cov0" title="0">{
        return &amp;Queries{
                db: tx,
        }
}</span>
</pre>
		
		<pre class="file" id="file88" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: inqueue.sql

package lrdb

import (
        "context"

        "github.com/google/uuid"
)

const claimInqueueWork = `-- name: ClaimInqueueWork :one
UPDATE inqueue AS i
SET
  claimed_by = $1,
  claimed_at = NOW()
WHERE i.id = (
  SELECT ii.id
  FROM inqueue ii
  WHERE ii.claimed_at IS NULL
    AND ii.telemetry_type = $2
  ORDER BY ii.priority DESC, ii.queue_ts
  LIMIT 1
  FOR UPDATE SKIP LOCKED
)
RETURNING id, queue_ts, priority, organization_id, collector_name, instance_num, bucket, object_id, telemetry_type, tries, claimed_by, claimed_at
`

type ClaimInqueueWorkParams struct {
        ClaimedBy     int64  `json:"claimed_by"`
        TelemetryType string `json:"telemetry_type"`
}

func (q *Queries) ClaimInqueueWork(ctx context.Context, arg ClaimInqueueWorkParams) (Inqueue, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, claimInqueueWork, arg.ClaimedBy, arg.TelemetryType)
        var i Inqueue
        err := row.Scan(
                &amp;i.ID,
                &amp;i.QueueTs,
                &amp;i.Priority,
                &amp;i.OrganizationID,
                &amp;i.CollectorName,
                &amp;i.InstanceNum,
                &amp;i.Bucket,
                &amp;i.ObjectID,
                &amp;i.TelemetryType,
                &amp;i.Tries,
                &amp;i.ClaimedBy,
                &amp;i.ClaimedAt,
        )
        return i, err
}</span>

const cleanupInqueueWork = `-- name: CleanupInqueueWork :exec
UPDATE inqueue
SET claimed_by = -1, claimed_at = NULL
WHERE claimed_at IS NOT NULL
  AND claimed_at &lt; NOW() - INTERVAL '5 minutes'
`

func (q *Queries) CleanupInqueueWork(ctx context.Context) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, cleanupInqueueWork)
        return err
}</span>

const deleteInqueueWork = `-- name: DeleteInqueueWork :exec
DELETE FROM inqueue
WHERE
  id = $1
  AND claimed_by = $2
`

type DeleteInqueueWorkParams struct {
        ID        uuid.UUID `json:"id"`
        ClaimedBy int64     `json:"claimed_by"`
}

func (q *Queries) DeleteInqueueWork(ctx context.Context, arg DeleteInqueueWorkParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, deleteInqueueWork, arg.ID, arg.ClaimedBy)
        return err
}</span>

const putInqueueWork = `-- name: PutInqueueWork :exec
INSERT INTO inqueue (organization_id, collector_name, instance_num, bucket, object_id, telemetry_type, priority)
VALUES ($1, $2, $3, $4, $5, $6, $7)
`

type PutInqueueWorkParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        CollectorName  string    `json:"collector_name"`
        InstanceNum    int16     `json:"instance_num"`
        Bucket         string    `json:"bucket"`
        ObjectID       string    `json:"object_id"`
        TelemetryType  string    `json:"telemetry_type"`
        Priority       int32     `json:"priority"`
}

func (q *Queries) PutInqueueWork(ctx context.Context, arg PutInqueueWorkParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, putInqueueWork,
                arg.OrganizationID,
                arg.CollectorName,
                arg.InstanceNum,
                arg.Bucket,
                arg.ObjectID,
                arg.TelemetryType,
                arg.Priority,
        )
        return err
}</span>

const releaseInqueueWork = `-- name: ReleaseInqueueWork :exec
UPDATE inqueue
SET
  claimed_by = -1,
  claimed_at = NULL,
  queue_ts = NOW() + INTERVAL '5 second',
  tries = tries + 1
WHERE
  id = $1
  AND claimed_by = $2
`

type ReleaseInqueueWorkParams struct {
        ID        uuid.UUID `json:"id"`
        ClaimedBy int64     `json:"claimed_by"`
}

func (q *Queries) ReleaseInqueueWork(ctx context.Context, arg ReleaseInqueueWorkParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, releaseInqueueWork, arg.ID, arg.ClaimedBy)
        return err
}</span>

const touchInqueueWork = `-- name: TouchInqueueWork :exec
UPDATE inqueue
SET
  claimed_at = NOW()
WHERE
  id IN ($1::uuid[])
  AND claimed_by = $2
`

type TouchInqueueWorkParams struct {
        Ids       []uuid.UUID `json:"ids"`
        ClaimedBy int64       `json:"claimed_by"`
}

func (q *Queries) TouchInqueueWork(ctx context.Context, arg TouchInqueueWorkParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, touchInqueueWork, arg.Ids, arg.ClaimedBy)
        return err
}</span>
</pre>
		
		<pre class="file" id="file89" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: inqueue_journal.sql

package lrdb

import (
        "context"

        "github.com/google/uuid"
)

const inqueueJournalDelete = `-- name: InqueueJournalDelete :exec
DELETE FROM inqueue_journal
WHERE organization_id = $1
  AND bucket = $2
  AND object_id = $3
`

type InqueueJournalDeleteParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Bucket         string    `json:"bucket"`
        ObjectID       string    `json:"object_id"`
}

func (q *Queries) InqueueJournalDelete(ctx context.Context, arg InqueueJournalDeleteParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, inqueueJournalDelete, arg.OrganizationID, arg.Bucket, arg.ObjectID)
        return err
}</span>

const inqueueJournalUpsert = `-- name: InqueueJournalUpsert :one
INSERT INTO inqueue_journal (organization_id, bucket, object_id)
VALUES ($1, $2, $3)
ON CONFLICT (organization_id, bucket, object_id)
  DO UPDATE SET updated_at = clock_timestamp()
RETURNING (updated_at = created_at) AS is_new
`

type InqueueJournalUpsertParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Bucket         string    `json:"bucket"`
        ObjectID       string    `json:"object_id"`
}

func (q *Queries) InqueueJournalUpsert(ctx context.Context, arg InqueueJournalUpsertParams) (bool, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, inqueueJournalUpsert, arg.OrganizationID, arg.Bucket, arg.ObjectID)
        var is_new bool
        err := row.Scan(&amp;is_new)
        return is_new, err
}</span>
</pre>
		
		<pre class="file" id="file90" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: log_seg.sql

package lrdb

import (
        "context"

        "github.com/google/uuid"
)

const compactLogSegments = `-- name: CompactLogSegments :exec
WITH
  all_fp AS (
    SELECT unnest(fingerprints) AS fp
      FROM log_seg
     WHERE organization_id = $1
       AND dateint        = $2
       AND instance_num   = $5
       AND segment_id     = ANY($11::bigint[])
  ),
  fingerprint_array AS (
    SELECT coalesce(
      array_agg(DISTINCT fp ORDER BY fp),
      '{}'::bigint[]
    ) AS fingerprints
    FROM all_fp
  ),
  deleted_seg AS (
    DELETE FROM log_seg
     WHERE organization_id = $1
       AND dateint        = $2
       AND instance_num   = $5
       AND segment_id     = ANY($11::bigint[])
  )
INSERT INTO log_seg (
  organization_id,
  dateint,
  ingest_dateint,
  segment_id,
  instance_num,
  record_count,
  file_size,
  ts_range,
  created_by,
  fingerprints
)
SELECT
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  $7,
  int8range($8, $9, '[)'),
  $10,
  fa.fingerprints
FROM fingerprint_array AS fa
`

type CompactLogSegmentsParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        IngestDateint  int32     `json:"ingest_dateint"`
        NewSegmentID   int64     `json:"new_segment_id"`
        InstanceNum    int16     `json:"instance_num"`
        NewRecordCount int64     `json:"new_record_count"`
        NewFileSize    int64     `json:"new_file_size"`
        NewStartTs     int64     `json:"new_start_ts"`
        NewEndTs       int64     `json:"new_end_ts"`
        CreatedBy      CreatedBy `json:"created_by"`
        OldSegmentIds  []int64   `json:"old_segment_ids"`
}

func (q *Queries) CompactLogSegments(ctx context.Context, arg CompactLogSegmentsParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, compactLogSegments,
                arg.OrganizationID,
                arg.Dateint,
                arg.IngestDateint,
                arg.NewSegmentID,
                arg.InstanceNum,
                arg.NewRecordCount,
                arg.NewFileSize,
                arg.NewStartTs,
                arg.NewEndTs,
                arg.CreatedBy,
                arg.OldSegmentIds,
        )
        return err
}</span>

const getLogSegmentsForCompaction = `-- name: GetLogSegmentsForCompaction :many
SELECT
  segment_id,
  lower(ts_range)::bigint AS start_ts,
  upper(ts_range)::bigint AS end_ts,
  file_size,
  record_count,
  ingest_dateint
FROM log_seg
WHERE organization_id = $1
  AND dateint         = $2
  AND instance_num    = $3
  AND file_size &gt; 0
  AND record_count &gt; 0
ORDER BY lower(ts_range)
`

type GetLogSegmentsForCompactionParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        InstanceNum    int16     `json:"instance_num"`
}

type GetLogSegmentsForCompactionRow struct {
        SegmentID     int64 `json:"segment_id"`
        StartTs       int64 `json:"start_ts"`
        EndTs         int64 `json:"end_ts"`
        FileSize      int64 `json:"file_size"`
        RecordCount   int64 `json:"record_count"`
        IngestDateint int32 `json:"ingest_dateint"`
}

func (q *Queries) GetLogSegmentsForCompaction(ctx context.Context, arg GetLogSegmentsForCompactionParams) ([]GetLogSegmentsForCompactionRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, getLogSegmentsForCompaction, arg.OrganizationID, arg.Dateint, arg.InstanceNum)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []GetLogSegmentsForCompactionRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i GetLogSegmentsForCompactionRow
                if err := rows.Scan(
                        &amp;i.SegmentID,
                        &amp;i.StartTs,
                        &amp;i.EndTs,
                        &amp;i.FileSize,
                        &amp;i.RecordCount,
                        &amp;i.IngestDateint,
                ); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}

const insertLogSegmentDirect = `-- name: InsertLogSegmentDirect :exec
INSERT INTO log_seg (
  organization_id,
  dateint,
  ingest_dateint,
  segment_id,
  instance_num,
  ts_range,
  record_count,
  file_size,
  created_by,
  fingerprints
)
VALUES (
  $1,
  $2,
  $3,
  $4,
  $5,
  int8range($6, $7, '[)'),
  $8,
  $9,
  $10,
  $11::bigint[]
)
`

type InsertLogSegmentParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        IngestDateint  int32     `json:"ingest_dateint"`
        SegmentID      int64     `json:"segment_id"`
        InstanceNum    int16     `json:"instance_num"`
        StartTs        int64     `json:"start_ts"`
        EndTs          int64     `json:"end_ts"`
        RecordCount    int64     `json:"record_count"`
        FileSize       int64     `json:"file_size"`
        CreatedBy      CreatedBy `json:"created_by"`
        Fingerprints   []int64   `json:"fingerprints"`
}

func (q *Queries) InsertLogSegmentDirect(ctx context.Context, arg InsertLogSegmentParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, insertLogSegmentDirect,
                arg.OrganizationID,
                arg.Dateint,
                arg.IngestDateint,
                arg.SegmentID,
                arg.InstanceNum,
                arg.StartTs,
                arg.EndTs,
                arg.RecordCount,
                arg.FileSize,
                arg.CreatedBy,
                arg.Fingerprints,
        )
        return err
}</span>
</pre>
		
		<pre class="file" id="file91" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "context"
)

func (q *Store) InsertLogSegment(ctx context.Context, params InsertLogSegmentParams) error <span class="cov0" title="0">{
        if err := q.ensureLogFPPartition(ctx, "log_seg", params.OrganizationID, params.Dateint); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return q.InsertLogSegmentDirect(ctx, params)</span>
}
</pre>
		
		<pre class="file" id="file92" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "context"
        "fmt"

        "github.com/google/uuid"
        "github.com/hashicorp/go-multierror"
)

func (q *Store) InsertMetricSegment(ctx context.Context, params InsertMetricSegmentParams) error <span class="cov0" title="0">{
        if err := q.ensureMetricSegmentPartition(ctx, params.OrganizationID, params.Dateint); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">return q.InsertMetricSegmentDirect(ctx, params)</span>
}

type ReplaceMetricSegsOld struct {
        TidPartition int16
        SegmentID    int64
}

type ReplaceMetricSegsNew struct {
        TidPartition int16
        SegmentID    int64
        StartTs      int64
        EndTs        int64
        RecordCount  int64
        FileSize     int64
        TidCount     int32
}

type ReplaceMetricSegsParams struct {
        // OrganizationID is the ID of the organization to which the metric segments belong.
        OrganizationID uuid.UUID
        // Dateint is the date in YYYYMMDD format for which the metric segments are being replaced.
        Dateint int32
        // IngestDateint is the date in YYYYMMDD format when the segments were ingested.
        IngestDateint int32
        // InstanceNum is the collector instance number, gotta keep it separated.
        InstanceNum int16
        // FrequencyMs is the frequency in milliseconds at which the metrics are collected.
        FrequencyMs int32
        // Published indicates whether the new segments are marked as published.
        Published bool
        // Rolledup indicates whether the new segments are marked as rolledup.
        Rolledup bool
        // OldRecords contains the segments to be deleted.
        OldRecords []ReplaceMetricSegsOld
        // NewRecords contains the segments to be inserted.
        NewRecords []ReplaceMetricSegsNew
        CreatedBy  CreatedBy
}

// ReplaceMetricSegs replaces old metric segments with new ones for a given organization, date, and instance.
// The change is made atomically.
func (q *Store) ReplaceMetricSegs(ctx context.Context, args ReplaceMetricSegsParams) error <span class="cov0" title="0">{
        oldItems := make([]BatchDeleteMetricSegsParams, len(args.OldRecords))
        for i, oldRec := range args.OldRecords </span><span class="cov0" title="0">{
                oldItems[i] = BatchDeleteMetricSegsParams{
                        OrganizationID: args.OrganizationID,
                        Dateint:        args.Dateint,
                        FrequencyMs:    args.FrequencyMs,
                        SegmentID:      oldRec.SegmentID,
                        InstanceNum:    args.InstanceNum,
                        TidPartition:   oldRec.TidPartition,
                }
        }</span>

        <span class="cov0" title="0">newItems := make([]BatchInsertMetricSegsParams, len(args.NewRecords))
        for i, newRec := range args.NewRecords </span><span class="cov0" title="0">{
                newItems[i] = BatchInsertMetricSegsParams{
                        OrganizationID: args.OrganizationID,
                        Dateint:        args.Dateint,
                        IngestDateint:  args.IngestDateint,
                        FrequencyMs:    args.FrequencyMs,
                        SegmentID:      newRec.SegmentID,
                        InstanceNum:    args.InstanceNum,
                        TidPartition:   newRec.TidPartition,
                        StartTs:        newRec.StartTs,
                        EndTs:          newRec.EndTs,
                        RecordCount:    newRec.RecordCount,
                        FileSize:       newRec.FileSize,
                        TidCount:       newRec.TidCount,
                        Published:      args.Published,
                        Rolledup:       args.Rolledup,
                        CreatedBy:      args.CreatedBy,
                }
        }</span>

        <span class="cov0" title="0">var errs *multierror.Error
        return q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if len(oldItems) &gt; 0 </span><span class="cov0" title="0">{
                        result := s.BatchDeleteMetricSegs(ctx, oldItems)
                        result.Exec(func(i int, err error) </span><span class="cov0" title="0">{
                                if err != nil </span><span class="cov0" title="0">{
                                        err = fmt.Errorf("error deleting old metric segment %d, keys %v: %w", i, oldItems[i], err)
                                        errs = multierror.Append(errs, err)
                                }</span>
                        })
                }

                <span class="cov0" title="0">if errs.ErrorOrNil() == nil &amp;&amp; len(newItems) &gt; 0 </span><span class="cov0" title="0">{
                        result := s.BatchInsertMetricSegs(ctx, newItems)
                        result.Exec(func(i int, err error) </span><span class="cov0" title="0">{
                                if err != nil </span><span class="cov0" title="0">{
                                        err = fmt.Errorf("error inserting new metric segment %d, keys %v: %w", i, newItems[i], err)
                                        errs = multierror.Append(errs, err)
                                }</span>
                        })
                }

                <span class="cov0" title="0">return errs.ErrorOrNil()</span>
        })
}
</pre>
		
		<pre class="file" id="file93" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: metric_seg.sql

package lrdb

import (
        "context"

        "github.com/google/uuid"
)

const getMetricSegs = `-- name: GetMetricSegs :many
SELECT organization_id, dateint, frequency_ms, segment_id, instance_num, tid_partition, ts_range, record_count, file_size, tid_count, ingest_dateint, published, rolledup, created_at, created_by
FROM metric_seg
WHERE
  organization_id = $1 AND
  dateint = $2 AND
  frequency_ms = $3 AND
  instance_num = $4
  AND (
    ($5::BIGINT = 0 AND $6::BIGINT = 0)
    OR
    (ts_range &amp;&amp; int8range($5, $6, '[)'))
  )
ORDER BY
  ts_range
`

type GetMetricSegsParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        FrequencyMs    int32     `json:"frequency_ms"`
        InstanceNum    int16     `json:"instance_num"`
        StartTs        int64     `json:"start_ts"`
        EndTs          int64     `json:"end_ts"`
}

func (q *Queries) GetMetricSegs(ctx context.Context, arg GetMetricSegsParams) ([]MetricSeg, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, getMetricSegs,
                arg.OrganizationID,
                arg.Dateint,
                arg.FrequencyMs,
                arg.InstanceNum,
                arg.StartTs,
                arg.EndTs,
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []MetricSeg
        for rows.Next() </span><span class="cov0" title="0">{
                var i MetricSeg
                if err := rows.Scan(
                        &amp;i.OrganizationID,
                        &amp;i.Dateint,
                        &amp;i.FrequencyMs,
                        &amp;i.SegmentID,
                        &amp;i.InstanceNum,
                        &amp;i.TidPartition,
                        &amp;i.TsRange,
                        &amp;i.RecordCount,
                        &amp;i.FileSize,
                        &amp;i.TidCount,
                        &amp;i.IngestDateint,
                        &amp;i.Published,
                        &amp;i.Rolledup,
                        &amp;i.CreatedAt,
                        &amp;i.CreatedBy,
                ); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}

const insertMetricSegmentDirect = `-- name: InsertMetricSegmentDirect :exec
INSERT INTO metric_seg (
  organization_id,
  dateint,
  ingest_dateint,
  frequency_ms,
  segment_id,
  instance_num,
  tid_partition,
  ts_range,
  record_count,
  file_size,
  tid_count,
  created_by,
  published
)
VALUES (
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  $7,
  int8range($8, $9, '[)'),
  $10,
  $11,
  $12,
  $13,
  $14
)
`

type InsertMetricSegmentParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        Dateint        int32     `json:"dateint"`
        IngestDateint  int32     `json:"ingest_dateint"`
        FrequencyMs    int32     `json:"frequency_ms"`
        SegmentID      int64     `json:"segment_id"`
        InstanceNum    int16     `json:"instance_num"`
        TidPartition   int16     `json:"tid_partition"`
        StartTs        int64     `json:"start_ts"`
        EndTs          int64     `json:"end_ts"`
        RecordCount    int64     `json:"record_count"`
        FileSize       int64     `json:"file_size"`
        TidCount       int32     `json:"tid_count"`
        CreatedBy      CreatedBy `json:"created_by"`
        Published      bool      `json:"published"`
}

func (q *Queries) InsertMetricSegmentDirect(ctx context.Context, arg InsertMetricSegmentParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, insertMetricSegmentDirect,
                arg.OrganizationID,
                arg.Dateint,
                arg.IngestDateint,
                arg.FrequencyMs,
                arg.SegmentID,
                arg.InstanceNum,
                arg.TidPartition,
                arg.StartTs,
                arg.EndTs,
                arg.RecordCount,
                arg.FileSize,
                arg.TidCount,
                arg.CreatedBy,
                arg.Published,
        )
        return err
}</span>

const listSegmentsForQuery = `-- name: ListSegmentsForQuery :many
SELECT
    instance_num,
    segment_id,
    lower(ts_range)::bigint AS start_ts,
    (upper(ts_range) - 1)::bigint AS end_ts
FROM metric_seg
WHERE ts_range &amp;&amp; int8range($1, $2, '[)')
  AND dateint = $3
  AND frequency_ms = $4
  AND organization_id = $5
  AND published = true
`

type ListSegmentsForQueryParams struct {
        Int8range      int64     `json:"int8range"`
        Int8range_2    int64     `json:"int8range_2"`
        Dateint        int32     `json:"dateint"`
        FrequencyMs    int32     `json:"frequency_ms"`
        OrganizationID uuid.UUID `json:"organization_id"`
}

type ListSegmentsForQueryRow struct {
        InstanceNum int16 `json:"instance_num"`
        SegmentID   int64 `json:"segment_id"`
        StartTs     int64 `json:"start_ts"`
        EndTs       int64 `json:"end_ts"`
}

func (q *Queries) ListSegmentsForQuery(ctx context.Context, arg ListSegmentsForQueryParams) ([]ListSegmentsForQueryRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, listSegmentsForQuery,
                arg.Int8range,
                arg.Int8range_2,
                arg.Dateint,
                arg.FrequencyMs,
                arg.OrganizationID,
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []ListSegmentsForQueryRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i ListSegmentsForQueryRow
                if err := rows.Scan(
                        &amp;i.InstanceNum,
                        &amp;i.SegmentID,
                        &amp;i.StartTs,
                        &amp;i.EndTs,
                ); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}
</pre>
		
		<pre class="file" id="file94" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package migrations

import (
        "context"
        "errors"
        "fmt"
        "log/slog"

        "github.com/golang-migrate/migrate/v4"
        "github.com/golang-migrate/migrate/v4/database/pgx"
        "github.com/golang-migrate/migrate/v4/source/iofs"
        "github.com/jackc/pgx/v5/pgxpool"
        "github.com/jackc/pgx/v5/stdlib"
)

// RunMigrationsUp applies all up migrations using embedded migration files.
func RunMigrationsUp(ctx context.Context, pool *pgxpool.Pool) error <span class="cov0" title="0">{
        sourceDriver, err := iofs.New(migrationFiles, ".")
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create iofs driver: %w", err)
        }</span>

        <span class="cov0" title="0">sqlDB := stdlib.OpenDBFromPool(pool)
        defer func() </span><span class="cov0" title="0">{
                slog.Info("closing sqlDB")
                _ = sqlDB.Close()
                slog.Info("closed sqlDB")
        }</span>()

        <span class="cov0" title="0">dbDriver, err := pgx.WithInstance(sqlDB, &amp;pgx.Config{
                MigrationsTable: "gomigrate_lrdb",
        })
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create pgx driver: %w", err)
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                _ = dbDriver.Close()
        }</span>()

        <span class="cov0" title="0">m, err := migrate.NewWithInstance("iofs", sourceDriver, "postgres", dbDriver)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create migrate instance: %w", err)
        }</span>

        <span class="cov0" title="0">_, dirty, err := m.Version()
        if err != nil &amp;&amp; err != migrate.ErrNilVersion </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get current version: %w", err)
        }</span>
        <span class="cov0" title="0">if dirty </span><span class="cov0" title="0">{
                return errors.New("migration is dirty, please fix it before proceeding")
        }</span>

        <span class="cov0" title="0">if err := m.Up(); err != nil &amp;&amp; err != migrate.ErrNoChange </span><span class="cov0" title="0">{
                return fmt.Errorf("migration failed: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file95" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0

package lrdb

import (
        "database/sql/driver"
        "fmt"
        "time"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5/pgtype"
)

type ActionEnum string

const (
        ActionEnumCompact ActionEnum = "compact"
        ActionEnumRollup  ActionEnum = "rollup"
)

func (e *ActionEnum) Scan(src interface{}) error <span class="cov0" title="0">{
        switch s := src.(type) </span>{
        case []byte:<span class="cov0" title="0">
                *e = ActionEnum(s)</span>
        case string:<span class="cov0" title="0">
                *e = ActionEnum(s)</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported scan type for ActionEnum: %T", src)</span>
        }
        <span class="cov0" title="0">return nil</span>
}

type NullActionEnum struct {
        ActionEnum ActionEnum `json:"action_enum"`
        Valid      bool       `json:"valid"` // Valid is true if ActionEnum is not NULL
}

// Scan implements the Scanner interface.
func (ns *NullActionEnum) Scan(value interface{}) error <span class="cov0" title="0">{
        if value == nil </span><span class="cov0" title="0">{
                ns.ActionEnum, ns.Valid = "", false
                return nil
        }</span>
        <span class="cov0" title="0">ns.Valid = true
        return ns.ActionEnum.Scan(value)</span>
}

// Value implements the driver Valuer interface.
func (ns NullActionEnum) Value() (driver.Value, error) <span class="cov0" title="0">{
        if !ns.Valid </span><span class="cov0" title="0">{
                return nil, nil
        }</span>
        <span class="cov0" title="0">return string(ns.ActionEnum), nil</span>
}

type SignalEnum string

const (
        SignalEnumLogs    SignalEnum = "logs"
        SignalEnumMetrics SignalEnum = "metrics"
        SignalEnumTraces  SignalEnum = "traces"
)

func (e *SignalEnum) Scan(src interface{}) error <span class="cov0" title="0">{
        switch s := src.(type) </span>{
        case []byte:<span class="cov0" title="0">
                *e = SignalEnum(s)</span>
        case string:<span class="cov0" title="0">
                *e = SignalEnum(s)</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported scan type for SignalEnum: %T", src)</span>
        }
        <span class="cov0" title="0">return nil</span>
}

type NullSignalEnum struct {
        SignalEnum SignalEnum `json:"signal_enum"`
        Valid      bool       `json:"valid"` // Valid is true if SignalEnum is not NULL
}

// Scan implements the Scanner interface.
func (ns *NullSignalEnum) Scan(value interface{}) error <span class="cov0" title="0">{
        if value == nil </span><span class="cov0" title="0">{
                ns.SignalEnum, ns.Valid = "", false
                return nil
        }</span>
        <span class="cov0" title="0">ns.Valid = true
        return ns.SignalEnum.Scan(value)</span>
}

// Value implements the driver Valuer interface.
func (ns NullSignalEnum) Value() (driver.Value, error) <span class="cov0" title="0">{
        if !ns.Valid </span><span class="cov0" title="0">{
                return nil, nil
        }</span>
        <span class="cov0" title="0">return string(ns.SignalEnum), nil</span>
}

type Inqueue struct {
        ID             uuid.UUID  `json:"id"`
        QueueTs        time.Time  `json:"queue_ts"`
        Priority       int32      `json:"priority"`
        OrganizationID uuid.UUID  `json:"organization_id"`
        CollectorName  string     `json:"collector_name"`
        InstanceNum    int16      `json:"instance_num"`
        Bucket         string     `json:"bucket"`
        ObjectID       string     `json:"object_id"`
        TelemetryType  string     `json:"telemetry_type"`
        Tries          int32      `json:"tries"`
        ClaimedBy      int64      `json:"claimed_by"`
        ClaimedAt      *time.Time `json:"claimed_at"`
}

type InqueueJournal struct {
        ID             int64     `json:"id"`
        OrganizationID uuid.UUID `json:"organization_id"`
        Bucket         string    `json:"bucket"`
        ObjectID       string    `json:"object_id"`
        CreatedAt      time.Time `json:"created_at"`
        UpdatedAt      time.Time `json:"updated_at"`
}

type LogSeg struct {
        OrganizationID uuid.UUID                 `json:"organization_id"`
        Dateint        int32                     `json:"dateint"`
        SegmentID      int64                     `json:"segment_id"`
        InstanceNum    int16                     `json:"instance_num"`
        Fingerprints   []int64                   `json:"fingerprints"`
        RecordCount    int64                     `json:"record_count"`
        FileSize       int64                     `json:"file_size"`
        IngestDateint  int32                     `json:"ingest_dateint"`
        TsRange        pgtype.Range[pgtype.Int8] `json:"ts_range"`
        CreatedBy      CreatedBy                 `json:"created_by"`
}

type MetricSeg struct {
        OrganizationID uuid.UUID                 `json:"organization_id"`
        Dateint        int32                     `json:"dateint"`
        FrequencyMs    int32                     `json:"frequency_ms"`
        SegmentID      int64                     `json:"segment_id"`
        InstanceNum    int16                     `json:"instance_num"`
        TidPartition   int16                     `json:"tid_partition"`
        TsRange        pgtype.Range[pgtype.Int8] `json:"ts_range"`
        RecordCount    int64                     `json:"record_count"`
        FileSize       int64                     `json:"file_size"`
        TidCount       int32                     `json:"tid_count"`
        IngestDateint  int32                     `json:"ingest_dateint"`
        Published      bool                      `json:"published"`
        Rolledup       bool                      `json:"rolledup"`
        CreatedAt      time.Time                 `json:"created_at"`
        CreatedBy      CreatedBy                 `json:"created_by"`
}

type ObjCleanup struct {
        ID             uuid.UUID `json:"id"`
        DeleteAt       time.Time `json:"delete_at"`
        OrganizationID uuid.UUID `json:"organization_id"`
        InstanceNum    int16     `json:"instance_num"`
        BucketID       string    `json:"bucket_id"`
        ObjectID       string    `json:"object_id"`
        Tries          int32     `json:"tries"`
}

type Setting struct {
        Key   string `json:"key"`
        Value string `json:"value"`
}

type SignalLock struct {
        ID             int64                            `json:"id"`
        WorkID         *int64                           `json:"work_id"`
        OrganizationID uuid.UUID                        `json:"organization_id"`
        InstanceNum    int16                            `json:"instance_num"`
        Dateint        int32                            `json:"dateint"`
        FrequencyMs    int32                            `json:"frequency_ms"`
        Signal         SignalEnum                       `json:"signal"`
        TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
        ClaimedBy      int64                            `json:"claimed_by"`
        ClaimedAt      *time.Time                       `json:"claimed_at"`
        HeartbeatedAt  time.Time                        `json:"heartbeated_at"`
}

type WorkQueue struct {
        ID             int64                            `json:"id"`
        Priority       int32                            `json:"priority"`
        RunnableAt     time.Time                        `json:"runnable_at"`
        OrganizationID uuid.UUID                        `json:"organization_id"`
        InstanceNum    int16                            `json:"instance_num"`
        Dateint        int32                            `json:"dateint"`
        FrequencyMs    int32                            `json:"frequency_ms"`
        Signal         SignalEnum                       `json:"signal"`
        Action         ActionEnum                       `json:"action"`
        NeedsRun       bool                             `json:"needs_run"`
        Tries          int32                            `json:"tries"`
        TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
        ClaimedBy      int64                            `json:"claimed_by"`
        ClaimedAt      *time.Time                       `json:"claimed_at"`
        HeartbeatedAt  time.Time                        `json:"heartbeated_at"`
}
</pre>
		
		<pre class="file" id="file96" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: obj_cleanup.sql

package lrdb

import (
        "context"

        "github.com/google/uuid"
)

const objectCleanupAdd = `-- name: ObjectCleanupAdd :exec
INSERT INTO obj_cleanup (
  organization_id,
  instance_num,
  bucket_id,
  object_id
) VALUES (
  $1,
  $2,
  $3,
  $4
) ON CONFLICT (organization_id, instance_num, bucket_id, object_id) DO NOTHING
`

type ObjectCleanupAddParams struct {
        OrganizationID uuid.UUID `json:"organization_id"`
        InstanceNum    int16     `json:"instance_num"`
        BucketID       string    `json:"bucket_id"`
        ObjectID       string    `json:"object_id"`
}

func (q *Queries) ObjectCleanupAdd(ctx context.Context, arg ObjectCleanupAddParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, objectCleanupAdd,
                arg.OrganizationID,
                arg.InstanceNum,
                arg.BucketID,
                arg.ObjectID,
        )
        return err
}</span>

const objectCleanupComplete = `-- name: ObjectCleanupComplete :exec
DELETE FROM obj_cleanup WHERE id = $1
`

func (q *Queries) ObjectCleanupComplete(ctx context.Context, id uuid.UUID) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, objectCleanupComplete, id)
        return err
}</span>

const objectCleanupFail = `-- name: ObjectCleanupFail :exec
UPDATE obj_cleanup
SET tries = tries + 1,
    delete_at = NOW() + INTERVAL '1 minute'
WHERE id = $1
`

func (q *Queries) ObjectCleanupFail(ctx context.Context, id uuid.UUID) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, objectCleanupFail, id)
        return err
}</span>

const objectCleanupGet = `-- name: ObjectCleanupGet :many
SELECT
  id,
  organization_id,
  instance_num,
  bucket_id,
  object_id
FROM obj_cleanup
WHERE delete_at &lt; NOW()
  AND tries &lt; 10
ORDER BY delete_at ASC
LIMIT $1
`

type ObjectCleanupGetRow struct {
        ID             uuid.UUID `json:"id"`
        OrganizationID uuid.UUID `json:"organization_id"`
        InstanceNum    int16     `json:"instance_num"`
        BucketID       string    `json:"bucket_id"`
        ObjectID       string    `json:"object_id"`
}

func (q *Queries) ObjectCleanupGet(ctx context.Context, maxrows int32) ([]ObjectCleanupGetRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, objectCleanupGet, maxrows)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []ObjectCleanupGetRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i ObjectCleanupGetRow
                if err := rows.Scan(
                        &amp;i.ID,
                        &amp;i.OrganizationID,
                        &amp;i.InstanceNum,
                        &amp;i.BucketID,
                        &amp;i.ObjectID,
                ); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}
</pre>
		
		<pre class="file" id="file97" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: parquet_estimator.sql

package lrdb

import (
        "context"

        "github.com/google/uuid"
)

const logSegEstimator = `-- name: LogSegEstimator :many
WITH params AS (
  SELECT 1_000_000::float8 AS target_bytes
),
bpr AS (
  SELECT
    organization_id,
    instance_num,
    (sum(file_size)::float8 / NULLIF(sum(record_count), 0))::float8 AS avg_bpr
  FROM log_seg
  WHERE
      record_count &gt; 100
      AND dateint IN ($1, $2)
      AND ts_range &amp;&amp; int8range($3, $4, '[)')
  GROUP BY organization_id, instance_num
)
SELECT
  b.organization_id,
  b.instance_num,
  CEIL(p.target_bytes / NULLIF(b.avg_bpr, 0))::bigint AS estimated_records
FROM bpr b
CROSS JOIN params p
`

type LogSegEstimatorParams struct {
        DateintLow  int32 `json:"dateint_low"`
        DateintHigh int32 `json:"dateint_high"`
        MsLow       int64 `json:"ms_low"`
        MsHigh      int64 `json:"ms_high"`
}

type LogSegEstimatorRow struct {
        OrganizationID   uuid.UUID `json:"organization_id"`
        InstanceNum      int16     `json:"instance_num"`
        EstimatedRecords int64     `json:"estimated_records"`
}

// Returns an estimate of the number of log segments, average bytes, average records,
// and average bytes per record for log segments in the last hour per organization and instance.
// This query is basically identical to the MetricSegEstimator, but for log segments.
func (q *Queries) LogSegEstimator(ctx context.Context, arg LogSegEstimatorParams) ([]LogSegEstimatorRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, logSegEstimator,
                arg.DateintLow,
                arg.DateintHigh,
                arg.MsLow,
                arg.MsHigh,
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []LogSegEstimatorRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i LogSegEstimatorRow
                if err := rows.Scan(&amp;i.OrganizationID, &amp;i.InstanceNum, &amp;i.EstimatedRecords); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}

const metricSegEstimator = `-- name: MetricSegEstimator :many
WITH params AS (
  SELECT 1_000_000::float8 AS target_bytes
),
bpr AS (
  SELECT
    organization_id,
    instance_num,
    (sum(file_size)::float8 / NULLIF(sum(record_count), 0))::float8 AS avg_bpr
  FROM metric_seg
  WHERE
      record_count &gt; 100
      AND dateint IN ($1, $2)
      AND ts_range &amp;&amp; int8range($3, $4, '[)')
  GROUP BY organization_id, instance_num
)
SELECT
  b.organization_id,
  b.instance_num,
  CEIL(p.target_bytes / NULLIF(b.avg_bpr, 0))::bigint AS estimated_records
FROM bpr b
CROSS JOIN params p
`

type MetricSegEstimatorParams struct {
        DateintLow  int32 `json:"dateint_low"`
        DateintHigh int32 `json:"dateint_high"`
        MsLow       int64 `json:"ms_low"`
        MsHigh      int64 `json:"ms_high"`
}

type MetricSegEstimatorRow struct {
        OrganizationID   uuid.UUID `json:"organization_id"`
        InstanceNum      int16     `json:"instance_num"`
        EstimatedRecords int64     `json:"estimated_records"`
}

// Returns an estimate of the number of metric segments, average bytes, average records,
// and average bytes per record for metric segments in the last hour per organization and instance.
// This query is basically identical to the LogSegEstimator, but for metric segments.
func (q *Queries) MetricSegEstimator(ctx context.Context, arg MetricSegEstimatorParams) ([]MetricSegEstimatorRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, metricSegEstimator,
                arg.DateintLow,
                arg.DateintHigh,
                arg.MsLow,
                arg.MsHigh,
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []MetricSegEstimatorRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i MetricSegEstimatorRow
                if err := rows.Scan(&amp;i.OrganizationID, &amp;i.InstanceNum, &amp;i.EstimatedRecords); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}
</pre>
		
		<pre class="file" id="file98" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "time"

        "github.com/jellydator/ttlcache/v3"
)

const (
        defaultTTLDuration = 30 * time.Minute
)

type flushFunction func()

var flushFunctions []flushFunction

func AddFlushFunction(f flushFunction) <span class="cov0" title="0">{
        flushFunctions = append(flushFunctions, f)
}</span>

func FlushCaches() <span class="cov0" title="0">{
        for _, f := range flushFunctions </span><span class="cov0" title="0">{
                f()
        }</span>
}

var (
        partitionTableCache = ttlcache.New(
                ttlcache.WithTTL[string, struct{}](defaultTTLDuration),
                ttlcache.WithDisableTouchOnHit[string, struct{}](),
                ttlcache.WithCapacity[string, struct{}](1_000_000),
        )
)

func init() <span class="cov0" title="0">{
        go partitionTableCache.Start()
        AddFlushFunction(partitionTableCache.DeleteAll)
}</span>

func RememberPartitionTable(tableName string) <span class="cov0" title="0">{
        partitionTableCache.Set(tableName, struct{}{}, ttlcache.DefaultTTL)
}</span>

func IsPartitionTableRemembered(tableName string) bool <span class="cov0" title="0">{
        return partitionTableCache.Get(tableName) != nil
}</span>
</pre>
		
		<pre class="file" id="file99" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "context"
        "fmt"

        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/dbase"
)

func (q *Queries) ensureLogFPPartition(ctx context.Context, parent string, org_id uuid.UUID, dateint int32) error <span class="cov0" title="0">{
        partitionTableName := parent + "_" + dbase.UUIDToBase36(org_id)
        key := fmt.Sprintf("%s_%d", partitionTableName, dateint)
        if IsPartitionTableRemembered(key) </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">sql := fmt.Sprintf(`SELECT create_logfpseg_partition('%s', '%s', '%s', %d, %d)`,
                parent, partitionTableName, org_id.String(), dateint, dateint+1)
        _, err := q.db.Exec(ctx, sql)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create partition %s for table %s: %w", partitionTableName, parent, err)
        }</span>
        <span class="cov0" title="0">RememberPartitionTable(key)
        return nil</span>
}

func (q *Queries) ensureMetricSegmentPartition(ctx context.Context, org_id uuid.UUID, dateint int32) error <span class="cov0" title="0">{
        partitionTableName := "mseg_" + dbase.UUIDToBase36(org_id)
        key := fmt.Sprintf("%s_%d", partitionTableName, dateint)
        if IsPartitionTableRemembered(key) </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">sql := fmt.Sprintf(`SELECT create_metricseg_partition('metric_seg', '%s', '%s', %d, %d)`,
                partitionTableName, org_id.String(), dateint, dateint+1)
        _, err := q.db.Exec(ctx, sql)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create partition %s for table metric_seg: %w", partitionTableName, err)
        }</span>
        <span class="cov0" title="0">RememberPartitionTable(key)
        return nil</span>
}
</pre>
		
		<pre class="file" id="file100" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "context"
        "time"

        "github.com/jackc/pgx/v5/pgxpool"
        "github.com/pgx-contrib/pgxotel"
)

// NewMetadataConnectionPool creates a new connection pool
// using the PostgreSQL connection string provided, and
// using pgx v5.
func NewConnectionPool(ctx context.Context, url string) (*pgxpool.Pool, error) <span class="cov0" title="0">{
        cfg, err := pgxpool.ParseConfig(url)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">cfg.ConnConfig.Tracer = &amp;pgxotel.QueryTracer{
                Name: "lrdb",
        }

        // Pool sizing
        cfg.MaxConns = 15
        cfg.MinConns = 1
        cfg.MinIdleConns = 1

        // Lifetimes &amp; health
        cfg.MaxConnIdleTime = 2 * time.Minute
        cfg.MaxConnLifetime = 30 * time.Minute
        cfg.MaxConnLifetimeJitter = 5 * time.Minute
        cfg.HealthCheckPeriod = 30 * time.Second

        return pgxpool.NewWithConfig(ctx, cfg)</span>
}
</pre>
		
		<pre class="file" id="file101" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: signal_locks.sql

package lrdb

import (
        "context"
)

const signalLockCleanup = `-- name: SignalLockCleanup :one
SELECT public.signal_lock_cleanup() as count
`

func (q *Queries) SignalLockCleanup(ctx context.Context) (int32, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, signalLockCleanup)
        var count int32
        err := row.Scan(&amp;count)
        return count, err
}</span>
</pre>
		
		<pre class="file" id="file102" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "context"
        "fmt"

        "github.com/jackc/pgx/v5/pgxpool"
)

// Store provides all functions to execute db queries and transactions
type Store struct {
        *Queries
        connPool *pgxpool.Pool
}

// NewStore creates a new Store
func NewStore(connPool *pgxpool.Pool) *Store <span class="cov0" title="0">{
        return &amp;Store{
                connPool: connPool,
                Queries:  New(connPool),
        }
}</span>

func (store *Store) Pool() *pgxpool.Pool <span class="cov0" title="0">{
        return store.connPool
}</span>

func (store *Store) execTx(ctx context.Context, fn func(*Store) error) (err error) <span class="cov0" title="0">{
        closed := false
        tx, err := store.connPool.Begin(ctx)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer func() </span><span class="cov0" title="0">{
                if !closed </span><span class="cov0" title="0">{
                        if rbErr := tx.Rollback(ctx); rbErr != nil </span><span class="cov0" title="0">{
                                err = fmt.Errorf("tx err: %v, rb err: %v", err, rbErr)
                        }</span>
                }
        }()

        <span class="cov0" title="0">txStore := &amp;Store{
                connPool: store.connPool,
                Queries:  New(tx),
        }

        if err = fn(txStore); err != nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">err = tx.Commit(ctx)
        if err == nil </span><span class="cov0" title="0">{
                closed = true
        }</span>
        <span class="cov0" title="0">return</span>
}
</pre>
		
		<pre class="file" id="file103" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package lrdb

import (
        "context"
)

func (q *Store) WorkQueueAdd(ctx context.Context, params WorkQueueAddParams) error <span class="cov0" title="0">{
        return q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if err := s.WorkQueueGlobalLock(ctx); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">return s.WorkQueueAddDirect(ctx, params)</span>
        })
}

func (q *Store) WorkQueueFail(ctx context.Context, params WorkQueueFailParams) error <span class="cov0" title="0">{
        return q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if err := s.WorkQueueGlobalLock(ctx); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">return s.WorkQueueFailDirect(ctx, params)</span>
        })
}

func (q *Store) WorkQueueComplete(ctx context.Context, params WorkQueueCompleteParams) error <span class="cov0" title="0">{
        return q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if err := s.WorkQueueGlobalLock(ctx); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">return s.WorkQueueCompleteDirect(ctx, params)</span>
        })
}

func (q *Store) WorkQueueHeartbeat(ctx context.Context, params WorkQueueHeartbeatParams) error <span class="cov0" title="0">{
        return q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if err := s.WorkQueueGlobalLock(ctx); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">return s.WorkQueueHeartbeatDirect(ctx, params)</span>
        })
}

func (q *Store) WorkQueueCleanup(ctx context.Context) ([]WorkQueueCleanupRow, error) <span class="cov0" title="0">{
        var result []WorkQueueCleanupRow
        err := q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if err := s.WorkQueueGlobalLock(ctx); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">var err error
                result, err = s.WorkQueueCleanupDirect(ctx)
                return err</span>
        })
        <span class="cov0" title="0">return result, err</span>
}

func (q *Store) WorkQueueClaim(ctx context.Context, params WorkQueueClaimParams) (WorkQueueClaimRow, error) <span class="cov0" title="0">{
        var result WorkQueueClaimRow
        err := q.execTx(ctx, func(s *Store) error </span><span class="cov0" title="0">{
                if err := s.WorkQueueGlobalLock(ctx); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">var err error
                result, err = s.WorkQueueClaimDirect(ctx, params)
                return err</span>
        })
        <span class="cov0" title="0">return result, err</span>
}
</pre>
		
		<pre class="file" id="file104" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: work_queue.sql

package lrdb

import (
        "context"
        "time"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5/pgtype"
)

const workQueueAddDirect = `-- name: WorkQueueAddDirect :exec
SELECT public.work_queue_add(
  $1      :: UUID,
  $2    :: SMALLINT,
  $3     :: INTEGER,
  $4   :: INTEGER,
  $5      :: signal_enum,
  $6      :: action_enum,
  $7    :: TSTZRANGE,
  $8 :: TIMESTAMPTZ,
  $9    :: INTEGER
)
`

type WorkQueueAddParams struct {
        OrgID      uuid.UUID                        `json:"org_id"`
        Instance   int16                            `json:"instance"`
        Dateint    int32                            `json:"dateint"`
        Frequency  int32                            `json:"frequency"`
        Signal     SignalEnum                       `json:"signal"`
        Action     ActionEnum                       `json:"action"`
        TsRange    pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
        RunnableAt time.Time                        `json:"runnable_at"`
        Priority   int32                            `json:"priority"`
}

func (q *Queries) WorkQueueAddDirect(ctx context.Context, arg WorkQueueAddParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, workQueueAddDirect,
                arg.OrgID,
                arg.Instance,
                arg.Dateint,
                arg.Frequency,
                arg.Signal,
                arg.Action,
                arg.TsRange,
                arg.RunnableAt,
                arg.Priority,
        )
        return err
}</span>

const workQueueCleanupDirect = `-- name: WorkQueueCleanupDirect :many
WITH params AS (
  SELECT
    NOW() AS v_now,
    (SELECT value::interval
       FROM public.settings
      WHERE key = 'lock_ttl_dead') AS dead_ttl
),
expired AS (
  UPDATE public.work_queue w
  SET
    claimed_by     = -1,
    claimed_at     = NULL,
    heartbeated_at = params.v_now,
    needs_run      = TRUE
  FROM params
  WHERE
    w.claimed_by &lt;&gt; -1
    AND w.heartbeated_at &lt; params.v_now - params.dead_ttl
  RETURNING w.id, w.priority, w.runnable_at, w.organization_id, w.instance_num, w.dateint, w.frequency_ms, w.signal, w.action, w.needs_run, w.tries, w.ts_range, w.claimed_by, w.claimed_at, w.heartbeated_at
),
deleted_locks AS (
  DELETE FROM public.signal_locks sl
  USING expired e
  WHERE sl.work_id = e.id
  RETURNING sl.id
)
SELECT
  e.id, e.priority, e.runnable_at, e.organization_id, e.instance_num, e.dateint, e.frequency_ms, e.signal, e.action, e.needs_run, e.tries, e.ts_range, e.claimed_by, e.claimed_at, e.heartbeated_at,
  (SELECT COUNT(*) FROM deleted_locks) AS locks_removed
FROM expired e
`

type WorkQueueCleanupRow struct {
        ID             int64                            `json:"id"`
        Priority       int32                            `json:"priority"`
        RunnableAt     time.Time                        `json:"runnable_at"`
        OrganizationID uuid.UUID                        `json:"organization_id"`
        InstanceNum    int16                            `json:"instance_num"`
        Dateint        int32                            `json:"dateint"`
        FrequencyMs    int32                            `json:"frequency_ms"`
        Signal         SignalEnum                       `json:"signal"`
        Action         ActionEnum                       `json:"action"`
        NeedsRun       bool                             `json:"needs_run"`
        Tries          int32                            `json:"tries"`
        TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
        ClaimedBy      int64                            `json:"claimed_by"`
        ClaimedAt      *time.Time                       `json:"claimed_at"`
        HeartbeatedAt  time.Time                        `json:"heartbeated_at"`
        LocksRemoved   int64                            `json:"locks_removed"`
}

func (q *Queries) WorkQueueCleanupDirect(ctx context.Context) ([]WorkQueueCleanupRow, error) <span class="cov0" title="0">{
        rows, err := q.db.Query(ctx, workQueueCleanupDirect)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">defer rows.Close()
        var items []WorkQueueCleanupRow
        for rows.Next() </span><span class="cov0" title="0">{
                var i WorkQueueCleanupRow
                if err := rows.Scan(
                        &amp;i.ID,
                        &amp;i.Priority,
                        &amp;i.RunnableAt,
                        &amp;i.OrganizationID,
                        &amp;i.InstanceNum,
                        &amp;i.Dateint,
                        &amp;i.FrequencyMs,
                        &amp;i.Signal,
                        &amp;i.Action,
                        &amp;i.NeedsRun,
                        &amp;i.Tries,
                        &amp;i.TsRange,
                        &amp;i.ClaimedBy,
                        &amp;i.ClaimedAt,
                        &amp;i.HeartbeatedAt,
                        &amp;i.LocksRemoved,
                ); err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
                <span class="cov0" title="0">items = append(items, i)</span>
        }
        <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return items, nil</span>
}

const workQueueCompleteDirect = `-- name: WorkQueueCompleteDirect :exec
WITH updated AS (
  UPDATE public.work_queue w
  SET
    claimed_by     = -1,
    claimed_at     = NULL,
    heartbeated_at = NOW(),
    needs_run      = FALSE,
    runnable_at    = NOW(),
    tries          = 0
  WHERE w.id         = $2::BIGINT
    AND w.claimed_by = $1
  RETURNING id
)
DELETE FROM public.signal_locks sl
USING updated u
WHERE sl.work_id    = u.id
  AND sl.claimed_by = $1
`

type WorkQueueCompleteParams struct {
        WorkerID int64 `json:"worker_id"`
        ID       int64 `json:"id"`
}

func (q *Queries) WorkQueueCompleteDirect(ctx context.Context, arg WorkQueueCompleteParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, workQueueCompleteDirect, arg.WorkerID, arg.ID)
        return err
}</span>

const workQueueFailDirect = `-- name: WorkQueueFailDirect :exec
WITH params AS (
  SELECT
    NOW()                                         AS v_now,
    (SELECT value::interval
       FROM public.settings
      WHERE key = 'work_fail_requeue_ttl')        AS requeue_ttl,
    (SELECT value::int
       FROM public.settings
      WHERE key = 'max_retries')                  AS max_retries
),
old AS (
  SELECT w.tries
  FROM public.work_queue w
  WHERE w.id         = $1::BIGINT
    AND w.claimed_by = $2
),
updated AS (
  UPDATE public.work_queue w
  SET
    claimed_by     = -1,
    claimed_at     = NULL,
    heartbeated_at = (SELECT v_now FROM params),
    tries =
      CASE
        WHEN o.tries IS NULL THEN 1
        ELSE o.tries + 1
      END,
    runnable_at =
      CASE
        WHEN o.tries + 1 &lt;= (SELECT max_retries FROM params)
          THEN (SELECT v_now FROM params) + (SELECT requeue_ttl FROM params)
        ELSE w.runnable_at
      END,
    needs_run =
      CASE
        WHEN o.tries + 1 &lt;= (SELECT max_retries FROM params) THEN TRUE
        ELSE FALSE
      END
  FROM old o
  WHERE w.id         = $1::BIGINT
    AND w.claimed_by = $2
)
DELETE FROM public.signal_locks sl
WHERE sl.work_id    = $1::BIGINT
  AND sl.claimed_by = $2
`

type WorkQueueFailParams struct {
        ID       int64 `json:"id"`
        WorkerID int64 `json:"worker_id"`
}

func (q *Queries) WorkQueueFailDirect(ctx context.Context, arg WorkQueueFailParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, workQueueFailDirect, arg.ID, arg.WorkerID)
        return err
}</span>

const workQueueGC = `-- name: WorkQueueGC :one
WITH doomed AS (
  SELECT w.id
  FROM public.work_queue AS w
  WHERE w.claimed_by = -1
    AND NOT w.needs_run
    AND w.runnable_at &lt; $1
  ORDER BY w.runnable_at
  LIMIT $2
  FOR UPDATE SKIP LOCKED
),
del_wq AS (
  DELETE FROM public.work_queue AS w
  USING doomed AS d
  WHERE w.id = d.id
  RETURNING 1
)
SELECT COALESCE(COUNT(*), 0)::int AS deleted
FROM del_wq
`

type WorkQueueGCParams struct {
        Cutoff  time.Time `json:"cutoff"`
        Maxrows int32     `json:"maxrows"`
}

func (q *Queries) WorkQueueGC(ctx context.Context, arg WorkQueueGCParams) (int32, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, workQueueGC, arg.Cutoff, arg.Maxrows)
        var deleted int32
        err := row.Scan(&amp;deleted)
        return deleted, err
}</span>

const workQueueGlobalLock = `-- name: WorkQueueGlobalLock :exec
SELECT pg_advisory_xact_lock(hashtext('work_queue_global')::bigint)
`

func (q *Queries) WorkQueueGlobalLock(ctx context.Context) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, workQueueGlobalLock)
        return err
}</span>

const workQueueHeartbeatDirect = `-- name: WorkQueueHeartbeatDirect :exec
WITH params AS (
  SELECT
    NOW() AS v_now,
    (SELECT value::interval
       FROM public.settings
      WHERE key = 'lock_ttl') AS lock_ttl
)
UPDATE public.work_queue w
SET heartbeated_at = p.v_now
FROM params p
WHERE w.id            = ANY($1::BIGINT[])
  AND w.claimed_by    = $2
  AND w.heartbeated_at &gt;= p.v_now - p.lock_ttl
`

type WorkQueueHeartbeatParams struct {
        Ids      []int64 `json:"ids"`
        WorkerID int64   `json:"worker_id"`
}

// 1) heart-beat the work_queue
func (q *Queries) WorkQueueHeartbeatDirect(ctx context.Context, arg WorkQueueHeartbeatParams) error <span class="cov0" title="0">{
        _, err := q.db.Exec(ctx, workQueueHeartbeatDirect, arg.Ids, arg.WorkerID)
        return err
}</span>
</pre>
		
		<pre class="file" id="file105" style="display: none">// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: work_queue_claim.sql

package lrdb

import (
        "context"
        "time"

        "github.com/google/uuid"
        "github.com/jackc/pgx/v5/pgtype"
)

const workQueueClaimDirect = `-- name: WorkQueueClaimDirect :one
WITH params AS (
    SELECT
      NOW() AS v_now,
      (SELECT value::interval FROM public.settings WHERE key = 'lock_ttl') AS v_lock_ttl
  ),

  target_freqs AS (
    SELECT unnest($1::INTEGER[]) AS freq
  ),

  rollup_sources(parent_freq_ms, child_freq_ms) AS (
    VALUES
      (60000,    10000),
      (300000,   60000),
      (1200000,  300000),
      (3600000, 1200000)
  ),

  sl_small AS MATERIALIZED (
    SELECT id, work_id, organization_id, instance_num, dateint, frequency_ms, signal, ts_range, claimed_by, claimed_at, heartbeated_at
    FROM public.signal_locks sl
    WHERE
      sl.signal       = $2
      AND sl.frequency_ms = ANY (
        -- the “own” frequencies
        ARRAY(SELECT freq FROM target_freqs)
        -- plus, if rollup, the child freqs
        || COALESCE(
             (SELECT array_agg(child_freq_ms)
              FROM rollup_sources
              WHERE parent_freq_ms = ANY(SELECT freq FROM target_freqs)
                AND $3::action_enum = 'rollup'),
             '{}'
           )
      )
  ),

candidate AS (
  SELECT w.id, w.priority, w.runnable_at, w.organization_id, w.instance_num, w.dateint, w.frequency_ms, w.signal, w.action, w.needs_run, w.tries, w.ts_range, w.claimed_by, w.claimed_at, w.heartbeated_at
  FROM public.work_queue w
  LEFT JOIN sl_small sl
    ON sl.organization_id = w.organization_id
   AND sl.instance_num    = w.instance_num
   AND sl.signal          = w.signal
   AND sl.ts_range &amp;&amp; w.ts_range
   AND sl.work_id &lt;&gt; w.id
  WHERE
    w.frequency_ms = ANY (SELECT freq FROM target_freqs)
    AND w.priority &gt;= $4
    AND w.signal     = $2
    AND w.action     = $3
    AND w.runnable_at &lt;= (SELECT v_now FROM params)
    AND sl.id IS NULL
    AND w.needs_run
  ORDER BY w.needs_run DESC, w.priority DESC, w.runnable_at, w.id
  LIMIT 1
  FOR UPDATE SKIP LOCKED
),

  lock_map AS (
    -- always insert a lock at the candidate’s own frequency
    SELECT c.frequency_ms AS lock_freq_ms
    FROM candidate c

    UNION ALL

    -- if this is a rollup action, also insert a lock at the child-frequency
    SELECT rs.child_freq_ms AS lock_freq_ms
    FROM candidate c
    JOIN rollup_sources rs
      ON c.frequency_ms = rs.parent_freq_ms
    WHERE $3 = 'rollup'
  ),

  cleanup_locks AS (
    DELETE FROM public.signal_locks sl
    USING candidate c
    WHERE sl.work_id = c.id
  ),

  new_locks AS (
    INSERT INTO public.signal_locks (
      organization_id, instance_num, dateint,
      frequency_ms,    signal,       claimed_by,
      claimed_at,      ts_range,     work_id
    )
    SELECT
      c.organization_id,
      c.instance_num,
      c.dateint,
      lm.lock_freq_ms,
      c.signal,
      $5,
      (SELECT v_now FROM params),
      c.ts_range,
      c.id
    FROM candidate c
    CROSS JOIN lock_map lm
    ORDER BY lm.lock_freq_ms
  ),

  updated AS (
    UPDATE public.work_queue w
    SET
      claimed_by     = $5,
      claimed_at     = (SELECT v_now FROM params),
      heartbeated_at = (SELECT v_now FROM params),
      needs_run      = FALSE,
      tries          = w.tries + 1
    FROM candidate c
    WHERE w.id = c.id
    RETURNING w.id, w.priority, w.runnable_at, w.organization_id, w.instance_num, w.dateint, w.frequency_ms, w.signal, w.action, w.needs_run, w.tries, w.ts_range, w.claimed_by, w.claimed_at, w.heartbeated_at
  )

SELECT id, priority, runnable_at, organization_id, instance_num, dateint, frequency_ms, signal, action, needs_run, tries, ts_range, claimed_by, claimed_at, heartbeated_at FROM updated
`

type WorkQueueClaimParams struct {
        TargetFreqs []int32    `json:"target_freqs"`
        Signal      SignalEnum `json:"signal"`
        Action      ActionEnum `json:"action"`
        MinPriority int32      `json:"min_priority"`
        WorkerID    int64      `json:"worker_id"`
}

type WorkQueueClaimRow struct {
        ID             int64                            `json:"id"`
        Priority       int32                            `json:"priority"`
        RunnableAt     time.Time                        `json:"runnable_at"`
        OrganizationID uuid.UUID                        `json:"organization_id"`
        InstanceNum    int16                            `json:"instance_num"`
        Dateint        int32                            `json:"dateint"`
        FrequencyMs    int32                            `json:"frequency_ms"`
        Signal         SignalEnum                       `json:"signal"`
        Action         ActionEnum                       `json:"action"`
        NeedsRun       bool                             `json:"needs_run"`
        Tries          int32                            `json:"tries"`
        TsRange        pgtype.Range[pgtype.Timestamptz] `json:"ts_range"`
        ClaimedBy      int64                            `json:"claimed_by"`
        ClaimedAt      *time.Time                       `json:"claimed_at"`
        HeartbeatedAt  time.Time                        `json:"heartbeated_at"`
}

func (q *Queries) WorkQueueClaimDirect(ctx context.Context, arg WorkQueueClaimParams) (WorkQueueClaimRow, error) <span class="cov0" title="0">{
        row := q.db.QueryRow(ctx, workQueueClaimDirect,
                arg.TargetFreqs,
                arg.Signal,
                arg.Action,
                arg.MinPriority,
                arg.WorkerID,
        )
        var i WorkQueueClaimRow
        err := row.Scan(
                &amp;i.ID,
                &amp;i.Priority,
                &amp;i.RunnableAt,
                &amp;i.OrganizationID,
                &amp;i.InstanceNum,
                &amp;i.Dateint,
                &amp;i.FrequencyMs,
                &amp;i.Signal,
                &amp;i.Action,
                &amp;i.NeedsRun,
                &amp;i.Tries,
                &amp;i.TsRange,
                &amp;i.ClaimedBy,
                &amp;i.ClaimedAt,
                &amp;i.HeartbeatedAt,
        )
        return i, err
}</span>
</pre>
		
		<pre class="file" id="file106" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package main

import (
        "fmt"
        "log/slog"
        "os"
        "path/filepath"
        "runtime/debug"
        "time"

        "github.com/KimMachineGun/automemlimit/memlimit"
        gomaxecs "github.com/rdforte/gomaxecs/maxprocs"
        "go.uber.org/automaxprocs/maxprocs"

        "github.com/cardinalhq/lakerunner/cmd"
)

func simpleLogger(msg string, args ...any) <span class="cov0" title="0">{
        fmt.Fprintf(os.Stderr, msg+"\n", args...)
}</span>

func init() <span class="cov0" title="0">{
        time.Local = time.UTC // Ensure all time operations are in UTC

        if gomaxecs.IsECS() </span><span class="cov0" title="0">{
                _, err := gomaxecs.Set(gomaxecs.WithLogger(simpleLogger))
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "failed to set maxprocs package github.com/rdforte/gomaxecs/maxprocs: %v\n", err)
                }</span>
        } else<span class="cov0" title="0"> {
                _, err := maxprocs.Set(maxprocs.Logger(simpleLogger))
                if err != nil </span><span class="cov0" title="0">{
                        fmt.Fprintf(os.Stderr, "failed to set maxprocs using package go.uber.org/automaxprocs/maxprocs: %v\n", err)
                }</span>
        }
        <span class="cov0" title="0">_, err := memlimit.SetGoMemLimitWithOpts(
                memlimit.WithRatio(0.8),
                memlimit.WithLogger(slog.Default()),
                memlimit.WithProvider(
                        memlimit.ApplyFallback(
                                memlimit.FromCgroup,
                                memlimit.FromSystem,
                        ),
                ),
        )
        if err != nil </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "failed to set memory limit using package github.com/KimMachineGun/automemlimit/memlimit: %v\n", err)
        }</span>

        <span class="cov0" title="0">if os.Getenv("GOGC") == "" </span><span class="cov0" title="0">{
                fmt.Fprintf(os.Stderr, "GOGC is not set, setting it to 50%%\n")
                debug.SetGCPercent(50)
                os.Setenv("GOGC", "50")
        }</span>
}

func main() <span class="cov0" title="0">{
        tmp := os.TempDir()
        tmp = filepath.Join(tmp, "lakerunner")
        if err := os.MkdirAll(tmp, 0755); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to create temp dir path (ignoring)", slog.String("path", tmp), slog.Any("error", err))
        }</span> else<span class="cov0" title="0"> {
                slog.Info("Created temp dir path", slog.String("path", tmp))
        }</span>
        <span class="cov0" title="0">if err := os.Setenv("TMPDIR", tmp); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to set TMPDIR environment variable", slog.String("path", tmp), slog.Any("error", err))
        }</span> else<span class="cov0" title="0"> {
                slog.Info("Set TMPDIR environment variable", slog.String("path", tmp))
        }</span>

        <span class="cov0" title="0">slog.Info("Using temp dir", "path", os.TempDir())

        cmd.Execute()</span>
}
</pre>
		
		<pre class="file" id="file107" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "fmt"
        "log/slog"
        "math"
        "sort"
        "strings"
        "time"

        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/axiomhq/hyperloglog"
)

// AggNode wraps a child and performs sum/avg/min/max/count with by/without.
type AggNode struct {
        Op      AggOp
        By      []string
        Without []string
        Child   ExecNode
}

func (n *AggNode) Hints() ExecHints <span class="cov0" title="0">{ return n.Child.Hints() }</span>

func (n *AggNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        child := n.Child.Eval(sg, step)
        if len(child) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        <span class="cov0" title="0">buildGroupedTags := func(tags map[string]any) map[string]any </span><span class="cov0" title="0">{
                if len(n.By) &gt; 0 </span><span class="cov0" title="0">{
                        out := make(map[string]any, len(n.By))
                        for _, l := range n.By </span><span class="cov0" title="0">{
                                if v, ok := tags[l]; ok </span><span class="cov0" title="0">{
                                        out[l] = v
                                }</span>
                        }
                        <span class="cov0" title="0">return out</span>
                }
                <span class="cov0" title="0">if len(n.Without) &gt; 0 </span><span class="cov0" title="0">{
                        drop := make(map[string]struct{}, len(n.Without))
                        for _, l := range n.Without </span><span class="cov0" title="0">{
                                drop[l] = struct{}{}
                        }</span>
                        <span class="cov0" title="0">out := make(map[string]any, len(tags))
                        for k, v := range tags </span><span class="cov0" title="0">{
                                if _, skip := drop[k]; !skip </span><span class="cov0" title="0">{
                                        out[k] = v
                                }</span>
                        }
                        <span class="cov0" title="0">return out</span>
                }
                <span class="cov0" title="0">return map[string]any{}</span> // global agg
        }

        <span class="cov0" title="0">makeKey := func(tags map[string]any) string </span><span class="cov0" title="0">{
                if len(n.By) &gt; 0 </span><span class="cov0" title="0">{
                        parts := make([]string, 0, len(n.By))
                        for _, l := range n.By </span><span class="cov0" title="0">{
                                if v, ok := tags[l]; ok </span><span class="cov0" title="0">{
                                        parts = append(parts, fmt.Sprintf("%s=%v", l, v))
                                }</span>
                        }
                        <span class="cov0" title="0">if len(parts) == 0 </span><span class="cov0" title="0">{
                                return "default"
                        }</span>
                        <span class="cov0" title="0">return strings.Join(parts, ",")</span>
                }
                <span class="cov0" title="0">if len(n.Without) &gt; 0 </span><span class="cov0" title="0">{
                        drop := make(map[string]struct{}, len(n.Without))
                        for _, l := range n.Without </span><span class="cov0" title="0">{
                                drop[l] = struct{}{}
                        }</span>
                        <span class="cov0" title="0">parts := make([]string, 0, len(tags))
                        for k, v := range tags </span><span class="cov0" title="0">{
                                if _, skip := drop[k]; !skip </span><span class="cov0" title="0">{
                                        parts = append(parts, fmt.Sprintf("%s=%v", k, v))
                                }</span>
                        }
                        <span class="cov0" title="0">if len(parts) == 0 </span><span class="cov0" title="0">{
                                return "default"
                        }</span>
                        <span class="cov0" title="0">sort.Strings(parts)
                        return strings.Join(parts, ",")</span>
                }
                <span class="cov0" title="0">return "default"</span>
        }

        // Detect what kind(s) of values we have from child.
        <span class="cov0" title="0">hasDDS, hasHLL := false, false
        for _, r := range child </span><span class="cov0" title="0">{
                switch r.Value.Kind </span>{
                case ValDDS:<span class="cov0" title="0">
                        hasDDS = true</span>
                case ValHLL:<span class="cov0" title="0">
                        hasHLL = true</span>
                default:<span class="cov0" title="0"></span>
                }
        }

        <span class="cov0" title="0">switch </span>{
        // --------- DDSketch merge path ----------
        case hasDDS:<span class="cov0" title="0">
                type dacc struct {
                        d    *ddsketch.DDSketch
                        ts   int64
                        tags map[string]any
                }
                accs := map[string]*dacc{}

                for _, r := range child </span><span class="cov0" title="0">{
                        if r.Value.Kind != ValDDS || r.Value.DDS == nil </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">k := makeKey(r.Tags)
                        a := accs[k]
                        if a == nil </span><span class="cov0" title="0">{
                                // Clone first incoming sketch to preserve mapping/accuracy.
                                pb := r.Value.DDS.ToProto()
                                d, err := ddsketch.FromProto(pb)
                                if err != nil </span><span class="cov0" title="0">{
                                        slog.Error("dds fromproto (clone) failed", "err", err)
                                        if d2, e2 := ddsketch.NewDefaultDDSketch(0.01); e2 == nil </span><span class="cov0" title="0">{
                                                a = &amp;dacc{d: d2, ts: sg.Timestamp, tags: buildGroupedTags(r.Tags)}
                                        }</span> else<span class="cov0" title="0"> {
                                                continue</span>
                                        }
                                } else<span class="cov0" title="0"> {
                                        a = &amp;dacc{d: d, ts: sg.Timestamp, tags: buildGroupedTags(r.Tags)}
                                }</span>
                                <span class="cov0" title="0">accs[k] = a</span>
                        }
                        <span class="cov0" title="0">if err := a.d.MergeWith(r.Value.DDS); err != nil </span><span class="cov0" title="0">{
                                slog.Error("dds merge failed", "err", err)
                        }</span>
                }

                <span class="cov0" title="0">out := make(map[string]EvalResult, len(accs))
                for k, a := range accs </span><span class="cov0" title="0">{
                        out[k] = EvalResult{
                                Timestamp: a.ts,
                                Value:     Value{Kind: ValDDS, DDS: a.d},
                                Tags:      a.tags,
                        }
                }</span>
                <span class="cov0" title="0">return out</span>

        // --------- HLL merge path ----------
        case hasHLL:<span class="cov0" title="0">
                type hacc struct {
                        h    *hyperloglog.Sketch
                        ts   int64
                        tags map[string]any
                }
                accs := map[string]*hacc{}

                for _, r := range child </span><span class="cov0" title="0">{
                        if r.Value.Kind != ValHLL || r.Value.HLL == nil </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">k := makeKey(r.Tags)
                        a := accs[k]
                        if a == nil </span><span class="cov0" title="0">{
                                acc := &amp;hyperloglog.Sketch{}
                                if b, err := r.Value.HLL.MarshalBinary(); err == nil </span><span class="cov0" title="0">{
                                        _ = acc.UnmarshalBinary(b)
                                }</span> else<span class="cov0" title="0"> {
                                        acc = hyperloglog.New14()
                                }</span>
                                <span class="cov0" title="0">a = &amp;hacc{
                                        h:    acc,
                                        ts:   sg.Timestamp,
                                        tags: buildGroupedTags(r.Tags),
                                }
                                accs[k] = a</span>
                        }
                        <span class="cov0" title="0">_ = a.h.Merge(r.Value.HLL)</span>
                }

                <span class="cov0" title="0">out := make(map[string]EvalResult, len(accs))
                for k, a := range accs </span><span class="cov0" title="0">{
                        if n.Op == AggCount </span><span class="cov0" title="0">{
                                // Cardinality estimate → scalar number result
                                est := a.h.Estimate()
                                out[k] = EvalResult{
                                        Timestamp: a.ts,
                                        Value:     Value{Kind: ValScalar, Num: float64(est)},
                                        Tags:      a.tags,
                                }
                        }</span> else<span class="cov0" title="0"> {
                                // For non-count ops, keep the HLL (if you ever need it)
                                out[k] = EvalResult{
                                        Timestamp: a.ts,
                                        Value:     Value{Kind: ValHLL, HLL: a.h},
                                        Tags:      a.tags,
                                }
                        }</span>
                }
                <span class="cov0" title="0">return out</span>

        // --------- Scalar vector-agg path ----------
        default:<span class="cov0" title="0">
                type acc struct {
                        sum   float64
                        count int
                        min   float64
                        max   float64
                        ts    int64
                        tags  map[string]any
                }
                aggs := make(map[string]*acc, len(child))

                for _, r := range child </span><span class="cov0" title="0">{
                        if r.Value.Kind != ValScalar || math.IsNaN(r.Value.Num) </span><span class="cov0" title="0">{
                                continue</span>
                        }
                        <span class="cov0" title="0">k := makeKey(r.Tags)
                        a := aggs[k]
                        if a == nil </span><span class="cov0" title="0">{
                                a = &amp;acc{
                                        min:  math.Inf(1),
                                        max:  math.Inf(-1),
                                        ts:   sg.Timestamp,
                                        tags: buildGroupedTags(r.Tags),
                                }
                                aggs[k] = a
                        }</span>
                        <span class="cov0" title="0">v := r.Value.Num
                        a.sum += v
                        a.count++
                        if v &lt; a.min </span><span class="cov0" title="0">{
                                a.min = v
                        }</span>
                        <span class="cov0" title="0">if v &gt; a.max </span><span class="cov0" title="0">{
                                a.max = v
                        }</span>
                }

                <span class="cov0" title="0">out := make(map[string]EvalResult, len(aggs))
                for k, a := range aggs </span><span class="cov0" title="0">{
                        var v float64
                        switch n.Op </span>{
                        case AggSum:<span class="cov0" title="0">
                                v = a.sum</span>
                        case AggAvg:<span class="cov0" title="0">
                                if a.count == 0 </span><span class="cov0" title="0">{
                                        v = math.NaN()
                                }</span> else<span class="cov0" title="0"> {
                                        v = a.sum / float64(a.count)
                                }</span>
                        case AggMin:<span class="cov0" title="0">
                                v = a.min</span>
                        case AggMax:<span class="cov0" title="0">
                                v = a.max</span>
                        case AggCount:<span class="cov0" title="0">
                                v = float64(a.count)</span>
                        default:<span class="cov0" title="0">
                                v = math.NaN()</span>
                        }
                        <span class="cov0" title="0">out[k] = EvalResult{
                                Timestamp: a.ts,
                                Value:     Value{Kind: ValScalar, Num: v},
                                Tags:      a.tags,
                        }</span>
                }
                <span class="cov0" title="0">return out</span>
        }
}
</pre>
		
		<pre class="file" id="file108" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "errors"
        "fmt"
        "maps"
        "slices"
        "strings"
        "sync"

        "github.com/DataDog/sketches-go/ddsketch/mapping"
        "github.com/DataDog/sketches-go/ddsketch/store"

        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/axiomhq/hyperloglog"
)

// If you already have encode/decode utilities, use those and delete these.
func decodeHLL(b []byte) (*hyperloglog.Sketch, error) <span class="cov0" title="0">{
        if len(b) == 0 </span><span class="cov0" title="0">{
                return nil, errors.New("empty HLL bytes")
        }</span>
        <span class="cov0" title="0">var h hyperloglog.Sketch
        if err := h.UnmarshalBinary(b); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;h, nil</span>
}
func encodeHLL(h *hyperloglog.Sketch) ([]byte, error) <span class="cov0" title="0">{
        return h.MarshalBinary()
}</span>

func decodeDDS(b []byte, m mapping.IndexMapping) (*ddsketch.DDSketch, error) <span class="cov0" title="0">{
        sk, err := ddsketch.DecodeDDSketch(b, store.DefaultProvider, m)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return sk, nil</span>
}

func encodeDDS(d *ddsketch.DDSketch) []byte <span class="cov0" title="0">{
        var buf []byte
        d.Encode(&amp;buf, false)
        return buf
}</span>

func tagsKey(m map[string]any) string <span class="cov0" title="0">{
        if len(m) == 0 </span><span class="cov0" title="0">{
                return ""
        }</span>
        <span class="cov0" title="0">ks := slices.Collect(maps.Keys(m))
        slices.Sort(ks)
        var b strings.Builder
        for i, k := range ks </span><span class="cov0" title="0">{
                if i &gt; 0 </span><span class="cov0" title="0">{
                        b.WriteByte(',')
                }</span>
                <span class="cov0" title="0">b.WriteString(k)
                b.WriteByte('=')
                // store as strings; if you have numbers/booleans, format them explicitly
                b.WriteString(fmt.Sprint(m[k]))</span>
        }
        <span class="cov0" title="0">return b.String()</span>
}

// ---- Mergers ----

type sketchMerger interface {
        merge(SketchInput, mapping.IndexMapping)
        dataPoints() []SketchInput
}

type simpleSketchMerger struct {
        init SketchInput
        // merged state
        hll *hyperloglog.Sketch
        dds *ddsketch.DDSketch
        agg map[string]float64
}

func newSimpleSketchMerger(init SketchInput, mapping mapping.IndexMapping) *simpleSketchMerger <span class="cov0" title="0">{
        sm := &amp;simpleSketchMerger{init: init}
        switch init.SketchTags.SketchType </span>{
        case SketchHLL:<span class="cov0" title="0">
                if len(init.SketchTags.Bytes) &gt; 0 </span><span class="cov0" title="0">{
                        if h, err := decodeHLL(init.SketchTags.Bytes); err == nil </span><span class="cov0" title="0">{
                                sm.hll = h
                        }</span>
                }
        case SketchDDS:<span class="cov0" title="0">
                if len(init.SketchTags.Bytes) &gt; 0 </span><span class="cov0" title="0">{
                        if d, err := decodeDDS(init.SketchTags.Bytes, mapping); err == nil </span><span class="cov0" title="0">{
                                sm.dds = d
                        }</span>
                }
        case SketchMAP:<span class="cov0" title="0">
                cp := make(map[string]float64, len(init.SketchTags.Agg))
                for k, v := range init.SketchTags.Agg </span><span class="cov0" title="0">{
                        cp[k] = v
                }</span>
                <span class="cov0" title="0">sm.agg = cp</span>
        }
        <span class="cov0" title="0">return sm</span>
}

func (m *simpleSketchMerger) merge(si SketchInput, indexMapping mapping.IndexMapping) <span class="cov0" title="0">{
        switch si.SketchTags.SketchType </span>{
        case SketchHLL:<span class="cov0" title="0">
                in, err := decodeHLL(si.SketchTags.Bytes)
                if err != nil || in == nil </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov0" title="0">if m.hll == nil </span><span class="cov0" title="0">{
                        m.hll = hyperloglog.New14()
                }</span>
                <span class="cov0" title="0">_ = m.hll.Merge(in)</span>

        case SketchDDS:<span class="cov0" title="0">
                in, err := decodeDDS(si.SketchTags.Bytes, indexMapping)
                if err != nil || in == nil </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov0" title="0">if m.dds == nil </span><span class="cov0" title="0">{
                        if d, e := ddsketch.NewDefaultDDSketch(0.01); e == nil </span><span class="cov0" title="0">{
                                m.dds = d
                        }</span> else<span class="cov0" title="0"> {
                                return
                        }</span>
                }
                <span class="cov0" title="0">_ = m.dds.MergeWith(in)</span>

        case SketchMAP:<span class="cov0" title="0">
                if m.agg == nil </span><span class="cov0" title="0">{
                        m.agg = map[string]float64{}
                }</span>
                <span class="cov0" title="0">for k, v := range si.SketchTags.Agg </span><span class="cov0" title="0">{
                        switch k </span>{
                        case SUM, COUNT:<span class="cov0" title="0">
                                m.agg[k] += v</span>
                        case MIN:<span class="cov0" title="0">
                                if cur, ok := m.agg[MIN]; !ok || v &lt; cur </span><span class="cov0" title="0">{
                                        m.agg[MIN] = v
                                }</span>
                        case MAX:<span class="cov0" title="0">
                                if cur, ok := m.agg[MAX]; !ok || v &gt; cur </span><span class="cov0" title="0">{
                                        m.agg[MAX] = v
                                }</span>
                        default:<span class="cov0" title="0"></span>
                                // ignore other keys for now
                        }
                }
        }
}

func (m *simpleSketchMerger) dataPoints() []SketchInput <span class="cov0" title="0">{
        out := m.init // copy
        switch m.init.SketchTags.SketchType </span>{
        case SketchHLL:<span class="cov0" title="0">
                if m.hll != nil </span><span class="cov0" title="0">{
                        if b, err := encodeHLL(m.hll); err == nil </span><span class="cov0" title="0">{
                                out.SketchTags.Bytes = b
                        }</span>
                }
        case SketchDDS:<span class="cov0" title="0">
                if m.dds != nil </span><span class="cov0" title="0">{
                        out.SketchTags.Bytes = encodeDDS(m.dds)
                }</span>
        case SketchMAP:<span class="cov0" title="0">
                if m.agg != nil </span><span class="cov0" title="0">{
                        out.SketchTags.Agg = maps.Clone(m.agg)
                }</span>
        }
        <span class="cov0" title="0">return []SketchInput{out}</span>
}

type groupBySketchMerger struct {
        byTags map[string]*simpleSketchMerger // key = stable tagsKey
}

func newGroupBySketchMerger() *groupBySketchMerger <span class="cov0" title="0">{
        return &amp;groupBySketchMerger{byTags: map[string]*simpleSketchMerger{}}
}</span>

func (g *groupBySketchMerger) merge(si SketchInput, indexMapping mapping.IndexMapping) <span class="cov0" title="0">{
        key := tagsKey(si.SketchTags.Tags)
        if acc, ok := g.byTags[key]; ok </span><span class="cov0" title="0">{
                acc.merge(si, indexMapping)
                return
        }</span>
        <span class="cov0" title="0">acc := newSimpleSketchMerger(si, indexMapping)
        g.byTags[key] = acc</span>
}

func (g *groupBySketchMerger) dataPoints() []SketchInput <span class="cov0" title="0">{
        var out []SketchInput
        for _, acc := range g.byTags </span><span class="cov0" title="0">{
                out = append(out, acc.dataPoints()...)
        }</span>
        <span class="cov0" title="0">return out</span>
}

// ---- TimeGroupedSketchAggregator ----

type BaseExprLookup func(si SketchInput) (BaseExpr, bool)

// TimeGroupedSketchAggregator groups by timestamp across a small ring of buffers,
// and within each time bucket it groups by BaseExpr.ID, merging compatible sketches.
// When a new timestamp bumps an occupied slot, the completed group is flushed.
type TimeGroupedSketchAggregator struct {
        mapping    mapping.IndexMapping
        mu         sync.Mutex
        numBuf     int
        buffers    []map[string]sketchMerger // per time-slot: by BaseExpr.ID
        timestamps []int64
        cutoff     int64
        lookup     BaseExprLookup
}

func NewTimeGroupedSketchAggregator(numBuffers int, lookup BaseExprLookup) *TimeGroupedSketchAggregator <span class="cov0" title="0">{
        if numBuffers &lt; 2 </span><span class="cov0" title="0">{
                numBuffers = 2
        }</span>
        <span class="cov0" title="0">bufs := make([]map[string]sketchMerger, numBuffers)
        ts := make([]int64, numBuffers)
        for i := range bufs </span><span class="cov0" title="0">{
                bufs[i] = map[string]sketchMerger{}
        }</span>
        <span class="cov0" title="0">m, err := mapping.NewLogarithmicMapping(0.01)
        if err != nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return &amp;TimeGroupedSketchAggregator{
                mapping:    m,
                numBuf:     numBuffers,
                buffers:    bufs,
                timestamps: ts,
                lookup:     lookup,
        }</span>
}

// findBuffer returns index of existing slot for t, or a negative insertion point
// (-pos-1) for the least-recent slot to be flushed/overwritten.
func (a *TimeGroupedSketchAggregator) findBuffer(t int64) int <span class="cov0" title="0">{
        // Keep slots roughly sorted; pick the "oldest" to evict.
        minIdx := 0
        for i := 0; i &lt; len(a.timestamps); i++ </span><span class="cov0" title="0">{
                if a.timestamps[i] == t </span><span class="cov0" title="0">{
                        return i
                }</span>
                <span class="cov0" title="0">if i &gt; 0 &amp;&amp; a.timestamps[i] &lt; a.timestamps[i-1] </span><span class="cov0" title="0">{
                        minIdx = i
                }</span>
        }
        <span class="cov0" title="0">return -minIdx - 1</span>
}

func (a *TimeGroupedSketchAggregator) flush(i int) SketchGroup <span class="cov0" title="0">{
        t := a.timestamps[i]
        grp := SketchGroup{
                Timestamp: t,
                Group:     map[string][]SketchInput{},
        }
        for beid, merger := range a.buffers[i] </span><span class="cov0" title="0">{
                grp.Group[beid] = merger.dataPoints()
        }</span>
        <span class="cov0" title="0">a.cutoff = t
        a.buffers[i] = map[string]sketchMerger{}
        a.timestamps[i] = 0
        return grp</span>
}

// AddBatch ingests a batch and returns any completed time-groups that got flushed.
// You can call this repeatedly as you stream data in order.
func (a *TimeGroupedSketchAggregator) AddBatch(in []SketchInput) (out []SketchGroup) <span class="cov0" title="0">{
        a.mu.Lock()
        defer a.mu.Unlock()

        for _, si := range in </span><span class="cov0" title="0">{
                t := si.Timestamp
                if t &lt;= a.cutoff </span><span class="cov0" title="0">{
                        // Drop late data; metrics omitted for brevity
                        continue</span>
                }

                <span class="cov0" title="0">slot := a.findBuffer(t)
                if slot &gt;= 0 </span><span class="cov0" title="0">{
                        a.aggregate(slot, si)
                        continue</span>
                }
                // rotate
                <span class="cov0" title="0">pos := -slot - 1
                if a.timestamps[pos] &gt; 0 </span><span class="cov0" title="0">{
                        flushed := a.flush(pos)
                        if flushed.Timestamp &gt; 0 </span><span class="cov0" title="0">{
                                out = append(out, flushed)
                        }</span>
                }
                <span class="cov0" title="0">a.aggregate(pos, si)
                a.timestamps[pos] = t</span>
        }
        <span class="cov0" title="0">return out</span>
}

// FlushAll flushes all non-empty buffers (end-of-stream).
func (a *TimeGroupedSketchAggregator) FlushAll() (out []SketchGroup) <span class="cov0" title="0">{
        a.mu.Lock()
        defer a.mu.Unlock()

        for i := range a.buffers </span><span class="cov0" title="0">{
                if a.timestamps[i] &gt; 0 </span><span class="cov0" title="0">{
                        out = append(out, a.flush(i))
                }</span>
        }
        // Keep a deterministic order
        <span class="cov0" title="0">slices.SortFunc(out, func(x, y SketchGroup) int </span><span class="cov0" title="0">{
                switch </span>{
                case x.Timestamp &lt; y.Timestamp:<span class="cov0" title="0">
                        return -1</span>
                case x.Timestamp &gt; y.Timestamp:<span class="cov0" title="0">
                        return 1</span>
                default:<span class="cov0" title="0">
                        return 0</span>
                }
        })
        <span class="cov0" title="0">return out</span>
}

func (a *TimeGroupedSketchAggregator) aggregate(i int, si SketchInput) <span class="cov0" title="0">{
        be, ok := a.lookup(si)
        if !ok </span><span class="cov0" title="0">{
                // unknown base expr → drop or log
                return
        }</span>
        <span class="cov0" title="0">beid := be.ID

        // Choose merger strategy. If the BaseExpr has explicit GroupBy (non-HLL/MAP nuance),
        // we preserve separate tag buckets via GroupBySketchMerger; otherwise we collapse.
        mergers := a.buffers[i]
        mer, ok := mergers[beid]
        if !ok </span><span class="cov0" title="0">{
                if len(be.GroupBy) &gt; 0 </span><span class="cov0" title="0">{
                        // HLL: we generally want to union across all tag buckets for the same group key
                        // (your pipeline already applied the grouping; if you do need per-tag buckets
                        // for HLL too, switch to GroupBySketchMerger here).
                        gb := newGroupBySketchMerger()
                        gb.merge(si, a.mapping)
                        mergers[beid] = gb
                        return
                }</span>
                <span class="cov0" title="0">sm := newSimpleSketchMerger(si, a.mapping)
                mergers[beid] = sm
                return</span>
        }
        <span class="cov0" title="0">mer.merge(si, a.mapping)</span>
}
</pre>
		
		<pre class="file" id="file109" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "fmt"
        "math"
        "sort"
        "strings"
        "time"
)

// BinaryNode : arithmetic (+ - * /) with vector matching (on-only).
type BinaryNode struct {
        Op    BinOp
        LHS   ExecNode
        RHS   ExecNode
        Match *VectorMatch // Only On []string is used
}

func (n *BinaryNode) Hints() ExecHints <span class="cov0" title="0">{
        l, r := n.LHS.Hints(), n.RHS.Hints()
        return ExecHints{
                WantTopK:    l.WantTopK || r.WantTopK,
                WantBottomK: l.WantBottomK || r.WantBottomK,
                WantCount:   l.WantCount || r.WantCount,
        }
}</span>

func (n *BinaryNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        lmap := n.LHS.Eval(sg, step)
        rmap := n.RHS.Eval(sg, step)
        if len(lmap) == 0 || len(rmap) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        // Build a join key from tags according to on(...).
        <span class="cov0" title="0">buildKey := func(tags map[string]any) (string, map[string]any) </span><span class="cov0" title="0">{
                // If on(...) is provided, keep only those labels as the join key + output tags.
                if n.Match != nil &amp;&amp; len(n.Match.On) &gt; 0 </span><span class="cov0" title="0">{
                        parts := make([]string, 0, len(n.Match.On))
                        outTags := make(map[string]any, len(n.Match.On))
                        for _, l := range n.Match.On </span><span class="cov0" title="0">{
                                if v, ok := tags[l]; ok </span><span class="cov0" title="0">{
                                        parts = append(parts, fmt.Sprintf("%s=%v", l, v))
                                        outTags[l] = v
                                }</span>
                        }
                        <span class="cov0" title="0">if len(parts) == 0 </span><span class="cov0" title="0">{
                                return "default", map[string]any{}
                        }</span>
                        <span class="cov0" title="0">return strings.Join(parts, ","), outTags</span>
                }

                // Default: match on full label set.
                <span class="cov0" title="0">if len(tags) == 0 </span><span class="cov0" title="0">{
                        return "default", map[string]any{}
                }</span>
                <span class="cov0" title="0">parts := make([]string, 0, len(tags))
                for k, v := range tags </span><span class="cov0" title="0">{
                        parts = append(parts, fmt.Sprintf("%s=%v", k, v))
                }</span>
                <span class="cov0" title="0">sort.Strings(parts)
                return strings.Join(parts, ","), tags</span>
        }

        // Index RHS by join key.
        <span class="cov0" title="0">type keyed struct {
                tags map[string]any
                res  EvalResult
        }
        ridx := make(map[string]keyed, len(rmap))
        for _, r := range rmap </span><span class="cov0" title="0">{
                k, ktags := buildKey(r.Tags)
                ridx[k] = keyed{tags: ktags, res: r}
        }</span>

        // Join and compute op on scalars.
        <span class="cov0" title="0">out := make(map[string]EvalResult)
        for _, l := range lmap </span><span class="cov0" title="0">{
                lk, ktags := buildKey(l.Tags)
                rr, ok := ridx[lk]
                if !ok </span><span class="cov0" title="0">{
                        continue</span> // inner join
                }
                // Only operate on scalars; skip pairs with non-scalar kinds.
                <span class="cov0" title="0">if l.Value.Kind != ValScalar || rr.res.Value.Kind != ValScalar </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">a, b := l.Value.Num, rr.res.Value.Num
                var v float64
                switch n.Op </span>{
                case OpAdd:<span class="cov0" title="0">
                        v = a + b</span>
                case OpSub:<span class="cov0" title="0">
                        v = a - b</span>
                case OpMul:<span class="cov0" title="0">
                        v = a * b</span>
                case OpDiv:<span class="cov0" title="0">
                        if b == 0 </span><span class="cov0" title="0">{
                                v = math.NaN()
                        }</span> else<span class="cov0" title="0"> {
                                v = a / b
                        }</span>
                default:<span class="cov0" title="0">
                        v = math.NaN()</span>
                }

                <span class="cov0" title="0">out[lk] = EvalResult{
                        Timestamp: sg.Timestamp,
                        Value:     Value{Kind: ValScalar, Num: v},
                        Tags:      ktags, // only the on(...) labels (or full set if no on)
                }</span>
        }

        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file110" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "sort"
        "time"
)

// BottomKNode : BottomK selects the smallest K per step from child outputs.
type BottomKNode struct {
        K     int
        Child ExecNode
}

func (n *BottomKNode) Hints() ExecHints <span class="cov0" title="0">{
        h := n.Child.Hints()
        h.WantBottomK = true
        return h
}</span>

func (n *BottomKNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        if n.K &lt;= 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>
        <span class="cov0" title="0">child := n.Child.Eval(sg, step)
        if len(child) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        <span class="cov0" title="0">type entry struct {
                key string
                val EvalResult
        }

        // Keep only scalar, finite values.
        buf := make([]entry, 0, len(child))
        for k, r := range child </span><span class="cov0" title="0">{
                if r.Value.Kind != ValScalar || math.IsNaN(r.Value.Num) </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">buf = append(buf, entry{key: k, val: r})</span>
        }
        <span class="cov0" title="0">if len(buf) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        // Sort ascending; tie-break by key for determinism.
        <span class="cov0" title="0">sort.SliceStable(buf, func(i, j int) bool </span><span class="cov0" title="0">{
                vi := buf[i].val.Value.Num
                vj := buf[j].val.Value.Num
                if vi == vj </span><span class="cov0" title="0">{
                        return buf[i].key &lt; buf[j].key
                }</span>
                <span class="cov0" title="0">return vi &lt; vj</span>
        })

        // Take bottom K.
        <span class="cov0" title="0">if len(buf) &gt; n.K </span><span class="cov0" title="0">{
                buf = buf[:n.K]
        }</span>

        <span class="cov0" title="0">out := make(map[string]EvalResult, len(buf))
        for _, e := range buf </span><span class="cov0" title="0">{
                out[e.key] = e.val
        }</span>
        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file111" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "time"
)

// ClampMaxNode : applies max(value, Max) to child stream.
type ClampMaxNode struct {
        Max   float64
        Child ExecNode
}

func (n *ClampMaxNode) Hints() ExecHints <span class="cov0" title="0">{ return n.Child.Hints() }</span>

func (n *ClampMaxNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        child := n.Child.Eval(sg, step)
        out := make(map[string]EvalResult, len(child))
        for k, r := range child </span><span class="cov0" title="0">{
                val := r.Value
                if val.Kind == ValScalar &amp;&amp; !math.IsNaN(val.Num) </span><span class="cov0" title="0">{
                        if val.Num &gt; n.Max </span><span class="cov0" title="0">{
                                val.Num = n.Max
                        }</span>
                }
                <span class="cov0" title="0">out[k] = EvalResult{
                        Timestamp: r.Timestamp,
                        Value:     val,
                        Tags:      r.Tags,
                }</span>
        }
        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file112" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "time"
)

// ClampMinNode : applies max(value, Min) to child stream.
type ClampMinNode struct {
        Min   float64
        Child ExecNode
}

func (n *ClampMinNode) Hints() ExecHints <span class="cov0" title="0">{ return n.Child.Hints() }</span>

func (n *ClampMinNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        child := n.Child.Eval(sg, step)
        out := make(map[string]EvalResult, len(child))
        for k, r := range child </span><span class="cov0" title="0">{
                val := r.Value
                if val.Kind == ValScalar &amp;&amp; !math.IsNaN(val.Num) </span><span class="cov0" title="0">{
                        if val.Num &lt; n.Min </span><span class="cov0" title="0">{
                                val.Num = n.Min
                        }</span>
                }
                <span class="cov0" title="0">out[k] = EvalResult{
                        Timestamp: r.Timestamp,
                        Value:     val,
                        Tags:      r.Tags,
                }</span>
        }
        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file113" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "fmt"
        "sort"
        "time"
)

func stepForQueryDuration(startMs, endMs int64) time.Duration <span class="cov0" title="0">{
        oneHourish := int64(1 * 65 * 60 * 1000)
        twelveHours := int64(12 * 60 * 60 * 1000)
        oneDay := int64(24 * 60 * 60 * 1000)
        threeDays := int64(3 * 24 * 60 * 60 * 1000)

        span := endMs - startMs
        switch </span>{
        case span &lt;= oneHourish:<span class="cov0" title="0">
                return 10 * time.Second</span>
        case span &lt;= twelveHours:<span class="cov0" title="0">
                return time.Minute</span>
        case span &lt;= oneDay:<span class="cov0" title="0">
                return 5 * time.Minute</span>
        case span &lt;= threeDays:<span class="cov0" title="0">
                return 20 * time.Minute</span>
        default:<span class="cov0" title="0">
                return time.Hour</span>
        }
}

type DateIntHours struct {
        DateInt int      // e.g. 20250814
        Hours   []string // "00".."23"
}

// zeroFilledHour returns "00".."23".
func zeroFilledHour(h int) string <span class="cov0" title="0">{
        return fmt.Sprintf("%02d", h)
}</span>

// toDateInt converts a time to YYYYMMDD (UTC unless you pass a different loc).
func toDateInt(t time.Time) int <span class="cov0" title="0">{
        y, m, d := t.Date()
        return y*10000 + int(m)*100 + d
}</span>

// dateIntHoursRange: given a time range produces the date int hours, in reverse order of date ints, and hours are reverse as well.
func dateIntHoursRange(startMs, endMs int64, loc *time.Location) []DateIntHours <span class="cov0" title="0">{
        if loc == nil </span><span class="cov0" title="0">{
                loc = time.UTC
        }</span>
        <span class="cov0" title="0">start := time.UnixMilli(startMs).In(loc).Truncate(time.Hour)
        end := time.UnixMilli(endMs).In(loc).Truncate(time.Hour)

        var out []DateIntHours

        var curDateInt int
        hoursSet := make(map[string]struct{})
        flush := func() </span><span class="cov0" title="0">{
                if curDateInt == 0 || len(hoursSet) == 0 </span><span class="cov0" title="0">{
                        return
                }</span>
                <span class="cov0" title="0">hh := make([]string, 0, len(hoursSet))
                for h := range hoursSet </span><span class="cov0" title="0">{
                        hh = append(hh, h)
                }</span>
                // reverse hour order "23".."00"
                <span class="cov0" title="0">sort.Sort(sort.Reverse(sort.StringSlice(hh)))
                out = append(out, DateIntHours{DateInt: curDateInt, Hours: hh})
                hoursSet = make(map[string]struct{})</span>
        }

        <span class="cov0" title="0">for t := start; !t.After(end.Add(time.Hour)); t = t.Add(time.Hour) </span><span class="cov0" title="0">{
                di := toDateInt(t)
                if curDateInt != 0 &amp;&amp; di != curDateInt </span><span class="cov0" title="0">{
                        flush()
                }</span>
                <span class="cov0" title="0">curDateInt = di
                hoursSet[zeroFilledHour(t.Hour())] = struct{}{}</span>
        }
        <span class="cov0" title="0">flush()

        for i, j := 0, len(out)-1; i &lt; j; i, j = i+1, j-1 </span><span class="cov0" title="0">{
                out[i], out[j] = out[j], out[i]
        }</span>

        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file114" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "context"
        "fmt"
        "os"
        "strconv"

        "github.com/google/uuid"
)

type WorkerDiscovery interface {
        Start(ctx context.Context) error
        Stop() error
        GetWorkersForSegments(organizationID uuid.UUID, segmentIDs []string) ([]SegmentWorkerMapping, error)
        GetAllWorkers() ([]Worker, error)
}

// CreateWorkerDiscovery creates the appropriate WorkerDiscovery implementation
// based on the EXECUTION_ENVIRONMENT environment variable.
//
// Supported values:
//   - "local": Creates LocalDevDiscovery for local development
//   - "kubernetes": Creates KubernetesWorkerDiscovery for Kubernetes environments
//   - unset or other values: Returns an error
func CreateWorkerDiscovery() (WorkerDiscovery, error) <span class="cov0" title="0">{
        execEnv := os.Getenv("EXECUTION_ENVIRONMENT")

        switch execEnv </span>{
        case "local":<span class="cov0" title="0">
                return NewLocalDevDiscovery(), nil</span>

        case "kubernetes":<span class="cov0" title="0">
                return createKubernetesWorkerDiscovery()</span>

        case "":<span class="cov0" title="0">
                return nil, fmt.Errorf("EXECUTION_ENVIRONMENT environment variable is required (must be 'local' or 'kubernetes')")</span>

        default:<span class="cov0" title="0">
                return nil, fmt.Errorf("unsupported EXECUTION_ENVIRONMENT: %s (must be 'local' or 'kubernetes')", execEnv)</span>
        }
}

// createKubernetesWorkerDiscovery creates a KubernetesWorkerDiscovery with required configuration
func createKubernetesWorkerDiscovery() (WorkerDiscovery, error) <span class="cov0" title="0">{
        namespace := os.Getenv("POD_NAMESPACE")
        if namespace == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("POD_NAMESPACE environment variable is required for kubernetes execution environment")
        }</span>

        <span class="cov0" title="0">workerLabelSelector := os.Getenv("WORKER_POD_LABEL_SELECTOR")
        if workerLabelSelector == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("WORKER_POD_LABEL_SELECTOR environment variable is required for kubernetes execution environment")
        }</span>

        <span class="cov0" title="0">workerPortStr := os.Getenv("QUERY_WORKER_PORT")
        if workerPortStr == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("QUERY_WORKER_PORT environment variable is required for kubernetes execution environment")
        }</span>

        <span class="cov0" title="0">workerPort, err := strconv.Atoi(workerPortStr)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("invalid QUERY_WORKER_PORT: %w", err)
        }</span>

        <span class="cov0" title="0">config := KubernetesWorkerDiscoveryConfig{
                Namespace:           namespace,
                WorkerLabelSelector: workerLabelSelector,
                WorkerPort:          workerPort,
        }

        return NewKubernetesWorkerDiscovery(config)</span>
}

func IsLocalDev() bool <span class="cov0" title="0">{
        return os.Getenv("EXECUTION_ENVIRONMENT") == "local"
}</span>
</pre>
		
		<pre class="file" id="file115" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "context"
        "time"
)

// EvalFlowOptions tunes buffering / aggregation behavior.
type EvalFlowOptions struct {
        // NumBuffers is the number of time-buckets the aggregator keeps before flushing
        // (small ring buffer). 3 is a good default.
        NumBuffers int
        // OutBuffer is the channel buffer size for result maps.
        OutBuffer int
}

// EvalFlow connects a stream of SketchInput -&gt; aggregator -&gt; root.Eval,
// and returns a channel of evaluated results (one map per flushed time-bucket).
type EvalFlow struct {
        root ExecNode
        step time.Duration
        agg  *TimeGroupedSketchAggregator

        outBuf int
}

// NewEvalFlow builds a flow for a compiled plan.
// `leaves` are used to build a BaseExpr lookup by ID for the aggregator.
func NewEvalFlow(
        root ExecNode,
        leaves []BaseExpr,
        step time.Duration,
        opts EvalFlowOptions,
) *EvalFlow <span class="cov0" title="0">{
        if opts.NumBuffers &lt;= 0 </span><span class="cov0" title="0">{
                opts.NumBuffers = 3
        }</span>
        <span class="cov0" title="0">if opts.OutBuffer &lt;= 0 </span><span class="cov0" title="0">{
                opts.OutBuffer = 256
        }</span>

        // Map BaseExpr.ID -&gt; BaseExpr for fast lookup from SketchInput.
        <span class="cov0" title="0">beByID := make(map[string]BaseExpr, len(leaves))
        for _, be := range leaves </span><span class="cov0" title="0">{
                beByID[be.ID] = be
        }</span>

        <span class="cov0" title="0">lookup := func(si SketchInput) (BaseExpr, bool) </span><span class="cov0" title="0">{
                // We expect workers to set si.ExprID (or similar). If your field is named
                // differently, adjust here.
                if be, ok := beByID[si.ExprID]; ok </span><span class="cov0" title="0">{
                        return be, true
                }</span>
                <span class="cov0" title="0">return BaseExpr{}, false</span>
        }

        <span class="cov0" title="0">return &amp;EvalFlow{
                root:   root,
                step:   step,
                agg:    NewTimeGroupedSketchAggregator(opts.NumBuffers, lookup),
                outBuf: opts.OutBuffer,
        }</span>
}

// Run consumes a globally merged time-sorted stream of SketchInput and produces
// a channel of evaluated results (one per flushed time-bucket).
func (f *EvalFlow) Run(
        ctx context.Context,
        in &lt;-chan SketchInput,
) &lt;-chan map[string]EvalResult <span class="cov0" title="0">{
        out := make(chan map[string]EvalResult, f.outBuf)

        go func() </span><span class="cov0" title="0">{
                defer close(out)

                for </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                // Flush what we have and exit.
                                f.flushAll(out)
                                return</span>

                        case si, ok := &lt;-in:<span class="cov0" title="0">
                                if !ok </span><span class="cov0" title="0">{
                                        // End of input: flush remaining buckets.
                                        f.flushAll(out)
                                        return
                                }</span>
                                // Add this single item; aggregator may return completed buckets.
                                <span class="cov0" title="0">for _, sg := range f.agg.AddBatch([]SketchInput{si}) </span><span class="cov0" title="0">{
                                        res := f.root.Eval(sg, f.step)
                                        if len(res) &gt; 0 </span><span class="cov0" title="0">{
                                                out &lt;- res
                                        }</span>
                                }
                        }
                }
        }()

        <span class="cov0" title="0">return out</span>
}

func (f *EvalFlow) flushAll(out chan&lt;- map[string]EvalResult) <span class="cov0" title="0">{
        for _, sg := range f.agg.FlushAll() </span><span class="cov0" title="0">{
                res := f.root.Eval(sg, f.step)
                if len(res) &gt; 0 </span><span class="cov0" title="0">{
                        out &lt;- res
                }</span>
        }
}
</pre>
		
		<pre class="file" id="file116" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/axiomhq/hyperloglog"
)

type SketchType string

const (
        SketchHLL SketchType = "hll" // cardinality
        SketchMAP SketchType = "map" // pre-aggregated (sum, count, min, max, etc.)
        SketchDDS SketchType = "dds" // distinct count sketch
        SUM                  = "sum"
        COUNT                = "count"
        MIN                  = "min"
        MAX                  = "max"
)

type SketchTags struct {
        Tags       map[string]any     `json:"tags"`
        SketchType SketchType         `json:"sketchType"`
        Bytes      []byte             `json:"bytes,omitempty"`
        Agg        map[string]float64 `json:"agg,omitempty"`
}

func (t *SketchTags) getAggValue(name string) float64 <span class="cov0" title="0">{
        if t.SketchType != SketchMAP || t.Agg == nil </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov0" title="0">value, exists := t.Agg[name]
        if !exists </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov0" title="0">return value</span>
}

type SketchInput struct {
        ExprID         string     `json:"exprID"`
        OrganizationID string     `json:"organizationID"`
        Timestamp      int64      `json:"timestamp"`
        Frequency      int64      `json:"frequency"` // in seconds
        SketchTags     SketchTags `json:"sketchTags"`
}

func (si SketchInput) GetTimestamp() int64 <span class="cov0" title="0">{ return si.Timestamp }</span>

type SketchGroup struct {
        Timestamp int64
        Group     map[string][]SketchInput // key = BaseExpr.ID
}

type ValueKind int

const (
        ValScalar ValueKind = iota
        ValHLL
        ValDDS
)

type Value struct {
        Kind ValueKind
        Num  float64
        HLL  *hyperloglog.Sketch
        DDS  *ddsketch.DDSketch
}

type EvalResult struct {
        Timestamp int64
        Tags      map[string]any
        Value     Value
}
</pre>
		
		<pre class="file" id="file117" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "context"
        "fmt"
        "log/slog"
        "os"
        "strings"
        "time"

        "github.com/google/uuid"
        "github.com/prometheus/common/model"

        "github.com/cardinalhq/lakerunner/lrdb"
)

// PushDownRequest is sent to a worker.
type PushDownRequest struct {
        OrganizationID uuid.UUID     `json:"orgId"`
        BaseExpr       BaseExpr      `json:"baseExpr"`
        StartTs        int64         `json:"startTs"`
        EndTs          int64         `json:"endTs"`
        Step           time.Duration `json:"step"`
        Segments       []SegmentInfo `json:"segments"`
}

// Evaluate plans pushdowns, fans requests out to workers, merges their streams,
// and returns a single chronologically merged stream of SketchInput.
// The merged stream’s timestamps are aligned to the evaluation window.
func (q *QuerierService) Evaluate(
        ctx context.Context,
        orgID uuid.UUID,
        startTs, endTs int64,
        queryPlan QueryPlan,
        reverseSort bool,
) (&lt;-chan map[string]EvalResult, error) <span class="cov0" title="0">{
        stepDuration := stepForQueryDuration(startTs, endTs)

        var allLeafChans []&lt;-chan SketchInput

        workers, err := q.workerDiscovery.GetAllWorkers()
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to get all workers", "err", err)
                return nil, fmt.Errorf("failed to get all workers: %w", err)
        }</span>

        // For each leaf/base-expr, compute effective window (offset-aware), then push down per grouped segments.
        <span class="cov0" title="0">for _, leaf := range queryPlan.Leaves </span><span class="cov0" title="0">{
                offMs, err := parseOffsetMs(leaf.Offset)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("invalid offset on leaf; ignoring offset", "offset", leaf.Offset, "err", err)
                        offMs = 0
                }</span>

                // Effective range to *read* from storage.
                <span class="cov0" title="0">effStart := startTs - offMs
                effEnd := endTs - offMs

                // Partition by dateInt hours for storage listing.
                dateIntHours := dateIntHoursRange(effStart, effEnd, time.UTC)

                for _, dateIntHour := range dateIntHours </span><span class="cov0" title="0">{
                        segments, err := q.lookupSegments(ctx, dateIntHour, effStart, effEnd, stepDuration, orgID)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to get segment infos", "dateInt", dateIntHour.DateInt, "err", err)
                                continue</span>
                        }
                        // Tag segments with this leaf id so worker knows which expr it is serving.
                        <span class="cov0" title="0">for i := range segments </span><span class="cov0" title="0">{
                                segments[i].ExprID = leaf.ID
                        }</span>

                        <span class="cov0" title="0">if len(segments) == 0 </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        // Form time-contiguous batches sized for the number of workers.
                        <span class="cov0" title="0">groups := ComputeReplayBatchesWithWorkers(segments, stepDuration, effStart, effEnd, len(workers), true)

                        for _, group := range groups </span><span class="cov0" title="0">{
                                // Collect all segment IDs for worker assignment
                                segmentIDs := make([]string, 0, len(group.Segments))
                                segmentMap := make(map[string][]SegmentInfo)
                                for _, segment := range segments </span><span class="cov0" title="0">{
                                        segmentIDs = append(segmentIDs, segment.SegmentID)
                                        segmentMap[segment.SegmentID] = append(segmentMap[segment.SegmentID], segment)
                                }</span>

                                // Get worker assignments for all segments
                                <span class="cov0" title="0">mappings, err := q.workerDiscovery.GetWorkersForSegments(orgID, segmentIDs)
                                if err != nil </span><span class="cov0" title="0">{
                                        slog.Error("failed to get worker assignments", "err", err)
                                        continue</span>
                                }

                                // Group segments by assigned worker
                                <span class="cov0" title="0">workerGroups := make(map[Worker][]SegmentInfo)
                                for _, mapping := range mappings </span><span class="cov0" title="0">{
                                        segmentList := segmentMap[mapping.SegmentID]
                                        workerGroups[mapping.Worker] = append(workerGroups[mapping.Worker], segmentList...)
                                }</span>

                                <span class="cov0" title="0">for worker, workerSegments := range workerGroups </span><span class="cov0" title="0">{
                                        req := PushDownRequest{
                                                OrganizationID: orgID,
                                                BaseExpr:       leaf,
                                                StartTs:        group.StartTs,
                                                EndTs:          group.EndTs,
                                                Segments:       workerSegments,
                                                Step:           stepDuration,
                                        }

                                        // Push down to worker; get its stream back.
                                        ch, err := q.pushDown(ctx, worker, req)
                                        if err != nil </span><span class="cov0" title="0">{
                                                slog.Error("pushdown failed", "worker", worker, "err", err)
                                                continue</span>
                                        }

                                        <span class="cov0" title="0">if offMs != 0 </span><span class="cov0" title="0">{
                                                ch = shiftTimestamps(ctx, ch, offMs, 256)
                                        }</span>

                                        <span class="cov0" title="0">allLeafChans = append(allLeafChans, ch)</span>
                                }
                        }
                }
        }

        // Nothing to merge → return closed chan.
        <span class="cov0" title="0">if len(allLeafChans) == 0 </span><span class="cov0" title="0">{
                slog.Info("no pushdowns produced any channels")
                out := make(chan SketchInput)
                close(out)
                return nil, fmt.Errorf("no pushdowns produced any channels")
        }</span>

        // Merge all worker streams by timestamp (ascending).
        <span class="cov0" title="0">merged := MergeSorted(ctx, reverseSort, 1024, allLeafChans...)
        // Pipe through EvalFlow (aggregator -&gt; root.Eval)
        flow := NewEvalFlow(queryPlan.Root, queryPlan.Leaves, stepDuration, EvalFlowOptions{
                NumBuffers: 2,
                OutBuffer:  1024,
        })
        results := flow.Run(ctx, merged)
        return results, nil</span>
}

// pushDown should POST req to the worker’s /pushdown and return a channel that yields SketchInput
// decoded from the worker’s SSE (or chunked JSON) stream. You can keep your existing stub here.
// Implement the HTTP/SSE client and decoding where you wire up workers.
func (q *QuerierService) pushDown(ctx context.Context, worker Worker, request PushDownRequest) (&lt;-chan SketchInput, error) <span class="cov0" title="0">{
        sql := request.BaseExpr.ToWorkerSQL(request.Step)
        if sql == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no SQL generated for expression")
        }</span>

        <span class="cov0" title="0">if IsLocalDev() </span><span class="cov0" title="0">{
                sql = strings.ReplaceAll(sql, "{start}", fmt.Sprintf("%d", 0))
                sql = strings.ReplaceAll(sql, "{end}", fmt.Sprintf("%d", time.Now().UnixMilli()))
                sql = strings.ReplaceAll(sql, "{table}", "read_parquet('./db/*.parquet')")
        }</span> else<span class="cov0" title="0"> {
                sql = strings.ReplaceAll(sql, "{start}", fmt.Sprintf("%d", request.StartTs))
                sql = strings.ReplaceAll(sql, "{end}", fmt.Sprintf("%d", request.EndTs))
                sql = strings.ReplaceAll(sql, "{table}", fmt.Sprintf("'%s'", "worker.ParquetPath"))
        }</span>
        <span class="cov0" title="0">slog.Info("Executing SQL on worker", "sql", sql)

        rows, err := q.ddb.Query(ctx, sql)
        if err != nil </span><span class="cov0" title="0">{
                slog.Error("failed to query worker", "worker", worker, "err", err.Error())
                return nil, fmt.Errorf("failed to query worker %w", err)
        }</span>

        <span class="cov0" title="0">out := make(chan SketchInput, 1024)
        go func() </span><span class="cov0" title="0">{
                defer close(out)
                defer rows.Close()

                cols, err := rows.Columns()
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("failed to get columns", "err", err)
                        return
                }</span>

                <span class="cov0" title="0">for rows.Next() </span><span class="cov0" title="0">{
                        vals := make([]interface{}, len(cols))
                        ptrs := make([]interface{}, len(cols))
                        for i := range vals </span><span class="cov0" title="0">{
                                ptrs[i] = &amp;vals[i]
                        }</span>

                        <span class="cov0" title="0">if err := rows.Scan(ptrs...); err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to scan row", "err", err)
                                continue</span>
                        }

                        <span class="cov0" title="0">var ts int64
                        agg := map[string]float64{}
                        tags := map[string]any{}

                        for i, col := range cols </span><span class="cov0" title="0">{
                                switch col </span>{
                                case "bucket_ts":<span class="cov0" title="0">
                                        switch v := vals[i].(type) </span>{
                                        case int64:<span class="cov0" title="0">
                                                ts = v</span>
                                        case int32:<span class="cov0" title="0">
                                                ts = int64(v)</span>
                                        case int:<span class="cov0" title="0">
                                                ts = int64(v)</span>
                                        default:<span class="cov0" title="0">
                                                slog.Error("unexpected type for bucket_ts", "value", vals[i])
                                                continue</span>
                                        }
                                case SUM, COUNT, MIN, MAX:<span class="cov0" title="0">
                                        if vals[i] == nil </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">switch v := vals[i].(type) </span>{
                                        case float64:<span class="cov0" title="0">
                                                agg[col] = v</span>
                                        case float32:<span class="cov0" title="0">
                                                agg[col] = float64(v)</span>
                                        case int64:<span class="cov0" title="0">
                                                agg[col] = float64(v)</span>
                                        case int32:<span class="cov0" title="0">
                                                agg[col] = float64(v)</span>
                                        case int:<span class="cov0" title="0">
                                                agg[col] = float64(v)</span>
                                        default:<span class="cov0" title="0">
                                                slog.Warn("unexpected numeric type in agg", "col", col, "value", vals[i])</span>
                                        }
                                default:<span class="cov0" title="0">
                                        if vals[i] != nil </span><span class="cov0" title="0">{
                                                tags[col] = vals[i]
                                        }</span>
                                }
                        }

                        <span class="cov0" title="0">slog.Info("making sketch input", "ts", ts)
                        out &lt;- SketchInput{
                                ExprID:         request.BaseExpr.ID,
                                OrganizationID: request.OrganizationID.String(),
                                Timestamp:      ts,
                                Frequency:      int64(request.Step.Seconds()),
                                SketchTags: SketchTags{
                                        Tags:       tags,
                                        SketchType: SketchMAP,
                                        Agg:        agg,
                                },
                        }</span>
                }

                <span class="cov0" title="0">if err := rows.Err(); err != nil </span><span class="cov0" title="0">{
                        slog.Error("row iteration error", "err", err)
                }</span>
        }()

        <span class="cov0" title="0">return out, nil</span>
}

// shiftTimestamps returns a channel that forwards every SketchInput from `in`
// with its Timestamp shifted by +deltaMs. Non-blocking via buffered output.
func shiftTimestamps(ctx context.Context, in &lt;-chan SketchInput, deltaMs int64, outBuf int) &lt;-chan SketchInput <span class="cov0" title="0">{
        out := make(chan SketchInput, outBuf)
        go func() </span><span class="cov0" title="0">{
                defer close(out)
                for </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                return</span>
                        case si, ok := &lt;-in:<span class="cov0" title="0">
                                if !ok </span><span class="cov0" title="0">{
                                        return
                                }</span>
                                <span class="cov0" title="0">si.Timestamp += deltaMs
                                select </span>{
                                case &lt;-ctx.Done():<span class="cov0" title="0">
                                        return</span>
                                case out &lt;- si:<span class="cov0" title="0"></span>
                                }
                        }
                }
        }()
        <span class="cov0" title="0">return out</span>
}

// parseOffsetMs parses a PromQL offset string (e.g., "5m", "1h") into milliseconds.
// Empty strings return 0 with nil error.
func parseOffsetMs(offset string) (int64, error) <span class="cov0" title="0">{
        if offset == "" </span><span class="cov0" title="0">{
                return 0, nil
        }</span>
        <span class="cov0" title="0">d, err := model.ParseDuration(offset)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov0" title="0">return int64(time.Duration(d) / time.Millisecond), nil</span>
}

func (q *QuerierService) lookupSegments(ctx context.Context,
        dih DateIntHours,
        startTs int64, endTs int64,
        stepDuration time.Duration,
        orgUUID uuid.UUID) ([]SegmentInfo, error) <span class="cov0" title="0">{

        var allSegments []SegmentInfo

        if IsLocalDev() </span><span class="cov0" title="0">{
                files, err := os.ReadDir("./db")
                if err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to read local db dir: %w", err)
                }</span>
                <span class="cov0" title="0">for _, f := range files </span><span class="cov0" title="0">{
                        if f.IsDir() || !strings.HasSuffix(f.Name(), ".parquet") </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        <span class="cov0" title="0">allSegments = append(allSegments, SegmentInfo{
                                SegmentID:  f.Name(),
                                StartTs:    startTs,
                                EndTs:      endTs,
                                CustomerID: orgUUID.String(),
                                Frequency:  stepDuration.Milliseconds(),
                        })</span>
                }
                <span class="cov0" title="0">return allSegments, nil</span>
        }

        <span class="cov0" title="0">rows, err := q.mdb.ListSegmentsForQuery(ctx, lrdb.ListSegmentsForQueryParams{
                Int8range:      startTs,
                Int8range_2:    endTs,
                Dateint:        int32(dih.DateInt),
                FrequencyMs:    int32(stepDuration.Milliseconds()),
                OrganizationID: orgUUID,
        })
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">for _, row := range rows </span><span class="cov0" title="0">{
                endHour := zeroFilledHour(time.UnixMilli(row.EndTs).UTC().Hour())
                allSegments = append(allSegments, SegmentInfo{
                        DateInt:     dih.DateInt,
                        Hour:        endHour,
                        SegmentID:   fmt.Sprintf("tbl_%d", row.SegmentID),
                        StartTs:     row.StartTs,
                        EndTs:       row.EndTs,
                        Dataset:     "metrics",
                        BucketName:  "bucket",
                        CustomerID:  orgUUID.String(),
                        CollectorID: "collectorId",
                        Frequency:   stepDuration.Milliseconds(),
                })
        }</span>

        <span class="cov0" title="0">return allSegments, nil</span>
}
</pre>
		
		<pre class="file" id="file118" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "crypto/sha1"
        "encoding/hex"
        "fmt"
        "sort"
        "strings"
        "time"
)

// ---------- Exec nodes &amp; plumbing (planning-time only) ----------

type BaseExpr struct {
        ID           string       `json:"id"`
        Metric       string       `json:"metric,omitempty"`
        Matchers     []LabelMatch `json:"matchers,omitempty"`
        Range        string       `json:"range,omitempty"`
        SubqueryStep string       `json:"subqueryStep,omitempty"`
        Offset       string       `json:"offset,omitempty"`

        // Final result grouping the worker should aggregate to for this leaf
        GroupBy []string `json:"groupBy,omitempty"`
        Without []string `json:"without,omitempty"`

        // Series function intent
        FuncName string `json:"func,omitempty"`

        // Hints
        WantTopK    bool `json:"wantTopK,omitempty"`
        WantBottomK bool `json:"wantBottomK,omitempty"`
        WantCount   bool `json:"wantCount,omitempty"`
        WantDDS     bool `json:"wantDDS,omitempty"`

        // Identity hints for COUNT (what to keep from the parent's "by")
        CountOnBy []string `json:"countOnBy,omitempty"`
        WorkerSQL string   `json:"workerSql,omitempty"`
}

type ExecHints struct {
        WantTopK    bool
        WantBottomK bool
        WantCount   bool
        WantDDS     bool
}

type ExecNode interface {
        Hints() ExecHints
        Eval(sg SketchGroup, step time.Duration) map[string]EvalResult
}

// ---------- Planner ----------

type QueryPlan struct {
        Root   ExecNode
        Leaves []BaseExpr
}

// nearestAggInfo returns info if the expr is *immediately* an Agg node.
func nearestAggInfo(e Expr) (AggOp, []string, []string, bool) <span class="cov8" title="1">{
        if e.Kind == KindAgg &amp;&amp; e.Agg != nil </span><span class="cov8" title="1">{
                return e.Agg.Op, e.Agg.By, e.Agg.Without, true
        }</span>
        <span class="cov8" title="1">return "", nil, nil, false</span>
}

// parentKeep keeps all child identity labels?
func keepsAll(parentKeep, childID []string) bool <span class="cov8" title="1">{
        if len(childID) == 0 </span><span class="cov0" title="0">{
                return true
        }</span>
        <span class="cov8" title="1">keep := map[string]struct{}{}
        for _, k := range parentKeep </span><span class="cov8" title="1">{
                keep[k] = struct{}{}
        }</span>
        <span class="cov8" title="1">for _, id := range childID </span><span class="cov8" title="1">{
                if _, ok := keep[id]; !ok </span><span class="cov8" title="1">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}

func Compile(root Expr) (QueryPlan, error) <span class="cov8" title="1">{
        var leaves []BaseExpr

        type ctx struct {
                rng      *RangeExpr
                funcName string

                // “current” child grouping (identity of the immediate child agg, if any)
                curGroup []string
                curWO    []string

                // final result grouping for this node
                outGroup []string
                outWO    []string

                // COUNT hints (persist until leaf)
                wantCount       bool
                wantDDS         bool
                countParentBy   []string
                countIdentityBy []string
                countIdentityWo []string

                // TOPK/BOTTOMK hints
                wantTopK    bool
                wantBottomK bool
        }

        buildLeaf := func(sel Selector, c ctx) (*LeafNode, BaseExpr) </span><span class="cov8" title="1">{
                be := BaseExpr{
                        Metric:      sel.Metric,
                        Matchers:    append([]LabelMatch(nil), sel.Matchers...),
                        Offset:      sel.Offset,
                        FuncName:    c.funcName,
                        WantTopK:    c.wantTopK,
                        WantBottomK: c.wantBottomK,
                        WantCount:   c.wantCount,
                        WantDDS:     c.wantDDS,
                }
                if c.rng != nil </span><span class="cov8" title="1">{
                        be.Range = c.rng.Range
                        be.SubqueryStep = c.rng.SubqueryStep
                }</span>

                // Default leaf grouping = parent’s desired output grouping
                <span class="cov8" title="1">be.GroupBy = append([]string(nil), c.outGroup...)
                be.Without = append([]string(nil), c.outWO...)

                // COUNT specialization:
                //   - leaf.GroupBy   = child identity (e.g. job,instance)
                //   - leaf.CountOnBy = parent keep-set (e.g. job)
                if c.wantCount </span><span class="cov8" title="1">{
                        if len(c.countIdentityBy) &gt; 0 </span><span class="cov8" title="1">{
                                be.GroupBy = append([]string(nil), c.countIdentityBy...)
                                be.Without = nil
                        }</span> else<span class="cov8" title="1"> if len(c.countIdentityWo) &gt; 0 </span><span class="cov0" title="0">{
                                be.Without = append([]string(nil), c.countIdentityWo...)
                                be.GroupBy = nil
                        }</span>
                        <span class="cov8" title="1">be.CountOnBy = append([]string(nil), c.countParentBy...)</span>
                }

                <span class="cov8" title="1">be.ID = baseExprID(be)
                return &amp;LeafNode{BE: be}, be</span>
        }

        <span class="cov8" title="1">var compile func(e Expr, c ctx) (ExecNode, error)

        compile = func(e Expr, c ctx) (ExecNode, error) </span><span class="cov8" title="1">{
                switch e.Kind </span>{
                case KindSelector:<span class="cov8" title="1">
                        n, be := buildLeaf(*e.Selector, c)
                        leaves = append(leaves, be)
                        return n, nil</span>

                case KindRange:<span class="cov8" title="1">
                        c2 := c
                        c2.rng = e.Range
                        return compile(e.Range.Expr, c2)</span>

                case KindFunc:<span class="cov8" title="1">
                        c2 := c

                        switch e.Func.Name </span>{
                        case "scalar":<span class="cov8" title="1">
                                // scalar(&lt;number&gt;) -&gt; literal scalar
                                if e.Func.ArgQ != nil </span><span class="cov8" title="1">{
                                        return &amp;ScalarNode{Value: *e.Func.ArgQ}, nil
                                }</span>
                                // scalar(expr) -&gt; ScalarOfNode over compiled child
                                <span class="cov8" title="1">if e.Func.Expr != nil </span><span class="cov8" title="1">{
                                        child, err := compile(*e.Func.Expr, c2)
                                        if err != nil </span><span class="cov0" title="0">{
                                                return nil, err
                                        }</span>
                                        <span class="cov8" title="1">return &amp;ScalarOfNode{Child: child}, nil</span>
                                }
                                <span class="cov0" title="0">return nil, fmt.Errorf("scalar() missing argument")</span>

                        case "abs", "ceil", "floor", "exp", "ln", "log2", "log10", "sqrt", "sgn":<span class="cov8" title="1">
                                if e.Func.Expr == nil </span><span class="cov0" title="0">{
                                        return nil, fmt.Errorf("%s() missing argument", e.Func.Name)
                                }</span>
                                <span class="cov8" title="1">child, err := compile(*e.Func.Expr, c2)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, err
                                }</span>
                                <span class="cov8" title="1">return &amp;UnaryNode{Func: e.Func.Name, Child: child}, nil</span>

                        case "quantile_over_time":<span class="cov8" title="1">
                                // Ask workers to return DDSketches for quantiles.
                                c2.funcName = e.Func.Name
                                c2.wantDDS = true
                                if e.Func.Expr == nil </span><span class="cov0" title="0">{
                                        return nil, fmt.Errorf("quantile_over_time requires a range vector")
                                }</span>
                                <span class="cov8" title="1">return compile(*e.Func.Expr, c2)</span>

                        // Series-producing funcs
                        case "rate", "irate", "increase",
                                "sum_over_time", "avg_over_time", "min_over_time", "max_over_time":<span class="cov8" title="1">
                                c2.funcName = e.Func.Name
                                if e.Func.Expr != nil </span><span class="cov8" title="1">{
                                        return compile(*e.Func.Expr, c2)
                                }</span>
                                <span class="cov0" title="0">return nil, fmt.Errorf("%s() missing argument", e.Func.Name)</span>

                        default:<span class="cov0" title="0">
                                // Unknown/unsupported function
                                return nil, fmt.Errorf("unsupported function: %s", e.Func.Name)</span>
                        }

                case KindAgg:<span class="cov8" title="1">
                        c2 := c
                        // Parent output grouping
                        if len(e.Agg.By) &gt; 0 </span><span class="cov8" title="1">{
                                c2.outGroup = e.Agg.By
                                c2.outWO = nil
                        }</span> else<span class="cov8" title="1"> if len(e.Agg.Without) &gt; 0 </span><span class="cov0" title="0">{
                                c2.outWO = e.Agg.Without
                                c2.outGroup = nil
                        }</span>

                        // Peek one level for the child identity (e.g. sum by (job,instance) …)
                        <span class="cov8" title="1">if _, by, wo, ok := nearestAggInfo(e.Agg.Expr); ok </span><span class="cov8" title="1">{
                                if len(by) &gt; 0 </span><span class="cov8" title="1">{
                                        c2.curGroup, c2.curWO = by, nil
                                }</span> else<span class="cov0" title="0"> if len(wo) &gt; 0 </span><span class="cov0" title="0">{
                                        c2.curWO, c2.curGroup = wo, nil
                                }</span>
                        } else<span class="cov8" title="1"> {
                                c2.curGroup, c2.curWO = nil, nil
                        }</span>

                        <span class="cov8" title="1">if e.Agg.Op == AggCount </span><span class="cov8" title="1">{
                                c2.wantCount = true
                                // parent keep-set: from `count by (...)`
                                c2.countParentBy = append([]string(nil), c2.outGroup...)
                                // child identity: from immediate child agg (sum by (job,instance))
                                if len(c2.curGroup) &gt; 0 </span><span class="cov8" title="1">{
                                        c2.countIdentityBy = append([]string(nil), c2.curGroup...)
                                        c2.countIdentityWo = nil
                                }</span> else<span class="cov8" title="1"> if len(c2.curWO) &gt; 0 </span><span class="cov0" title="0">{
                                        c2.countIdentityWo = append([]string(nil), c2.curWO...)
                                        c2.countIdentityBy = nil
                                }</span> else<span class="cov8" title="1"> {
                                        c2.countIdentityBy, c2.countIdentityWo = nil, nil
                                }</span>
                        }

                        <span class="cov8" title="1">child, err := compile(e.Agg.Expr, c2)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">return &amp;AggNode{Op: e.Agg.Op, By: c2.outGroup, Without: c2.outWO, Child: child}, nil</span>

                case KindTopK:<span class="cov8" title="1">
                        c2 := c
                        // Inspect the immediate child for identity
                        var childBy []string
                        if _, by, _, ok := nearestAggInfo(e.TopK.Expr); ok </span><span class="cov8" title="1">{
                                childBy = by
                        }</span>
                        // Parent keep-set (if any)
                        <span class="cov8" title="1">parentKeep := c2.outGroup
                        // If parent drops any child identity label → API-side topk (no worker sketch)
                        if len(parentKeep) &gt; 0 &amp;&amp; len(childBy) &gt; 0 &amp;&amp; !keepsAll(parentKeep, childBy) </span><span class="cov8" title="1">{
                                c2.wantTopK = false
                                child, err := compile(e.TopK.Expr, c2)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, err
                                }</span>
                                <span class="cov8" title="1">return &amp;TopKNode{K: e.TopK.K, Child: child}, nil</span>
                        }
                        // Worker-side topk
                        <span class="cov8" title="1">c2.wantTopK = true
                        child, err := compile(e.TopK.Expr, c2)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">return &amp;TopKNode{K: e.TopK.K, Child: child}, nil</span>

                case KindBottomK:<span class="cov0" title="0">
                        c2 := c
                        // For symmetry; same rule as TopK
                        var childBy []string
                        if _, by, _, ok := nearestAggInfo(e.BottomK.Expr); ok </span><span class="cov0" title="0">{
                                childBy = by
                        }</span>
                        <span class="cov0" title="0">parentKeep := c2.outGroup
                        if len(parentKeep) &gt; 0 &amp;&amp; len(childBy) &gt; 0 &amp;&amp; !keepsAll(parentKeep, childBy) </span><span class="cov0" title="0">{
                                c2.wantBottomK = false
                                child, err := compile(e.BottomK.Expr, c2)
                                if err != nil </span><span class="cov0" title="0">{
                                        return nil, err
                                }</span>
                                <span class="cov0" title="0">return &amp;BottomKNode{K: e.BottomK.K, Child: child}, nil</span>
                        }
                        <span class="cov0" title="0">c2.wantBottomK = true
                        child, err := compile(e.BottomK.Expr, c2)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">return &amp;BottomKNode{K: e.BottomK.K, Child: child}, nil</span>

                case KindHistogramQuantile:<span class="cov8" title="1">
                        c2 := c
                        c2.wantDDS = true
                        child, err := compile(e.HistQuant.Expr, c2)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">return &amp;QuantileNode{Q: e.HistQuant.Q, Child: child}, nil</span>

                case KindClampMin:<span class="cov8" title="1">
                        child, err := compile(e.ClampMin.Expr, c)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">return &amp;ClampMinNode{Min: e.ClampMin.Min, Child: child}, nil</span>

                case KindClampMax:<span class="cov0" title="0">
                        child, err := compile(e.ClampMax.Expr, c)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">return &amp;ClampMaxNode{Max: e.ClampMax.Max, Child: child}, nil</span>

                case KindBinary:<span class="cov8" title="1">
                        lhs, err := compile(e.BinOp.LHS, c)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">rhs, err := compile(e.BinOp.RHS, c)
                        if err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov8" title="1">return &amp;BinaryNode{Op: e.BinOp.Op, LHS: lhs, RHS: rhs, Match: e.BinOp.Match}, nil</span>
                }
                <span class="cov0" title="0">return nil, fmt.Errorf("exec compile: unknown kind %q", e.Kind)</span>
        }

        <span class="cov8" title="1">rootNode, err := compile(root, ctx{})
        if err != nil </span><span class="cov0" title="0">{
                return QueryPlan{}, err
        }</span>
        <span class="cov8" title="1">return QueryPlan{Root: rootNode, Leaves: dedupeBaseExprs(leaves)}, nil</span>
}

// --- helpers ---

func dedupeBaseExprs(in []BaseExpr) []BaseExpr <span class="cov8" title="1">{
        if len(in) &lt;= 1 </span><span class="cov8" title="1">{
                return in
        }</span>
        <span class="cov8" title="1">seen := map[string]BaseExpr{}
        for _, b := range in </span><span class="cov8" title="1">{
                seen[b.ID] = b
        }</span>
        <span class="cov8" title="1">out := make([]BaseExpr, 0, len(seen))
        for _, v := range seen </span><span class="cov8" title="1">{
                out = append(out, v)
        }</span>
        <span class="cov8" title="1">sort.Slice(out, func(i, j int) bool </span><span class="cov8" title="1">{ return out[i].ID &lt; out[j].ID }</span>)
        <span class="cov8" title="1">return out</span>
}

// baseExprID makes a stable content hash to use as an identifier.
func baseExprID(b BaseExpr) string <span class="cov8" title="1">{
        var sb strings.Builder
        sb.WriteString("m=" + b.Metric + ";")
        sb.WriteString("off=" + b.Offset + ";")
        sb.WriteString("rng=" + b.Range + ";")
        sb.WriteString("step=" + b.SubqueryStep + ";")
        sb.WriteString("fn=" + b.FuncName + ";")
        if b.WantTopK </span><span class="cov8" title="1">{
                sb.WriteString("topk=1;")
        }</span>
        <span class="cov8" title="1">if b.WantBottomK </span><span class="cov0" title="0">{
                sb.WriteString("bottomk=1;")
        }</span>
        <span class="cov8" title="1">if b.WantCount </span><span class="cov8" title="1">{
                sb.WriteString("count=1;")
        }</span>
        <span class="cov8" title="1">if b.WantDDS </span><span class="cov8" title="1">{
                sb.WriteString("dds=1;")
        }</span>
        <span class="cov8" title="1">writeCSV := func(tag string, ss []string) </span><span class="cov8" title="1">{
                if len(ss) == 0 </span><span class="cov8" title="1">{
                        return
                }</span>
                <span class="cov8" title="1">cp := append([]string(nil), ss...)
                sort.Strings(cp)
                sb.WriteString(tag)
                sb.WriteString(strings.Join(cp, ","))
                sb.WriteString(";")</span>
        }
        <span class="cov8" title="1">writeCSV("by=", b.GroupBy)
        writeCSV("wo=", b.Without)
        writeCSV("countOnBy=", b.CountOnBy)

        if len(b.Matchers) &gt; 0 </span><span class="cov8" title="1">{
                cp := append([]LabelMatch(nil), b.Matchers...)
                sort.Slice(cp, func(i, j int) bool </span><span class="cov0" title="0">{
                        if cp[i].Label != cp[j].Label </span><span class="cov0" title="0">{
                                return cp[i].Label &lt; cp[j].Label
                        }</span>
                        <span class="cov0" title="0">if cp[i].Op != cp[j].Op </span><span class="cov0" title="0">{
                                return cp[i].Op &lt; cp[j].Op
                        }</span>
                        <span class="cov0" title="0">return cp[i].Value &lt; cp[j].Value</span>
                })
                <span class="cov8" title="1">for _, m := range cp </span><span class="cov8" title="1">{
                        sb.WriteString("lm:")
                        sb.WriteString(m.Label)
                        sb.WriteString(string(m.Op))
                        sb.WriteString(m.Value)
                        sb.WriteString(";")
                }</span>
        }
        <span class="cov8" title="1">sum := sha1.Sum([]byte(sb.String()))
        return hex.EncodeToString(sum[:8])</span>
}
</pre>
		
		<pre class="file" id="file119" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "context"
        "fmt"
        "log/slog"
        "net"
        "os"
        "sort"
        "strconv"
        "sync"
        "time"

        "github.com/cespare/xxhash/v2"
        "github.com/google/uuid"
        discoveryv1 "k8s.io/api/discovery/v1"
        "k8s.io/apimachinery/pkg/labels"
        informers "k8s.io/client-go/informers"
        coreinformers "k8s.io/client-go/informers/core/v1"
        discinformers "k8s.io/client-go/informers/discovery/v1"
        "k8s.io/client-go/kubernetes"
        corelisters "k8s.io/client-go/listers/core/v1"
        disclisters "k8s.io/client-go/listers/discovery/v1"
        "k8s.io/client-go/rest"
        "k8s.io/client-go/tools/cache"
        "k8s.io/client-go/tools/clientcmd"
)

type Worker struct {
        IP   string
        Port int
}

type SegmentWorkerMapping struct {
        SegmentID string
        Worker    Worker
}

type KubernetesWorkerDiscovery struct {
        // config
        namespace           string
        workerLabelSelector string
        workerPort          int

        // clients/caches
        clientset *kubernetes.Clientset
        factory   informers.SharedInformerFactory
        svcInf    coreinformers.ServiceInformer
        esInf     discinformers.EndpointSliceInformer
        svcList   corelisters.ServiceLister
        esList    disclisters.EndpointSliceLister

        // state
        mu         sync.RWMutex
        workers    []Worker
        running    bool
        cancelFunc context.CancelFunc

        // debounce rebuilds
        debounceMu     sync.Mutex
        debounceTimer  *time.Timer
        debounceDelay  time.Duration
        lastRebuildErr error
}

var _ WorkerDiscovery = (*KubernetesWorkerDiscovery)(nil)

type KubernetesWorkerDiscoveryConfig struct {
        Namespace           string // REQUIRED (or via POD_NAMESPACE)
        WorkerLabelSelector string // REQUIRED, selector applied to Services
        WorkerPort          int    // Fallback when no port found on ES/Service; defaults to 8080
        // If true, include IPv6 endpoints as well.
        AllowIPv6 bool
}

func NewKubernetesWorkerDiscovery(cfg KubernetesWorkerDiscoveryConfig) (*KubernetesWorkerDiscovery, error) <span class="cov0" title="0">{
        ns := cfg.Namespace
        if ns == "" </span><span class="cov0" title="0">{
                if v := os.Getenv("POD_NAMESPACE"); v != "" </span><span class="cov0" title="0">{
                        ns = v
                }</span> else<span class="cov0" title="0"> {
                        return nil, fmt.Errorf("namespace is required")
                }</span>
        }
        <span class="cov0" title="0">if cfg.WorkerLabelSelector == "" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("WorkerLabelSelector is required")
        }</span>
        <span class="cov0" title="0">if cfg.WorkerPort == 0 </span><span class="cov0" title="0">{
                cfg.WorkerPort = 8080
        }</span>

        // Prefer in-cluster; fallback to kubeconfig for local dev
        <span class="cov0" title="0">k8sConfig, err := rest.InClusterConfig()
        if err != nil </span><span class="cov0" title="0">{
                if kc, err2 := clientcmd.BuildConfigFromFlags("", clientcmd.RecommendedHomeFile); err2 == nil </span><span class="cov0" title="0">{
                        k8sConfig = kc
                }</span> else<span class="cov0" title="0"> {
                        return nil, fmt.Errorf("k8s config error (in-cluster/kubeconfig): %w / %v", err, err2)
                }</span>
        }
        <span class="cov0" title="0">cs, err := kubernetes.NewForConfig(k8sConfig)
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("create clientset: %w", err)
        }</span>

        <span class="cov0" title="0">factory := informers.NewSharedInformerFactoryWithOptions(
                cs,
                0,
                informers.WithNamespace(ns),
        )

        svcInf := factory.Core().V1().Services()
        esInf := factory.Discovery().V1().EndpointSlices()

        return &amp;KubernetesWorkerDiscovery{
                namespace:           ns,
                workerLabelSelector: cfg.WorkerLabelSelector,
                workerPort:          cfg.WorkerPort,
                clientset:           cs,
                factory:             factory,
                svcInf:              svcInf,
                esInf:               esInf,
                svcList:             svcInf.Lister(),
                esList:              esInf.Lister(),
        }, nil</span>
}

func (k *KubernetesWorkerDiscovery) Start(ctx context.Context) error <span class="cov0" title="0">{
        k.mu.Lock()
        if k.running </span><span class="cov0" title="0">{
                k.mu.Unlock()
                return fmt.Errorf("worker discovery is already running")
        }</span>
        <span class="cov0" title="0">k.running = true
        k.mu.Unlock()

        slog.Info("Starting worker discovery",
                "namespace", k.namespace,
                "svcSelector", k.workerLabelSelector)

        // Event handlers → debounce → rebuild
        handler := cache.ResourceEventHandlerFuncs{
                AddFunc:    func(any) </span><span class="cov0" title="0">{ k.scheduleRebuild() }</span>,
                UpdateFunc: func(any, any) <span class="cov0" title="0">{ k.scheduleRebuild() }</span>,
                DeleteFunc: func(any) <span class="cov0" title="0">{ k.scheduleRebuild() }</span>,
        }
        <span class="cov0" title="0">if _, err := k.svcInf.Informer().AddEventHandler(handler); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to add event handler to service informer: %w", err)
        }</span>
        <span class="cov0" title="0">if _, err := k.esInf.Informer().AddEventHandler(handler); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to add event handler to endpoint informer: %w", err)
        }</span>

        <span class="cov0" title="0">runCtx, cancel := context.WithCancel(ctx)
        k.cancelFunc = cancel

        // Start informers
        go k.factory.Start(runCtx.Done())

        // Wait for caches
        if ok := cache.WaitForCacheSync(
                runCtx.Done(),
                k.svcInf.Informer().HasSynced,
                k.esInf.Informer().HasSynced,
        ); !ok </span><span class="cov0" title="0">{
                if err := k.Stop(); err != nil </span><span class="cov0" title="0">{
                        slog.Error("failed to stop during cache sync failure", "error", err)
                }</span>
                <span class="cov0" title="0">return fmt.Errorf("informer cache sync failed")</span>
        }

        // Initial build
        <span class="cov0" title="0">if err := k.rebuildWorkers(runCtx); err != nil </span><span class="cov0" title="0">{
                slog.Error("initial worker rebuild failed", "error", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

func (k *KubernetesWorkerDiscovery) Stop() error <span class="cov0" title="0">{
        k.mu.Lock()
        defer k.mu.Unlock()
        if !k.running </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">k.running = false
        if k.cancelFunc != nil </span><span class="cov0" title="0">{
                k.cancelFunc()
                k.cancelFunc = nil
        }</span>
        // Stop any pending debounce
        <span class="cov0" title="0">k.debounceMu.Lock()
        if k.debounceTimer != nil </span><span class="cov0" title="0">{
                k.debounceTimer.Stop()
                k.debounceTimer = nil
        }</span>
        <span class="cov0" title="0">k.debounceMu.Unlock()
        return nil</span>
}

func (k *KubernetesWorkerDiscovery) scheduleRebuild() <span class="cov0" title="0">{
        k.debounceMu.Lock()
        defer k.debounceMu.Unlock()
        if k.debounceTimer != nil </span><span class="cov0" title="0">{
                k.debounceTimer.Stop()
        }</span>
        <span class="cov0" title="0">k.debounceTimer = time.AfterFunc(k.debounceDelay, func() </span><span class="cov0" title="0">{
                // Use a bounded context for the rebuild
                ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
                defer cancel()
                if err := k.rebuildWorkers(ctx); err != nil </span><span class="cov0" title="0">{
                        slog.Error("worker rebuild failed", "error", err)
                        k.lastRebuildErr = err
                }</span> else<span class="cov0" title="0"> {
                        k.lastRebuildErr = nil
                }</span>
        })
}

func (k *KubernetesWorkerDiscovery) rebuildWorkers(ctx context.Context) error <span class="cov0" title="0">{
        selector, err := labels.Parse(k.workerLabelSelector)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("invalid label selector %q: %w", k.workerLabelSelector, err)
        }</span>

        <span class="cov0" title="0">svcs, err := k.svcList.Services(k.namespace).List(selector)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("list services (cache): %w", err)
        }</span>

        <span class="cov0" title="0">seen := make(map[string]struct{}, 32)
        out := make([]Worker, 0, 32)

        for _, svc := range svcs </span><span class="cov0" title="0">{
                esSelector := labels.Set{
                        discoveryv1.LabelServiceName: svc.Name,
                }.AsSelector()

                esList, err := k.esList.EndpointSlices(k.namespace).List(esSelector)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("list EndpointSlices (cache)", "service", svc.Name, "error", err)
                        continue</span>
                }

                <span class="cov0" title="0">defPort := k.workerPort
                if len(svc.Spec.Ports) &gt; 0 &amp;&amp; svc.Spec.Ports[0].Port != 0 </span><span class="cov0" title="0">{
                        defPort = int(svc.Spec.Ports[0].Port)
                }</span>

                <span class="cov0" title="0">for _, es := range esList </span><span class="cov0" title="0">{
                        esPort := defPort
                        if len(es.Ports) &gt; 0 &amp;&amp; es.Ports[0].Port != nil </span><span class="cov0" title="0">{
                                esPort = int(*es.Ports[0].Port)
                        }</span>

                        <span class="cov0" title="0">for _, ep := range es.Endpoints </span><span class="cov0" title="0">{
                                ready := ep.Conditions.Ready != nil &amp;&amp; *ep.Conditions.Ready
                                serving := ep.Conditions.Serving == nil || *ep.Conditions.Serving
                                terminating := ep.Conditions.Terminating != nil &amp;&amp; *ep.Conditions.Terminating
                                if !ready || !serving || terminating </span><span class="cov0" title="0">{
                                        continue</span>
                                }

                                <span class="cov0" title="0">for _, addr := range ep.Addresses </span><span class="cov0" title="0">{
                                        ip := net.ParseIP(addr)
                                        if ip == nil || ip.To4() == nil </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">key := addr + ":" + strconv.Itoa(esPort)
                                        if _, ok := seen[key]; ok </span><span class="cov0" title="0">{
                                                continue</span>
                                        }
                                        <span class="cov0" title="0">seen[key] = struct{}{}
                                        out = append(out, Worker{IP: addr, Port: esPort})</span>
                                }
                        }
                }
        }

        <span class="cov0" title="0">sort.Slice(out, func(i, j int) bool </span><span class="cov0" title="0">{
                if out[i].IP == out[j].IP </span><span class="cov0" title="0">{
                        return out[i].Port &lt; out[j].Port
                }</span>
                <span class="cov0" title="0">return out[i].IP &lt; out[j].IP</span>
        })

        <span class="cov0" title="0">k.mu.Lock()
        k.workers = out
        k.mu.Unlock()

        slog.Info("Worker snapshot updated", "namespace", k.namespace, "totalWorkers", len(out))
        return nil</span>
}

func (k *KubernetesWorkerDiscovery) GetWorkersForSegments(organizationID uuid.UUID, segmentIDs []string) ([]SegmentWorkerMapping, error) <span class="cov0" title="0">{
        k.mu.RLock()
        ws := make([]Worker, len(k.workers))
        copy(ws, k.workers)
        k.mu.RUnlock()

        if len(ws) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no workers available")
        }</span>

        <span class="cov0" title="0">mappings := make([]SegmentWorkerMapping, 0, len(segmentIDs))
        for _, seg := range segmentIDs </span><span class="cov0" title="0">{
                w := k.assignSegmentToWorker(organizationID, seg, ws)
                mappings = append(mappings, SegmentWorkerMapping{SegmentID: seg, Worker: w})
        }</span>
        <span class="cov0" title="0">return mappings, nil</span>
}

func (k *KubernetesWorkerDiscovery) GetAllWorkers() ([]Worker, error) <span class="cov0" title="0">{
        k.mu.RLock()
        defer k.mu.RUnlock()
        ws := make([]Worker, len(k.workers))
        copy(ws, k.workers)
        return ws, nil
}</span>

func (k *KubernetesWorkerDiscovery) assignSegmentToWorker(org uuid.UUID, seg string, ws []Worker) Worker <span class="cov0" title="0">{
        if len(ws) == 0 </span><span class="cov0" title="0">{
                return Worker{}
        }</span>
        <span class="cov0" title="0">segKey := org.String() + ":" + seg

        var best Worker
        var bestHash uint64
        for i, w := range ws </span><span class="cov0" title="0">{
                wk := w.IP + ":" + strconv.Itoa(w.Port)
                hv := xxhash.Sum64String(segKey + wk)
                if i == 0 || hv &gt; bestHash </span><span class="cov0" title="0">{
                        best, bestHash = w, hv
                }</span>
        }
        <span class="cov0" title="0">return best</span>
}
</pre>
		
		<pre class="file" id="file120" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "fmt"
        "log/slog"
        "math"
        "strings"
        "time"

        "github.com/DataDog/sketches-go/ddsketch"
        "github.com/DataDog/sketches-go/ddsketch/pb/sketchpb"
        "github.com/axiomhq/hyperloglog"
        "github.com/gogo/protobuf/proto"
        "github.com/prometheus/common/model"
)

// LeafNode corresponds to one BaseExpr pushdown (one worker stream).
type LeafNode struct {
        BE BaseExpr
}

func (n *LeafNode) Hints() ExecHints <span class="cov0" title="0">{
        return ExecHints{
                WantTopK:    n.BE.WantTopK,
                WantBottomK: n.BE.WantBottomK,
                WantCount:   n.BE.WantCount,
                WantDDS:     n.BE.WantDDS,
        }
}</span>

func (n *LeafNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        rows := sg.Group[n.BE.ID]
        if len(rows) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        <span class="cov0" title="0">keyFor := func(tags map[string]any) string </span><span class="cov0" title="0">{
                if len(n.BE.GroupBy) == 0 </span><span class="cov0" title="0">{
                        return "default"
                }</span>
                <span class="cov0" title="0">parts := make([]string, 0, len(n.BE.GroupBy))
                for _, lbl := range n.BE.GroupBy </span><span class="cov0" title="0">{
                        if v, ok := tags[lbl]; ok </span><span class="cov0" title="0">{
                                parts = append(parts, fmt.Sprintf("%s=%v", lbl, v))
                        }</span>
                }
                <span class="cov0" title="0">if len(parts) == 0 </span><span class="cov0" title="0">{
                        return "default"
                }</span>
                <span class="cov0" title="0">return strings.Join(parts, ",")</span>
        }

        <span class="cov0" title="0">out := make(map[string]EvalResult, len(rows))
        for _, si := range rows </span><span class="cov0" title="0">{
                var v Value

                switch si.SketchTags.SketchType </span>{
                case SketchHLL:<span class="cov0" title="0">
                        if len(si.SketchTags.Bytes) == 0 </span><span class="cov0" title="0">{
                                v = Value{Kind: ValScalar, Num: math.NaN()}
                                break</span>
                        }
                        <span class="cov0" title="0">var h hyperloglog.Sketch
                        if err := h.UnmarshalBinary(si.SketchTags.Bytes); err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to unmarshal HLL sketch", "error", err)
                                v = Value{Kind: ValScalar, Num: math.NaN()}
                                break</span>
                        }
                        <span class="cov0" title="0">v = Value{Kind: ValHLL, HLL: &amp;h}</span>

                case SketchDDS:<span class="cov0" title="0">
                        if len(si.SketchTags.Bytes) == 0 </span><span class="cov0" title="0">{
                                v = Value{Kind: ValScalar, Num: math.NaN()}
                                break</span>
                        }
                        <span class="cov0" title="0">var pb sketchpb.DDSketch
                        if err := proto.Unmarshal(si.SketchTags.Bytes, &amp;pb); err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to unmarshal DDSketch proto", "error", err)
                                v = Value{Kind: ValScalar, Num: math.NaN()}
                                break</span>
                        }
                        <span class="cov0" title="0">sk, err := ddsketch.FromProto(&amp;pb)
                        if err != nil </span><span class="cov0" title="0">{
                                slog.Error("failed to build DDSketch from proto", "error", err)
                                v = Value{Kind: ValScalar, Num: math.NaN()}
                                break</span>
                        }
                        <span class="cov0" title="0">v = Value{Kind: ValDDS, DDS: sk}</span>

                case SketchMAP:<span class="cov0" title="0">
                        secs := step.Seconds()
                        v = Value{Kind: ValScalar, Num: evalLeafValueWithSecs(n.BE, si, secs)}</span>

                default:<span class="cov0" title="0">
                        // Unknown sketch type
                        v = Value{Kind: ValScalar, Num: math.NaN()}</span>
                }

                <span class="cov0" title="0">k := keyFor(si.SketchTags.Tags)
                out[k] = EvalResult{
                        Timestamp: si.Timestamp,
                        Value:     v,
                        Tags:      si.SketchTags.Tags,
                }</span>
        }
        <span class="cov0" title="0">return out</span>
}

func rangeSeconds(be BaseExpr, stepSecs float64) float64 <span class="cov0" title="0">{
        if be.Range == "" </span><span class="cov0" title="0">{
                return stepSecs
        }</span>
        <span class="cov0" title="0">d, err := model.ParseDuration(be.Range) // or your own parser
        if err != nil </span><span class="cov0" title="0">{
                return math.NaN()
        }</span>
        <span class="cov0" title="0">return time.Duration(d).Seconds()</span>
}

// Same as your evalLeafValue but pass secs to avoid recomputing per-row.
func evalLeafValueWithSecs(be BaseExpr, in SketchInput, secs float64) float64 <span class="cov0" title="0">{
        if in.SketchTags.SketchType != SketchMAP </span><span class="cov0" title="0">{
                return math.NaN()
        }</span>
        <span class="cov0" title="0">if be.WantCount </span><span class="cov0" title="0">{
                return in.SketchTags.getAggValue(COUNT)
        }</span>
        <span class="cov0" title="0">rngSecs := rangeSeconds(be, secs)
        switch be.FuncName </span>{
        case "rate":<span class="cov0" title="0">
                if secs &lt;= 0 </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">return in.SketchTags.getAggValue(SUM) / rngSecs</span>
        case "increase", "sum_over_time", "":<span class="cov0" title="0">
                return in.SketchTags.getAggValue(SUM)</span>
        case "avg_over_time":<span class="cov0" title="0">
                sum := in.SketchTags.getAggValue(SUM)
                cnt := in.SketchTags.getAggValue(COUNT)
                if cnt == 0 </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">return sum / cnt</span>
        case "min_over_time":<span class="cov0" title="0">
                return in.SketchTags.getAggValue(MIN)</span>
        case "max_over_time":<span class="cov0" title="0">
                return in.SketchTags.getAggValue(MAX)</span>
        default:<span class="cov0" title="0">
                return math.NaN()</span>
        }
}
</pre>
		
		<pre class="file" id="file121" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "context"
        "log/slog"

        "github.com/google/uuid"
)

type LocalDevDiscovery struct {
}

func NewLocalDevDiscovery() *LocalDevDiscovery <span class="cov0" title="0">{
        return &amp;LocalDevDiscovery{}
}</span>

func (d *LocalDevDiscovery) Start(ctx context.Context) error <span class="cov0" title="0">{
        slog.Info("LocalDevDiscovery started")
        return nil
}</span>

func (d *LocalDevDiscovery) Stop() error <span class="cov0" title="0">{
        slog.Info("LocalDevDiscovery stopped")
        return nil
}</span>

func (d *LocalDevDiscovery) GetWorkersForSegments(organizationID uuid.UUID, segmentIDs []string) ([]SegmentWorkerMapping, error) <span class="cov0" title="0">{
        mappings := make([]SegmentWorkerMapping, len(segmentIDs))
        for i, segmentID := range segmentIDs </span><span class="cov0" title="0">{
                mappings[i] = SegmentWorkerMapping{
                        SegmentID: segmentID,
                        Worker: Worker{
                                IP:   "127.0.0.1",
                                Port: 8080,
                        },
                }
        }</span>
        <span class="cov0" title="0">return mappings, nil</span>
}

func (d *LocalDevDiscovery) GetAllWorkers() ([]Worker, error) <span class="cov0" title="0">{

        return []Worker{
                {
                        IP:   "127.0.0.1",
                        Port: 8080,
                },
        }, nil
}</span>
</pre>
		
		<pre class="file" id="file122" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "fmt"
        "time"

        "github.com/prometheus/common/model"
        "github.com/prometheus/prometheus/model/labels"
        promparser "github.com/prometheus/prometheus/promql/parser"
)

//
// ------------------------- AST TYPES -------------------------
//`

type Expr struct {
        Kind      ExprKind           `json:"kind"`
        Selector  *Selector          `json:"selector,omitempty"`
        Range     *RangeExpr         `json:"range,omitempty"`
        Func      *FuncCall          `json:"func,omitempty"`
        Agg       *AggExpr           `json:"agg,omitempty"`
        TopK      *TopKExpr          `json:"topk,omitempty"`
        BottomK   *TopKExpr          `json:"bottomk,omitempty"`
        BinOp     *BinaryExpr        `json:"binop,omitempty"`
        HistQuant *HistogramQuantile `json:"histogramQuantile,omitempty"`
        ClampMin  *ClampMinExpr      `json:"clampMin,omitempty"`
        ClampMax  *ClampMaxExpr      `json:"clampMax,omitempty"` // NEW
}

type ExprKind string

const (
        KindSelector          ExprKind = "selector"
        KindRange             ExprKind = "range"
        KindFunc              ExprKind = "func"
        KindAgg               ExprKind = "agg"
        KindTopK              ExprKind = "topk"
        KindBottomK           ExprKind = "bottomk"
        KindBinary            ExprKind = "binary"
        KindHistogramQuantile ExprKind = "histogram_quantile"
        KindClampMin          ExprKind = "clamp_min"
        KindClampMax          ExprKind = "clamp_max" // NEW
)

// Selector Leaf: metric selector
type Selector struct {
        Metric   string       `json:"metric,omitempty"`
        Matchers []LabelMatch `json:"matchers,omitempty"`
        Offset   string       `json:"offset,omitempty"` // e.g. "5m"
}

type LabelMatch struct {
        Label string  `json:"label"`
        Op    MatchOp `json:"op"` // =, !=, =~, !~
        Value string  `json:"value"`
}

type MatchOp string

const (
        MatchEq  MatchOp = "="
        MatchNe  MatchOp = "!="
        MatchRe  MatchOp = "=~"
        MatchNre MatchOp = "!~"
)

// RangeExpr Range wrapper
type RangeExpr struct {
        Expr         Expr   `json:"expr"`                   // inner instant expr
        Range        string `json:"range"`                  // e.g. "5m"
        SubqueryStep string `json:"subqueryStep,omitempty"` // optional "[range:step]"
}

// FuncCall Functions
type FuncCall struct {
        // Name: "rate" | "irate" | "increase" | "..._over_time" | "scalar"
        // Plus unary math: "abs","ceil","floor","exp","ln","log2","log10","sqrt","sgn"
        Name string   `json:"name"`
        ArgQ *float64 `json:"q,omitempty"`    // for quantile_over_time or scalar(number)
        Expr *Expr    `json:"expr,omitempty"` // for rate/over_time/scalar(expr)/unary math
}

// AggExpr Aggregations
type AggExpr struct {
        Op      AggOp    `json:"op"` // sum|avg|min|max|count
        Expr    Expr     `json:"expr"`
        By      []string `json:"by,omitempty"` // mutually exclusive with Without
        Without []string `json:"without,omitempty"`
}

type AggOp string

const (
        AggSum   AggOp = "sum"
        AggAvg   AggOp = "avg"
        AggMin   AggOp = "min"
        AggMax   AggOp = "max"
        AggCount AggOp = "count"
)

// TopKExpr Top/Bottom K
type TopKExpr struct {
        K    int  `json:"k"`
        Expr Expr `json:"expr"`
}

// BinaryExpr Arithmetic (MVP: + - * /)
type BinaryExpr struct {
        Op    BinOp        `json:"op"`
        LHS   Expr         `json:"lhs"`
        RHS   Expr         `json:"rhs"`
        Match *VectorMatch `json:"match,omitempty"` // optional: on()/ignoring(), group_left/right
}

type BinOp string

const (
        OpAdd BinOp = "+"
        OpSub BinOp = "-"
        OpMul BinOp = "*"
        OpDiv BinOp = "/"
)

type VectorMatch struct {
        On       []string `json:"on,omitempty"`
        Ignoring []string `json:"ignoring,omitempty"`
        Group    string   `json:"group,omitempty"`  // "", "left", "right"
        Labels   []string `json:"labels,omitempty"` // for group_left/right
}

// HistogramQuantile Histogram quantile
type HistogramQuantile struct {
        Q    float64 `json:"q"`
        Expr Expr    `json:"expr"` // usually sum by (le,...)(rate(&lt;metric&gt;_bucket[...]))
}

// ClampMinExpr ClampMin
type ClampMinExpr struct {
        Min  float64 `json:"min"`
        Expr Expr    `json:"expr"`
}

// ClampMaxExpr ClampMax (NEW)
type ClampMaxExpr struct {
        Max  float64 `json:"max"`
        Expr Expr    `json:"expr"`
}

//
// ------------------------- TRANSPILER -------------------------
//

func FromPromQL(q string) (Expr, error) <span class="cov8" title="1">{
        expr, err := promparser.ParseExpr(q)
        if err != nil </span><span class="cov0" title="0">{
                return Expr{}, err
        }</span>
        <span class="cov8" title="1">return fromNode(expr)</span>
}

func fromNode(n promparser.Node) (Expr, error) <span class="cov8" title="1">{
        switch v := n.(type) </span>{

        case *promparser.VectorSelector:<span class="cov8" title="1">
                return Expr{
                        Kind: KindSelector,
                        Selector: &amp;Selector{
                                Metric:   v.Name,
                                Matchers: toMatchers(v.LabelMatchers),
                                Offset:   promDur(v.OriginalOffset),
                        },
                }, nil</span>

        case *promparser.MatrixSelector:<span class="cov8" title="1">
                vs := v.VectorSelector.(*promparser.VectorSelector)
                inner := Expr{
                        Kind: KindSelector,
                        Selector: &amp;Selector{
                                Metric:   vs.Name,
                                Matchers: toMatchers(vs.LabelMatchers),
                                Offset:   promDur(vs.OriginalOffset),
                        },
                }
                return Expr{
                        Kind: KindRange,
                        Range: &amp;RangeExpr{
                                Expr:  inner,
                                Range: promDur(v.Range),
                        },
                }, nil</span>

        case *promparser.SubqueryExpr:<span class="cov8" title="1">
                inner, err := fromNode(v.Expr)
                if err != nil </span><span class="cov0" title="0">{
                        return Expr{}, err
                }</span>
                <span class="cov8" title="1">r := RangeExpr{
                        Expr:  inner,
                        Range: promDur(v.Range),
                }
                if v.Step &gt; 0 </span><span class="cov8" title="1">{
                        r.SubqueryStep = promDur(v.Step)
                }</span>
                <span class="cov8" title="1">return Expr{Kind: KindRange, Range: &amp;r}, nil</span>

        case *promparser.Call:<span class="cov8" title="1">
                fn := v.Func.Name

                // topk / bottomk
                if fn == "topk" || fn == "bottomk" </span><span class="cov0" title="0">{
                        if len(v.Args) != 2 </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported(fn+" arity", "")
                        }</span>
                        <span class="cov0" title="0">kn, ok := v.Args[0].(*promparser.NumberLiteral)
                        if !ok </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported(fn+" k", "non-number k")
                        }</span>
                        <span class="cov0" title="0">inner, err := fromNode(v.Args[1])
                        if err != nil </span><span class="cov0" title="0">{
                                return Expr{}, err
                        }</span>
                        <span class="cov0" title="0">k := int(kn.Val)
                        if fn == "topk" </span><span class="cov0" title="0">{
                                return Expr{Kind: KindTopK, TopK: &amp;TopKExpr{K: k, Expr: inner}}, nil
                        }</span>
                        <span class="cov0" title="0">return Expr{Kind: KindBottomK, BottomK: &amp;TopKExpr{K: k, Expr: inner}}, nil</span>
                }

                // histogram_quantile(q, expr)
                <span class="cov8" title="1">if fn == "histogram_quantile" </span><span class="cov8" title="1">{
                        if len(v.Args) != 2 </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("histogram_quantile arity", "")
                        }</span>
                        <span class="cov8" title="1">qsc, ok := v.Args[0].(*promparser.NumberLiteral)
                        if !ok </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("histogram_quantile q", "")
                        }</span>
                        <span class="cov8" title="1">inner, err := fromNode(v.Args[1])
                        if err != nil </span><span class="cov0" title="0">{
                                return Expr{}, err
                        }</span>
                        <span class="cov8" title="1">return Expr{
                                Kind:      KindHistogramQuantile,
                                HistQuant: &amp;HistogramQuantile{Q: qsc.Val, Expr: inner},
                        }, nil</span>
                }

                // clamp_min(expr, min)
                <span class="cov8" title="1">if fn == "clamp_min" </span><span class="cov8" title="1">{
                        if len(v.Args) != 2 </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("clamp_min arity", "")
                        }</span>
                        <span class="cov8" title="1">x, err := fromNode(v.Args[0])
                        if err != nil </span><span class="cov0" title="0">{
                                return Expr{}, err
                        }</span>
                        <span class="cov8" title="1">minNum, ok := v.Args[1].(*promparser.NumberLiteral)
                        if !ok </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("clamp_min min (must be scalar)", "")
                        }</span>
                        <span class="cov8" title="1">return Expr{
                                Kind:     KindClampMin,
                                ClampMin: &amp;ClampMinExpr{Min: minNum.Val, Expr: x},
                        }, nil</span>
                }

                // clamp_max(expr, max)  (NEW)
                <span class="cov8" title="1">if fn == "clamp_max" </span><span class="cov0" title="0">{
                        if len(v.Args) != 2 </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("clamp_max arity", "")
                        }</span>
                        <span class="cov0" title="0">x, err := fromNode(v.Args[0])
                        if err != nil </span><span class="cov0" title="0">{
                                return Expr{}, err
                        }</span>
                        <span class="cov0" title="0">maxNum, ok := v.Args[1].(*promparser.NumberLiteral)
                        if !ok </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("clamp_max max (must be scalar)", "")
                        }</span>
                        <span class="cov0" title="0">return Expr{
                                Kind:     KindClampMax,
                                ClampMax: &amp;ClampMaxExpr{Max: maxNum.Val, Expr: x},
                        }, nil</span>
                }

                // scalar(...) (PromQL function)
                <span class="cov8" title="1">if fn == "scalar" </span><span class="cov8" title="1">{
                        if len(v.Args) != 1 </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("scalar arity", "")
                        }</span>
                        // If argument is a number literal, encode as scalar-number
                        <span class="cov8" title="1">if num, ok := v.Args[0].(*promparser.NumberLiteral); ok </span><span class="cov0" title="0">{
                                q := num.Val
                                return Expr{
                                        Kind: KindFunc,
                                        Func: &amp;FuncCall{Name: "scalar", ArgQ: &amp;q},
                                }, nil
                        }</span>
                        <span class="cov8" title="1">inner, err := fromNode(v.Args[0])
                        if err != nil </span><span class="cov0" title="0">{
                                return Expr{}, err
                        }</span>
                        <span class="cov8" title="1">return Expr{
                                Kind: KindFunc,
                                Func: &amp;FuncCall{Name: "scalar", Expr: &amp;inner},
                        }, nil</span>
                }

                // Unary math functions: abs, ceil, floor, exp, ln, log2, log10, sqrt, sgn
                <span class="cov8" title="1">switch fn </span>{
                case "abs", "ceil", "floor", "exp", "ln", "log2", "log10", "sqrt", "sgn":<span class="cov8" title="1">
                        if len(v.Args) != 1 </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported(fn+" arity", "")
                        }</span>
                        <span class="cov8" title="1">argExpr, err := fromNode(v.Args[0])
                        if err != nil </span><span class="cov0" title="0">{
                                return Expr{}, err
                        }</span>
                        <span class="cov8" title="1">return Expr{
                                Kind: KindFunc,
                                Func: &amp;FuncCall{Name: fn, Expr: &amp;argExpr},
                        }, nil</span>
                }

                // rate/irate/increase and *_over_time
                <span class="cov8" title="1">switch fn </span>{
                case "rate", "irate", "increase",
                        "sum_over_time", "avg_over_time", "min_over_time", "max_over_time", "quantile_over_time":<span class="cov8" title="1">
                        var qptr *float64
                        var argExpr Expr
                        if fn == "quantile_over_time" </span><span class="cov8" title="1">{
                                if len(v.Args) != 2 </span><span class="cov0" title="0">{
                                        return Expr{}, errUnsupported("quantile_over_time arity", "")
                                }</span>
                                <span class="cov8" title="1">qsc, ok := v.Args[0].(*promparser.NumberLiteral)
                                if !ok </span><span class="cov0" title="0">{
                                        return Expr{}, errUnsupported("quantile_over_time q", "")
                                }</span>
                                <span class="cov8" title="1">qptr = &amp;qsc.Val
                                var err error
                                argExpr, err = fromNode(v.Args[1])
                                if err != nil </span><span class="cov0" title="0">{
                                        return Expr{}, err
                                }</span>
                        } else<span class="cov8" title="1"> {
                                if len(v.Args) != 1 </span><span class="cov0" title="0">{
                                        return Expr{}, errUnsupported("function arity", fn)
                                }</span>
                                <span class="cov8" title="1">var err error
                                argExpr, err = fromNode(v.Args[0])
                                if err != nil </span><span class="cov0" title="0">{
                                        return Expr{}, err
                                }</span>
                        }
                        <span class="cov8" title="1">return Expr{
                                Kind: KindFunc,
                                Func: &amp;FuncCall{Name: fn, ArgQ: qptr, Expr: &amp;argExpr},
                        }, nil</span>
                default:<span class="cov0" title="0">
                        return Expr{}, errUnsupported("function", fn)</span>
                }

        case *promparser.AggregateExpr:<span class="cov8" title="1">
                inner, err := fromNode(v.Expr)
                if err != nil </span><span class="cov0" title="0">{
                        return Expr{}, err
                }</span>

                // Handle topk/bottomk which are AggregateExpr with a Param (k)
                <span class="cov8" title="1">switch v.Op </span>{
                case promparser.TOPK, promparser.BOTTOMK:<span class="cov8" title="1">
                        if v.Param == nil </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("topk/bottomk k", "missing param")
                        }</span>
                        <span class="cov8" title="1">num, ok := v.Param.(*promparser.NumberLiteral)
                        if !ok </span><span class="cov0" title="0">{
                                return Expr{}, errUnsupported("topk/bottomk k", "non-number k")
                        }</span>
                        <span class="cov8" title="1">k := int(num.Val)
                        if v.Op == promparser.TOPK </span><span class="cov8" title="1">{
                                return Expr{Kind: KindTopK, TopK: &amp;TopKExpr{K: k, Expr: inner}}, nil
                        }</span>
                        <span class="cov8" title="1">return Expr{Kind: KindBottomK, BottomK: &amp;TopKExpr{K: k, Expr: inner}}, nil</span>
                }

                // Regular aggregations (sum/avg/min/max/count) with by/without
                <span class="cov8" title="1">a := AggExpr{
                        Op:   toAggOp(v.Op),
                        Expr: inner,
                }
                if v.Without </span><span class="cov0" title="0">{
                        a.Without = v.Grouping
                }</span> else<span class="cov8" title="1"> if len(v.Grouping) &gt; 0 </span><span class="cov8" title="1">{
                        a.By = v.Grouping
                }</span>
                <span class="cov8" title="1">return Expr{Kind: KindAgg, Agg: &amp;a}, nil</span>

        case *promparser.BinaryExpr:<span class="cov8" title="1">
                lhs, err := fromNode(v.LHS)
                if err != nil </span><span class="cov0" title="0">{
                        return Expr{}, err
                }</span>
                <span class="cov8" title="1">rhs, err := fromNode(v.RHS)
                if err != nil </span><span class="cov0" title="0">{
                        return Expr{}, err
                }</span>
                <span class="cov8" title="1">be := BinaryExpr{
                        Op:  toBinOp(v.Op),
                        LHS: lhs, RHS: rhs,
                }
                if v.VectorMatching != nil </span><span class="cov8" title="1">{
                        m := &amp;VectorMatch{}
                        if v.VectorMatching.On </span><span class="cov0" title="0">{
                                m.On = v.VectorMatching.MatchingLabels
                        }</span> else<span class="cov8" title="1"> {
                                m.Ignoring = v.VectorMatching.MatchingLabels
                        }</span>
                        <span class="cov8" title="1">switch v.VectorMatching.Card </span>{
                        case promparser.CardManyToOne:<span class="cov0" title="0">
                                m.Group = "left"
                                m.Labels = v.VectorMatching.Include</span>
                        case promparser.CardOneToMany:<span class="cov0" title="0">
                                m.Group = "right"
                                m.Labels = v.VectorMatching.Include</span>
                        default:<span class="cov8" title="1"></span>
                        }
                        <span class="cov8" title="1">be.Match = m</span>
                }
                <span class="cov8" title="1">return Expr{Kind: KindBinary, BinOp: &amp;be}, nil</span>

        case *promparser.ParenExpr:<span class="cov8" title="1">
                return fromNode(v.Expr)</span>

        case *promparser.NumberLiteral:<span class="cov8" title="1">
                val := v.Val
                return Expr{
                        Kind: KindFunc,
                        Func: &amp;FuncCall{Name: "scalar", ArgQ: &amp;val},
                }, nil</span>

        default:<span class="cov0" title="0">
                return Expr{}, errUnsupported("node", fmt.Sprintf("%T", n))</span>
        }
}

// promDur formats time.Duration like PromQL ("1m", "5m", "2h5m") and returns "" if zero.
func promDur(d time.Duration) string <span class="cov8" title="1">{
        if d == 0 </span><span class="cov8" title="1">{
                return ""
        }</span>
        <span class="cov8" title="1">return model.Duration(d).String()</span>
}

// Strip the synthetic __name__ matcher the parser adds when a metric name is present.
func toMatchers(ms []*labels.Matcher) []LabelMatch <span class="cov8" title="1">{
        out := make([]LabelMatch, 0, len(ms))
        for _, m := range ms </span><span class="cov8" title="1">{
                if m == nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">if m.Name == "__name__" </span><span class="cov8" title="1">{
                        // Skip; Selector.Metric already carries the metric name.
                        continue</span>
                }
                <span class="cov8" title="1">out = append(out, LabelMatch{
                        Label: m.Name,
                        Op:    toMatchOp(m.Type),
                        Value: m.Value,
                })</span>
        }
        <span class="cov8" title="1">return out</span>
}

func toMatchOp(t labels.MatchType) MatchOp <span class="cov8" title="1">{
        switch t </span>{
        case labels.MatchEqual:<span class="cov8" title="1">
                return MatchEq</span>
        case labels.MatchNotEqual:<span class="cov0" title="0">
                return MatchNe</span>
        case labels.MatchRegexp:<span class="cov8" title="1">
                return MatchRe</span>
        case labels.MatchNotRegexp:<span class="cov0" title="0">
                return MatchNre</span>
        default:<span class="cov0" title="0">
                return MatchEq</span>
        }
}

func toAggOp(op promparser.ItemType) AggOp <span class="cov8" title="1">{
        switch op </span>{
        case promparser.SUM:<span class="cov8" title="1">
                return AggSum</span>
        case promparser.AVG:<span class="cov0" title="0">
                return AggAvg</span>
        case promparser.MIN:<span class="cov0" title="0">
                return AggMin</span>
        case promparser.MAX:<span class="cov0" title="0">
                return AggMax</span>
        case promparser.COUNT:<span class="cov8" title="1">
                return AggCount</span>
        default:<span class="cov0" title="0">
                return AggSum</span>
        }
}

func toBinOp(op promparser.ItemType) BinOp <span class="cov8" title="1">{
        switch op </span>{
        case promparser.ADD:<span class="cov0" title="0">
                return OpAdd</span>
        case promparser.SUB:<span class="cov0" title="0">
                return OpSub</span>
        case promparser.MUL:<span class="cov8" title="1">
                return OpMul</span>
        case promparser.DIV:<span class="cov8" title="1">
                return OpDiv</span>
        default:<span class="cov0" title="0">
                return OpAdd</span>
        }
}

type unsupportedError struct{ what, name string }

func (e unsupportedError) Error() string <span class="cov0" title="0">{ return "unsupported " + e.what + ": " + e.name }</span>

func errUnsupported(what, name string) error <span class="cov0" title="0">{ return unsupportedError{what, name} }</span>
</pre>
		
		<pre class="file" id="file123" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "time"

        "log/slog"

        "github.com/DataDog/sketches-go/ddsketch"
)

// QuantileNode computes value-at-quantile from DDSketch child (e.g. histogram_quantile).
type QuantileNode struct {
        Q     float64 // 0..1
        Child ExecNode
}

func (n *QuantileNode) Hints() ExecHints <span class="cov0" title="0">{ return n.Child.Hints() }</span>

func (n *QuantileNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        child := n.Child.Eval(sg, step)
        if len(child) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        // Clamp quantile to [0,1]
        <span class="cov0" title="0">q := n.Q
        if q &lt; 0 </span><span class="cov0" title="0">{
                q = 0
        }</span> else<span class="cov0" title="0"> if q &gt; 1 </span><span class="cov0" title="0">{
                q = 1
        }</span>

        // Accumulate DDSketches per child key (grouping is unchanged at this node).
        <span class="cov0" title="0">type acc struct {
                sk   *ddsketch.DDSketch
                tags map[string]any
                ts   int64
        }
        accs := make(map[string]*acc, len(child))

        hasDDS := false
        for k, r := range child </span><span class="cov0" title="0">{
                if r.Value.Kind != ValDDS || r.Value.DDS == nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">hasDDS = true
                a := accs[k]
                if a == nil </span><span class="cov0" title="0">{
                        // Use the first incoming sketch as accumulator.
                        // (Optionally deep-copy if you prefer immutability.)
                        accs[k] = &amp;acc{
                                sk:   r.Value.DDS,
                                tags: r.Tags,
                                ts:   r.Timestamp,
                        }
                        continue</span>
                }
                // Merge subsequent sketches for this key.
                <span class="cov0" title="0">if err := a.sk.MergeWith(r.Value.DDS); err != nil </span><span class="cov0" title="0">{
                        slog.Error("ddsketch merge failed", "err", err)
                }</span>
        }

        // If no DDS were found, return NaNs for each key (quantile undefined).
        <span class="cov0" title="0">if !hasDDS </span><span class="cov0" title="0">{
                out := make(map[string]EvalResult, len(child))
                for k, r := range child </span><span class="cov0" title="0">{
                        out[k] = EvalResult{
                                Timestamp: r.Timestamp,
                                Tags:      r.Tags,
                                Value: Value{
                                        Kind: ValScalar,
                                        Num:  math.NaN(),
                                },
                        }
                }</span>
                <span class="cov0" title="0">return out</span>
        }

        // Compute quantile for each key and emit scalars.
        <span class="cov0" title="0">out := make(map[string]EvalResult, len(accs))
        for k, a := range accs </span><span class="cov0" title="0">{
                val, err := a.sk.GetValueAtQuantile(q)
                if err != nil </span><span class="cov0" title="0">{
                        slog.Error("ddsketch quantile failed", "q", q, "err", err)
                        val = math.NaN()
                }</span>
                <span class="cov0" title="0">out[k] = EvalResult{
                        Timestamp: a.ts,
                        Tags:      a.tags,
                        Value: Value{
                                Kind: ValScalar, // quantile result is a scalar
                                Num:  val,
                        },
                }</span>
        }
        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file124" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "context"
        "encoding/json"
        "errors"
        "fmt"
        "log/slog"
        "net/http"

        "github.com/cardinalhq/oteltools/pkg/dateutils"
        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/internal/duckdbx"
        "github.com/cardinalhq/lakerunner/lrdb"
)

type QuerierService struct {
        mdb             lrdb.StoreFull
        ddb             *duckdbx.DB
        workerDiscovery WorkerDiscovery
}

// NewQuerierService creates a new QuerierService with the given database store and worker discovery.
func NewQuerierService(mdb lrdb.StoreFull, workerDiscovery WorkerDiscovery) (*QuerierService, error) <span class="cov0" title="0">{
        ddb, err := duckdbx.Open("",
                duckdbx.WithMemoryLimitMB(2048),
                duckdbx.WithExtension("httpfs", ""),
        )
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>
        <span class="cov0" title="0">return &amp;QuerierService{
                mdb:             mdb,
                ddb:             ddb,
                workerDiscovery: workerDiscovery,
        }, nil</span>
}

func (q *QuerierService) ServeHTTP(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        orgID := r.URL.Query().Get("orgId")
        if orgID == "" </span><span class="cov0" title="0">{
                http.Error(w, "missing orgId", http.StatusBadRequest)
                return
        }</span>
        <span class="cov0" title="0">s := r.URL.Query().Get("s")
        e := r.URL.Query().Get("e")
        if s == "" || e == "" </span><span class="cov0" title="0">{
                http.Error(w, "missing s/e", http.StatusBadRequest)
                return
        }</span>

        <span class="cov0" title="0">startTs, endTs, err := dateutils.ToStartEnd(s, e)
        if err != nil </span><span class="cov0" title="0">{
                http.Error(w, "invalid s/e: "+err.Error(), http.StatusBadRequest)
                return
        }</span>
        <span class="cov0" title="0">if startTs &gt;= endTs </span><span class="cov0" title="0">{
                http.Error(w, "start must be &lt; end", http.StatusBadRequest)
                return
        }</span>

        <span class="cov0" title="0">orgUUID, err := uuid.Parse(orgID)
        if err != nil </span><span class="cov0" title="0">{
                http.Error(w, "invalid orgId: "+err.Error(), http.StatusBadRequest)
                return
        }</span>

        <span class="cov0" title="0">prom := r.URL.Query().Get("q")
        if prom == "" </span><span class="cov0" title="0">{
                http.Error(w, "missing query expression", http.StatusBadRequest)
                return
        }</span>

        <span class="cov0" title="0">reverse := r.URL.Query().Get("reverse")
        reverseSort := true
        if reverse != "" </span><span class="cov0" title="0">{
                reverseSort = reverse == "true"
        }</span>

        <span class="cov0" title="0">promExpr, err := FromPromQL(prom)
        if err != nil </span><span class="cov0" title="0">{
                http.Error(w, "invalid query expression: "+err.Error(), http.StatusBadRequest)
                return
        }</span>

        <span class="cov0" title="0">plan, err := Compile(promExpr)
        if err != nil </span><span class="cov0" title="0">{
                http.Error(w, "compile error: "+err.Error(), http.StatusBadRequest)
                return
        }</span>

        // Kick off evaluation; reverseSort can be toggled if you add a query param.
        <span class="cov0" title="0">resultsCh, err := q.Evaluate(r.Context(), orgUUID, startTs, endTs, plan, reverseSort)
        if err != nil </span><span class="cov0" title="0">{
                http.Error(w, "evaluate error: "+err.Error(), http.StatusInternalServerError)
                return
        }</span>

        // SSE setup
        <span class="cov0" title="0">flusher, ok := w.(http.Flusher)
        if !ok </span><span class="cov0" title="0">{
                http.Error(w, "streaming unsupported", http.StatusInternalServerError)
                return
        }</span>
        <span class="cov0" title="0">w.Header().Set("Content-Type", "text/event-stream")
        w.Header().Set("Cache-Control", "no-cache")
        w.Header().Set("Connection", "keep-alive")

        writeSSE := func(event string, v any) error </span><span class="cov0" title="0">{
                var data []byte
                var err error
                if v != nil </span><span class="cov0" title="0">{
                        data, err = json.Marshal(v)
                        if err != nil </span><span class="cov0" title="0">{
                                return err
                        }</span>
                } else<span class="cov0" title="0"> {
                        data = []byte(`null`)
                }</span>
                // Write SSE frame
                <span class="cov0" title="0">if _, err := fmt.Fprintf(w, "event: %s\n", event); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if _, err := w.Write([]byte("data: ")); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if _, err := w.Write(data); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">if _, err := w.Write([]byte("\n\n")); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">flusher.Flush()
                return nil</span>
        }

        // Stream results until channel closes or client disconnects.
        <span class="cov0" title="0">notify := r.Context().Done()
        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-notify:<span class="cov0" title="0">
                        // client went away; stop work
                        slog.Info("client disconnected; stopping stream")
                        return</span>
                case res, ok := &lt;-resultsCh:<span class="cov0" title="0">
                        if !ok </span><span class="cov0" title="0">{
                                // End of stream: send a final "done" event.
                                _ = writeSSE("done", map[string]string{"status": "ok"})
                                return
                        }</span>
                        // Stream one result tick
                        <span class="cov0" title="0">if err := writeSSE("result", res); err != nil </span><span class="cov0" title="0">{
                                slog.Error("write SSE failed", "error", err)
                                return
                        }</span>
                }
        }
}

func (q *QuerierService) Run(doneCtx context.Context) error <span class="cov0" title="0">{
        slog.Info("Starting querier service")

        mux := http.NewServeMux()

        mux.Handle("/api/v1/query", q)

        srv := &amp;http.Server{
                Addr:    ":8080",
                Handler: mux, // use mux instead of q directly
        }

        go func() </span><span class="cov0" title="0">{
                if err := srv.ListenAndServe(); err != nil &amp;&amp; !errors.Is(err, http.ErrServerClosed) </span><span class="cov0" title="0">{
                        slog.Error("Failed to start HTTP server", slog.Any("error", err))
                }</span>
        }()

        <span class="cov0" title="0">&lt;-doneCtx.Done()

        slog.Info("Shutting down querier service")
        if err := srv.Shutdown(context.Background()); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to shutdown HTTP server", slog.Any("error", err))
                return fmt.Errorf("failed to shutdown HTTP server: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file125" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "time"
)

// ScalarNode holds a literal scalar value.
type ScalarNode struct {
        Value float64
}

func (n *ScalarNode) Hints() ExecHints <span class="cov0" title="0">{ return ExecHints{} }</span>

func (n *ScalarNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        return map[string]EvalResult{
                "default": {
                        Timestamp: sg.Timestamp,
                        Value:     Value{Kind: ValScalar, Num: n.Value},
                        Tags:      map[string]any{}, // no labels on a pure scalar
                },
        }
}</span>

type ScalarOfNode struct {
        Child ExecNode
}

func (n *ScalarOfNode) Hints() ExecHints <span class="cov0" title="0">{ return n.Child.Hints() }</span>

func (n *ScalarOfNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        m := n.Child.Eval(sg, step)
        if len(m) != 1 </span><span class="cov0" title="0">{
                return map[string]EvalResult{"default": {
                        Timestamp: sg.Timestamp,
                        Value:     Value{Kind: ValScalar, Num: math.NaN()},
                        Tags:      map[string]any{},
                }}
        }</span>
        <span class="cov0" title="0">for _, r := range m </span><span class="cov0" title="0">{ // the only element
                if r.Value.Kind != ValScalar || math.IsNaN(r.Value.Num) </span><span class="cov0" title="0">{
                        return map[string]EvalResult{"default": {
                                Timestamp: sg.Timestamp,
                                Value:     Value{Kind: ValScalar, Num: math.NaN()},
                                Tags:      map[string]any{},
                        }}
                }</span>
                <span class="cov0" title="0">return map[string]EvalResult{"default": {
                        Timestamp: sg.Timestamp,
                        Value:     Value{Kind: ValScalar, Num: r.Value.Num},
                        Tags:      map[string]any{},
                }}</span>
        }
        // unreachable, but keep compiler happy
        <span class="cov0" title="0">return map[string]EvalResult{}</span>
}
</pre>
		
		<pre class="file" id="file126" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "fmt"
        "math"
        "sort"
        "strings"
        "time"

        "github.com/prometheus/common/model"
)

var supportedFuncs = map[string]bool{
        "sum_over_time":      true,
        "avg_over_time":      true,
        "min_over_time":      true,
        "max_over_time":      true,
        "rate":               true,
        "irate":              true, // same SQL as rate; API can do last-two-samples nuance later if needed
        "increase":           true,
        "quantile_over_time": false, // needs DDS
        "histogram_quantile": false, // needs DDS
        "":                   true,  // raw/instant (we still bucket for step)
}

// ToWorkerSQL builds a per-step, per-group SQL (DuckDB).
// We always bucket to `step`; for *_over_time/rate/increase we apply a ROWS
// window of K-1 PRECEDING, where K = ceil(range/step). Output is 1 row per step bucket.
func (be *BaseExpr) ToWorkerSQL(step time.Duration) string <span class="cov8" title="1">{
        // Sketch-required paths → worker should return sketches
        if be.WantDDS </span><span class="cov0" title="0">{
                return ""
        }</span>
        // If func not supported and it's not a topk/bottomk child, skip SQL
        <span class="cov8" title="1">if !supportedFuncs[be.FuncName] &amp;&amp; !(be.WantTopK || be.WantBottomK) </span><span class="cov0" title="0">{
                return ""
        }</span>

        // COUNT fast-path: COUNT-by-group with no identity collapse → pure SQL
        <span class="cov8" title="1">if be.WantCount &amp;&amp; equalStringSets(be.CountOnBy, be.GroupBy) </span><span class="cov0" title="0">{
                return buildStepOnly(be, []proj{{"COUNT(*)", "count"}}, step)
        }</span>
        // Identity collapse (distinct series counting) → HLL path
        <span class="cov8" title="1">if be.WantCount &amp;&amp; !equalStringSets(be.CountOnBy, be.GroupBy) </span><span class="cov0" title="0">{
                return ""
        }</span>

        <span class="cov8" title="1">switch be.FuncName </span>{
        // Sliding-window functions (need range)
        case "sum_over_time":<span class="cov0" title="0">
                return buildWindowed(be, need{sum: true}, step)</span>
        case "avg_over_time":<span class="cov0" title="0">
                return buildWindowed(be, need{sum: true, count: true}, step)</span>
        case "min_over_time":<span class="cov0" title="0">
                return buildWindowed(be, need{min: true}, step)</span>
        case "max_over_time":<span class="cov0" title="0">
                return buildWindowed(be, need{max: true}, step)</span>
        case "rate", "irate":<span class="cov8" title="1">
                // rate = sum_over_time / range_seconds. We push sum window; API can divide by range.
                return buildWindowed(be, need{sum: true}, step)</span>
        case "increase":<span class="cov0" title="0">
                // increase = sum_over_time (over counter deltas). Same windowed SUM; API uses as-is.
                return buildWindowed(be, need{sum: true}, step)</span>

        // Raw/instant—just step bucket aggregates (no sliding window)
        case "":<span class="cov0" title="0">
                return buildStepOnly(be, []proj{
                        {"SUM(rollup_sum)", "sum"},
                        {"COUNT(rollup_count)", "count"},
                }, step)</span>

        default:<span class="cov0" title="0">
                return ""</span>
        }
}

type proj struct{ expr, alias string }

type need struct {
        sum, count, min, max bool
}

const (
        timePredicate = "\"_cardinalhq.timestamp\" &gt;= {start} AND \"_cardinalhq.timestamp\" &lt; {end}"
)

// buildStepOnly: densify to one row per step (+ per group), join step aggregates.
func buildStepOnly(be *BaseExpr, projs []proj, step time.Duration) string <span class="cov0" title="0">{
        stepMs := step.Milliseconds()
        bucketExpr := fmt.Sprintf("(\"_cardinalhq.timestamp\" - (\"_cardinalhq.timestamp\" %% %d))", stepMs)

        where := whereFor(be)
        timeWhere := withTime(where)

        buckets := fmt.Sprintf("buckets AS (SELECT range AS bucket_ts FROM range({start}, {end}, %d))", stepMs)

        var groupsCTE, gridCTE, gridFrom string
        if len(be.GroupBy) &gt; 0 </span><span class="cov0" title="0">{
                groupsCTE = "groups AS (SELECT DISTINCT " + strings.Join(be.GroupBy, ", ") + " FROM {table}" + timeWhere + ")"
                gridCTE = "grid AS (SELECT bucket_ts, " + strings.Join(be.GroupBy, ", ") + " FROM buckets CROSS JOIN groups)"
                gridFrom = "grid g"
        }</span> else<span class="cov0" title="0"> {
                gridFrom = "buckets b"
        }</span>

        // Step aggregates
        <span class="cov0" title="0">stepCols := []string{bucketExpr + " AS bucket_ts"}
        needSum, needCount := false, false
        for _, p := range projs </span><span class="cov0" title="0">{
                switch p.alias </span>{
                case "sum":<span class="cov0" title="0">
                        needSum = true</span>
                case "count":<span class="cov0" title="0">
                        needCount = true</span>
                }
        }
        <span class="cov0" title="0">if needSum </span><span class="cov0" title="0">{
                stepCols = append(stepCols, "SUM(rollup_sum) AS step_sum")
        }</span>
        <span class="cov0" title="0">if needCount </span><span class="cov0" title="0">{
                stepCols = append(stepCols, "COUNT(rollup_count) AS step_count")
        }</span>
        <span class="cov0" title="0">if len(be.GroupBy) &gt; 0 </span><span class="cov0" title="0">{
                stepCols = append(stepCols, strings.Join(be.GroupBy, ", "))
        }</span>
        <span class="cov0" title="0">stepAgg := "step_aggr AS (SELECT " + strings.Join(stepCols, ", ") +
                " FROM {table}" + timeWhere +
                groupByClause(be.GroupBy, "bucket_ts") + ")"

        // Final select: join grid with step aggregates; COALESCE sums/counts to 0
        var outCols []string
        outCols = append(outCols, "bucket_ts")
        if len(be.GroupBy) &gt; 0 </span><span class="cov0" title="0">{
                outCols = append(outCols, strings.Join(be.GroupBy, ", "))
        }</span>
        <span class="cov0" title="0">for _, p := range projs </span><span class="cov0" title="0">{
                switch p.alias </span>{
                case "sum":<span class="cov0" title="0">
                        outCols = append(outCols, "COALESCE(sa.step_sum, 0) AS sum")</span>
                case "count":<span class="cov0" title="0">
                        outCols = append(outCols, "COALESCE(sa.step_count, 0) AS count")</span>
                default:<span class="cov0" title="0">
                        outCols = append(outCols, fmt.Sprintf("%s AS %s", p.expr, p.alias))</span>
                }
        }

        <span class="cov0" title="0">var joinKeys string
        if len(be.GroupBy) &gt; 0 </span><span class="cov0" title="0">{
                joinKeys = "USING (bucket_ts, " + strings.Join(be.GroupBy, ", ") + ")"
        }</span> else<span class="cov0" title="0"> {
                joinKeys = "USING (bucket_ts)"
        }</span>

        <span class="cov0" title="0">withs := []string{buckets}
        if groupsCTE != "" </span><span class="cov0" title="0">{
                withs = append(withs, groupsCTE, gridCTE)
        }</span>
        <span class="cov0" title="0">withs = append(withs, stepAgg)

        sql := "WITH " + strings.Join(withs, ", ") +
                " SELECT " + strings.Join(outCols, ", ") +
                " FROM " + gridFrom +
                " LEFT JOIN step_aggr sa " + joinKeys

        if len(be.GroupBy) == 0 </span><span class="cov0" title="0">{
                sql += " WHERE EXISTS (SELECT 1 FROM step_aggr)"
        }</span>

        <span class="cov0" title="0">sql += " ORDER BY bucket_ts ASC"
        return sql</span>
}

// buildWindowed: densify grid then window over step aggregates.
func buildWindowed(be *BaseExpr, need need, step time.Duration) string <span class="cov8" title="1">{
        stepMs := step.Milliseconds()
        bucketExpr := fmt.Sprintf("(\"_cardinalhq.timestamp\" - (\"_cardinalhq.timestamp\" %% %d))", stepMs)

        where := whereFor(be)
        timeWhere := withTime(where)

        // CTE: buckets
        buckets := fmt.Sprintf("buckets AS (SELECT range AS bucket_ts FROM range({start}, {end}, %d))", stepMs)

        // Optional groups/grid CTEs
        var groupsCTE, gridCTE, gridFrom string
        if len(be.GroupBy) &gt; 0 </span><span class="cov8" title="1">{
                groupsCTE = "groups AS (SELECT DISTINCT " + strings.Join(be.GroupBy, ", ") + " FROM {table}" + timeWhere + ")"
                gridCTE = "grid AS (SELECT bucket_ts, " + strings.Join(be.GroupBy, ", ") + " FROM buckets CROSS JOIN groups)"
                gridFrom = "grid g"
        }</span> else<span class="cov8" title="1"> {
                gridFrom = "buckets b"
        }</span>

        // Step aggregates (per step + group)
        <span class="cov8" title="1">stepCols := []string{bucketExpr + " AS bucket_ts"}
        if need.sum </span><span class="cov8" title="1">{
                stepCols = append(stepCols, "SUM(rollup_sum) AS step_sum")
        }</span>
        <span class="cov8" title="1">if need.count </span><span class="cov0" title="0">{
                stepCols = append(stepCols, "COUNT(rollup_count) AS step_count")
        }</span>
        <span class="cov8" title="1">if need.min </span><span class="cov0" title="0">{
                stepCols = append(stepCols, "MIN(rollup_min) AS step_min")
        }</span>
        <span class="cov8" title="1">if need.max </span><span class="cov0" title="0">{
                stepCols = append(stepCols, "MAX(rollup_max) AS step_max")
        }</span>
        <span class="cov8" title="1">if len(be.GroupBy) &gt; 0 </span><span class="cov8" title="1">{
                stepCols = append(stepCols, strings.Join(be.GroupBy, ", "))
        }</span>
        <span class="cov8" title="1">stepAgg := "step_aggr AS (SELECT " + strings.Join(stepCols, ", ") +
                " FROM {table}" + timeWhere +
                groupByClause(be.GroupBy, "bucket_ts") + ")"

        // Window frame size
        kMinus1 := rowsPreceding(be.Range, step)

        // Final select: join grid with step_aggr; COALESCE sum/count to 0 before windowing
        var baseCols []string
        baseCols = append(baseCols, "bucket_ts")
        if len(be.GroupBy) &gt; 0 </span><span class="cov8" title="1">{
                baseCols = append(baseCols, strings.Join(be.GroupBy, ", "))
        }</span>
        <span class="cov8" title="1">if need.sum </span><span class="cov8" title="1">{
                baseCols = append(baseCols, "COALESCE(sa.step_sum, 0) AS w_step_sum")
        }</span>
        <span class="cov8" title="1">if need.count </span><span class="cov0" title="0">{
                baseCols = append(baseCols, "COALESCE(sa.step_count, 0) AS w_step_count")
        }</span>
        <span class="cov8" title="1">if need.min </span><span class="cov0" title="0">{
                // min/max: leave NULLs; window MIN/MAX of NULLs stays NULL until a value appears
                baseCols = append(baseCols, "sa.step_min AS w_step_min")
        }</span>
        <span class="cov8" title="1">if need.max </span><span class="cov0" title="0">{
                baseCols = append(baseCols, "sa.step_max AS w_step_max")
        }</span>

        <span class="cov8" title="1">var part string
        if len(be.GroupBy) &gt; 0 </span><span class="cov8" title="1">{
                part = "PARTITION BY " + strings.Join(be.GroupBy, ", ")
        }</span>

        <span class="cov8" title="1">order := " ORDER BY bucket_ts"
        var outCols []string
        outCols = append(outCols, "bucket_ts")
        if len(be.GroupBy) &gt; 0 </span><span class="cov8" title="1">{
                outCols = append(outCols, strings.Join(be.GroupBy, ", "))
        }</span>
        <span class="cov8" title="1">if need.sum </span><span class="cov8" title="1">{
                outCols = append(outCols,
                        fmt.Sprintf("SUM(w_step_sum) OVER (%s%s ROWS BETWEEN %d PRECEDING AND CURRENT ROW) AS sum", part, order, kMinus1))
        }</span>
        <span class="cov8" title="1">if need.count </span><span class="cov0" title="0">{
                outCols = append(outCols,
                        fmt.Sprintf("SUM(w_step_count) OVER (%s%s ROWS BETWEEN %d PRECEDING AND CURRENT ROW) AS count", part, order, kMinus1))
        }</span>
        <span class="cov8" title="1">if need.min </span><span class="cov0" title="0">{
                outCols = append(outCols,
                        fmt.Sprintf("MIN(w_step_min) OVER (%s%s ROWS BETWEEN %d PRECEDING AND CURRENT ROW) AS min", part, order, kMinus1))
        }</span>
        <span class="cov8" title="1">if need.max </span><span class="cov0" title="0">{
                outCols = append(outCols,
                        fmt.Sprintf("MAX(w_step_max) OVER (%s%s ROWS BETWEEN %d PRECEDING AND CURRENT ROW) AS max", part, order, kMinus1))
        }</span>

        <span class="cov8" title="1">var joinKeys string
        if len(be.GroupBy) &gt; 0 </span><span class="cov8" title="1">{
                joinKeys = "USING (bucket_ts, " + strings.Join(be.GroupBy, ", ") + ")"
        }</span> else<span class="cov8" title="1"> {
                joinKeys = "USING (bucket_ts)"
        }</span>

        <span class="cov8" title="1">withs := []string{buckets}
        if groupsCTE != "" </span><span class="cov8" title="1">{
                withs = append(withs, groupsCTE, gridCTE)
        }</span>
        <span class="cov8" title="1">withs = append(withs, stepAgg)

        sql := "WITH " + strings.Join(withs, ", ") +
                " SELECT " + strings.Join(outCols, ", ") +
                " FROM (SELECT " + strings.Join(baseCols, ", ") + " FROM " + gridFrom +
                " LEFT JOIN step_aggr sa " + joinKeys + ")"

        // Suppress densified zero rows when nothing matched at all.
        if len(be.GroupBy) == 0 </span><span class="cov8" title="1">{
                sql += " WHERE EXISTS (SELECT 1 FROM step_aggr)"
        }</span>

        <span class="cov8" title="1">sql += " ORDER BY bucket_ts ASC"
        return sql</span>
}

// --- Helpers ----------------------------------------------------------------

func withTime(where string) string <span class="cov8" title="1">{
        if where == "" </span><span class="cov0" title="0">{
                return " WHERE " + timePredicate
        }</span>
        <span class="cov8" title="1">return where + " AND " + timePredicate</span>
}

func groupByClause(by []string, first string) string <span class="cov8" title="1">{
        parts := []string{first}
        if len(by) &gt; 0 </span><span class="cov8" title="1">{
                parts = append(parts, by...)
        }</span>
        <span class="cov8" title="1">return " GROUP BY " + strings.Join(parts, ", ")</span>
}

func rowsPreceding(rangeStr string, step time.Duration) int <span class="cov8" title="1">{
        // Default to a single-row window if no range (CURRENT ROW only)
        if rangeStr == "" </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="1">dur, err := model.ParseDuration(rangeStr)
        if err != nil </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="1">rangeMs := time.Duration(dur).Milliseconds()
        stepMs := step.Milliseconds()
        if stepMs &lt;= 0 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="1">k := int64(math.Ceil(float64(rangeMs) / float64(stepMs)))
        if k &lt;= 0 </span><span class="cov0" title="0">{
                return 0
        }</span>
        <span class="cov8" title="1">return int(k - 1)</span> // ROWS &lt;k-1&gt; PRECEDING + CURRENT covers k rows
}

func equalStringSets(a, b []string) bool <span class="cov0" title="0">{
        if len(a) != len(b) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">as := append([]string(nil), a...)
        bs := append([]string(nil), b...)
        sort.Strings(as)
        sort.Strings(bs)
        for i := range as </span><span class="cov0" title="0">{
                if as[i] != bs[i] </span><span class="cov0" title="0">{
                        return false
                }</span>
        }
        <span class="cov0" title="0">return true</span>
}

func whereFor(be *BaseExpr) string <span class="cov8" title="1">{
        var parts []string
        if be.Metric != "" </span><span class="cov8" title="1">{
                parts = append(parts, fmt.Sprintf("\"_cardinalhq.name\" = %s", sqlLit(be.Metric)))
        }</span>
        <span class="cov8" title="1">for _, m := range be.Matchers </span><span class="cov0" title="0">{
                switch m.Op </span>{
                case MatchEq:<span class="cov0" title="0">
                        parts = append(parts, fmt.Sprintf("%s = %s", m.Label, sqlLit(m.Value)))</span>
                case MatchNe:<span class="cov0" title="0">
                        parts = append(parts, fmt.Sprintf("%s &lt;&gt; %s", m.Label, sqlLit(m.Value)))</span>
                case MatchRe:<span class="cov0" title="0">
                        parts = append(parts, fmt.Sprintf("%s ~ %s", m.Label, sqlLit(m.Value)))</span>
                case MatchNre:<span class="cov0" title="0">
                        parts = append(parts, fmt.Sprintf("%s !~ %s", m.Label, sqlLit(m.Value)))</span>
                }
        }
        <span class="cov8" title="1">if len(parts) == 0 </span><span class="cov0" title="0">{
                return ""
        }</span>
        <span class="cov8" title="1">return " WHERE " + strings.Join(parts, " AND ")</span>
}

func sqlLit(s string) string <span class="cov8" title="1">{
        return "'" + strings.ReplaceAll(s, "'", "''") + "'"
}</span>
</pre>
		
		<pre class="file" id="file127" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "container/heap"
        "context"
)

// Timestamped is the constraint for mergeable items.
type Timestamped interface {
        GetTimestamp() int64
}

// MergeSorted merges N locally-sorted channels into one globally-sorted stream.
// - reverse=false =&gt; ascending
// - reverse=true  =&gt; descending
// Each input must be sorted in the same direction as `reverse`.
func MergeSorted[T Timestamped](
        ctx context.Context,
        reverse bool,
        outBuf int,
        chans ...&lt;-chan T,
) &lt;-chan T <span class="cov8" title="1">{
        out := make(chan T, outBuf)
        if len(chans) == 0 </span><span class="cov8" title="1">{
                close(out)
                return out
        }</span>

        <span class="cov8" title="1">type headMsg struct {
                src int
                val T
                ok  bool // ok=false means source has closed (explicit)
        }

        req := make([]chan struct{}, len(chans))
        rsp := make([]chan headMsg, len(chans))
        for i := range chans </span><span class="cov8" title="1">{
                req[i] = make(chan struct{}, 1)
                rsp[i] = make(chan headMsg, 1)
        }</span>

        // One goroutine per source: on request, deliver exactly one item, or a "closed".
        <span class="cov8" title="1">for i, ch := range chans </span><span class="cov8" title="1">{
                i, ch := i, ch
                go func() </span><span class="cov8" title="1">{
                        defer close(rsp[i])
                        for </span><span class="cov8" title="1">{
                                select </span>{
                                case &lt;-ctx.Done():<span class="cov0" title="0">
                                        return</span>
                                case _, ok := &lt;-req[i]:<span class="cov8" title="1">
                                        if !ok </span><span class="cov0" title="0">{
                                                return
                                        }</span>
                                        <span class="cov8" title="1">v, ok := &lt;-ch
                                        if !ok </span><span class="cov8" title="1">{
                                                // Explicit closed signal
                                                select </span>{
                                                case &lt;-ctx.Done():<span class="cov0" title="0"></span>
                                                case rsp[i] &lt;- headMsg{src: i, ok: false}:<span class="cov8" title="1"></span>
                                                }
                                                <span class="cov8" title="1">return</span>
                                        }
                                        <span class="cov8" title="1">select </span>{
                                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                                return</span>
                                        case rsp[i] &lt;- headMsg{src: i, val: v, ok: true}:<span class="cov8" title="1"></span>
                                        }
                                }
                        }
                }()
        }

        <span class="cov8" title="1">go func() </span><span class="cov8" title="1">{
                defer close(out)
                defer func() </span><span class="cov8" title="1">{
                        // Unblock sources waiting on req[i]
                        for i := range req </span><span class="cov8" title="1">{
                                close(req[i])
                        }</span>
                }()

                <span class="cov8" title="1">h := &amp;headHeap[T]{reverse: reverse}
                heap.Init(h)

                open := make([]bool, len(chans))          // source still open (not finalized)
                inHeap := make([]bool, len(chans))        // source currently has a head in heap
                closedPending := make([]bool, len(chans)) // source closed but head still in heap
                awaiting := make([]bool, len(chans))      // request sent, response not yet handled

                openCount := len(chans)   // # of sources not finalized (includes closedPending)
                initPending := len(chans) // until each source responds once (head or close)
                haveHeads := 0            // # of sources that currently have a head in the heap

                // Initially request first head from every source.
                for i := range chans </span><span class="cov8" title="1">{
                        open[i] = true
                        awaiting[i] = true
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                return</span>
                        case req[i] &lt;- struct{}{}:<span class="cov8" title="1"></span>
                        }
                }

                // Normalize any response (either a head or a close) for source i.
                <span class="cov8" title="1">handleRsp := func(i int, m headMsg, ok bool) </span><span class="cov8" title="1">{
                        if awaiting[i] </span><span class="cov8" title="1">{
                                awaiting[i] = false
                                if initPending &gt; 0 </span><span class="cov8" title="1">{
                                        initPending--
                                }</span>
                        }

                        <span class="cov8" title="1">if !ok </span><span class="cov0" title="0">{
                                // rsp[i] channel itself is closed (source goroutine exited).
                                if inHeap[i] </span><span class="cov0" title="0">{
                                        closedPending[i] = true
                                }</span> else<span class="cov0" title="0"> if open[i] </span><span class="cov0" title="0">{
                                        open[i] = false
                                        openCount--
                                }</span>
                                <span class="cov0" title="0">return</span>
                        }

                        <span class="cov8" title="1">if !m.ok </span><span class="cov8" title="1">{
                                // Explicit closed signal from source (no head payload).
                                if inHeap[i] </span><span class="cov0" title="0">{
                                        closedPending[i] = true
                                }</span> else<span class="cov8" title="1"> if open[i] </span><span class="cov8" title="1">{
                                        open[i] = false
                                        openCount--
                                }</span>
                                <span class="cov8" title="1">return</span>
                        }

                        // m.ok == true → a real head
                        <span class="cov8" title="1">if !inHeap[i] </span><span class="cov8" title="1">{
                                heap.Push(h, head[T]{src: i, val: m.val})
                                inHeap[i] = true
                                haveHeads++
                        }</span>
                }

                // Pull any ready responses without blocking.
                <span class="cov8" title="1">pollAll := func() </span><span class="cov8" title="1">{
                        for i := range chans </span><span class="cov8" title="1">{
                                // We may get either a response we are awaiting, or a channel close.
                                if !(awaiting[i] || open[i] || closedPending[i]) </span><span class="cov8" title="1">{
                                        continue</span>
                                }
                                <span class="cov8" title="1">select </span>{
                                case &lt;-ctx.Done():<span class="cov0" title="0">
                                        return</span>
                                case m, ok := &lt;-rsp[i]:<span class="cov8" title="1">
                                        handleRsp(i, m, ok)</span>
                                default:<span class="cov8" title="1"></span>
                                }
                        }
                }

                // Block for exactly one response to progress, but only from sources that owe a response.
                <span class="cov8" title="1">waitOne := func() bool </span><span class="cov8" title="1">{
                        idx := -1
                        for i := range chans </span><span class="cov8" title="1">{
                                if awaiting[i] </span><span class="cov8" title="1">{
                                        idx = i
                                        break</span>
                                }
                        }
                        <span class="cov8" title="1">if idx == -1 </span><span class="cov0" title="0">{
                                return false
                        }</span>
                        <span class="cov8" title="1">select </span>{
                        case &lt;-ctx.Done():<span class="cov8" title="1">
                                return false</span>
                        case m, ok := &lt;-rsp[idx]:<span class="cov8" title="1">
                                handleRsp(idx, m, ok)
                                return true</span>
                        }
                }

                <span class="cov8" title="1">for </span><span class="cov8" title="1">{
                        pollAll()

                        // Only emit when every still-open source currently has a head in the heap.
                        if initPending == 0 &amp;&amp; haveHeads == openCount &amp;&amp; h.Len() &gt; 0 </span><span class="cov8" title="1">{
                                best := heap.Pop(h).(head[T])
                                src := best.src
                                inHeap[src] = false
                                haveHeads--

                                // If this source had already closed, now finalize it after its head is popped.
                                if closedPending[src] </span><span class="cov0" title="0">{
                                        closedPending[src] = false
                                        if open[src] </span><span class="cov0" title="0">{
                                                open[src] = false
                                                openCount--
                                        }</span>
                                } else<span class="cov8" title="1"> {
                                        // Request next head from the still-open source.
                                        awaiting[src] = true
                                        select </span>{
                                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                                return</span>
                                        case req[src] &lt;- struct{}{}:<span class="cov8" title="1"></span>
                                        }
                                }

                                // Emit the chosen item.
                                <span class="cov8" title="1">select </span>{
                                case &lt;-ctx.Done():<span class="cov0" title="0">
                                        return</span>
                                case out &lt;- best.val:<span class="cov8" title="1"></span>
                                }
                                <span class="cov8" title="1">continue</span>
                        }

                        // If no open sources remain and heap empty → done.
                        <span class="cov8" title="1">if openCount == 0 &amp;&amp; h.Len() == 0 </span><span class="cov8" title="1">{
                                return
                        }</span>

                        // Otherwise block for one awaited response to make progress (or exit on ctx).
                        <span class="cov8" title="1">if !waitOne() </span><span class="cov8" title="1">{
                                select </span>{
                                case &lt;-ctx.Done():<span class="cov8" title="1">
                                        return</span>
                                default:<span class="cov0" title="0"></span>
                                }
                        }
                }
        }()

        <span class="cov8" title="1">return out</span>
}

// ----- heap plumbing -----

type head[T Timestamped] struct {
        src int
        val T
}

type headHeap[T Timestamped] struct {
        data    []head[T]
        reverse bool
}

func (h *headHeap[T]) Len() int <span class="cov8" title="1">{ return len(h.data) }</span>
func (h *headHeap[T]) Less(i, j int) bool <span class="cov8" title="1">{
        ti := h.data[i].val.GetTimestamp()
        tj := h.data[j].val.GetTimestamp()
        if h.reverse </span><span class="cov8" title="1">{
                return ti &gt; tj // Pop will return the "smallest", i.e., the largest timestamp here.
        }</span>
        <span class="cov8" title="1">return ti &lt; tj</span>
}
func (h *headHeap[T]) Swap(i, j int) <span class="cov8" title="1">{ h.data[i], h.data[j] = h.data[j], h.data[i] }</span>
func (h *headHeap[T]) Push(x any)    <span class="cov8" title="1">{ h.data = append(h.data, x.(head[T])) }</span>
func (h *headHeap[T]) Pop() any <span class="cov8" title="1">{
        n := len(h.data)
        v := h.data[n-1]
        h.data = h.data[:n-1]
        return v
}</span>
</pre>
		
		<pre class="file" id="file128" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "sort"
        "time"
)

type SegmentInfo struct {
        DateInt     int    `json:"dateInt"`
        Hour        string `json:"hour"`
        SegmentID   string `json:"segmentId"`
        StartTs     int64  `json:"startTs"`
        EndTs       int64  `json:"endTs"`
        ExprID      string `json:"exprId"`
        Dataset     string `json:"dataset"`
        BucketName  string `json:"bucketName"`
        CustomerID  string `json:"customerId"`
        CollectorID string `json:"collectorId"`
        Frequency   int64  `json:"frequency"`
}

type SegmentGroup struct {
        StartTs  int64
        EndTs    int64
        Segments []SegmentInfo
}

// ComputeReplayBatchesWithWorkers Public entrypoint: takes workers, computes targetSize internally.
func ComputeReplayBatchesWithWorkers(
        segments []SegmentInfo,
        step time.Duration,
        queryStartTs, queryEndTs int64,
        workers int,
        reverseSort bool,
) []SegmentGroup <span class="cov8" title="1">{
        ts := TargetSize(len(segments), workers)
        return ComputeReplayBatches(
                segments,
                step,
                queryStartTs,
                queryEndTs,
                ts,
                reverseSort,
        )
}</span>

// ComputeReplayBatches computes batches of segments to replay over a time window.
func ComputeReplayBatches(
        segments []SegmentInfo,
        step time.Duration,
        queryStartTs, queryEndTs int64,
        targetSize int,
        reverseSort bool,
) []SegmentGroup <span class="cov8" title="1">{
        if len(segments) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">if targetSize &lt;= 0 </span><span class="cov0" title="0">{
                targetSize = len(segments)
        }</span>

        <span class="cov8" title="1">windows := buildWindows(segments, step, queryStartTs, queryEndTs)

        sort.Slice(windows, func(i, j int) bool </span><span class="cov8" title="1">{
                if windows[i].StartTs == windows[j].StartTs </span><span class="cov0" title="0">{
                        return windows[i].EndTs &lt; windows[j].EndTs
                }</span>
                <span class="cov8" title="1">return windows[i].StartTs &lt; windows[j].StartTs</span>
        })

        <span class="cov8" title="1">batches := coalesceContiguous(windows, targetSize)

        if reverseSort </span><span class="cov8" title="1">{
                for i, j := 0, len(batches)-1; i &lt; j; i, j = i+1, j-1 </span><span class="cov8" title="1">{
                        batches[i], batches[j] = batches[j], batches[i]
                }</span>
        }

        <span class="cov8" title="1">for i := range batches </span><span class="cov8" title="1">{
                batches[i] = normalizeAndMerge(batches[i], queryStartTs, queryEndTs)
        }</span>
        <span class="cov8" title="1">return batches</span>
}

// ---- internals ----

// Align each segment to step, clamp to query, then group by exact [start,end).
func buildWindows(segs []SegmentInfo, step time.Duration, qStart, qEnd int64) []SegmentGroup <span class="cov8" title="1">{
        stepMs := step.Milliseconds()
        if stepMs &lt;= 0 </span><span class="cov0" title="0">{
                stepMs = 1
        }</span>

        <span class="cov8" title="1">type key struct{ s, e int64 }
        buckets := map[key][]SegmentInfo{}

        align := func(ts int64) int64 </span><span class="cov8" title="1">{
                // Truncate down to step boundary
                return ts - (ts % stepMs)
        }</span>
        <span class="cov8" title="1">ceilToStep := func(ts int64) int64 </span><span class="cov8" title="1">{
                if r := ts % stepMs; r == 0 </span><span class="cov8" title="1">{
                        return ts
                }</span>
                <span class="cov0" title="0">return ts + (stepMs - (ts % stepMs))</span>
        }

        <span class="cov8" title="1">for _, s := range segs </span><span class="cov8" title="1">{
                // align to step
                as := align(s.StartTs)
                ae := ceilToStep(s.EndTs)
                // clamp to query
                if as &lt; qStart </span><span class="cov8" title="1">{
                        as = qStart - (qStart % stepMs) // align/clamp boundary too
                }</span>
                <span class="cov8" title="1">if ae &gt; qEnd </span><span class="cov8" title="1">{
                        ae = ceilToStep(qEnd)
                }</span>
                <span class="cov8" title="1">if as &gt;= ae </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov8" title="1">s2 := s
                s2.StartTs = as
                s2.EndTs = ae
                k := key{as, ae}
                buckets[k] = append(buckets[k], s2)</span>
        }

        <span class="cov8" title="1">wins := make([]SegmentGroup, 0, len(buckets))
        for k, list := range buckets </span><span class="cov8" title="1">{
                wins = append(wins, SegmentGroup{
                        StartTs:  k.s,
                        EndTs:    k.e,
                        Segments: list,
                })
        }</span>
        <span class="cov8" title="1">return wins</span>
}

// Greedy pack adjacent windows into batches by time. Flush on gaps or when targetSize reached.
func coalesceContiguous(wins []SegmentGroup, targetSize int) []SegmentGroup <span class="cov8" title="1">{
        if len(wins) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov8" title="1">var out []SegmentGroup

        var curStart, curEnd int64
        var curSegs []SegmentInfo
        var curCount int

        flush := func() </span><span class="cov8" title="1">{
                if len(curSegs) == 0 </span><span class="cov8" title="1">{
                        return
                }</span>
                <span class="cov8" title="1">out = append(out, SegmentGroup{
                        StartTs:  curStart,
                        EndTs:    curEnd,
                        Segments: curSegs,
                })
                curStart, curEnd = 0, 0
                curSegs = nil
                curCount = 0</span>
        }

        <span class="cov8" title="1">for idx, w := range wins </span><span class="cov8" title="1">{
                if idx == 0 </span><span class="cov8" title="1">{
                        curStart, curEnd = w.StartTs, w.EndTs
                        curSegs = append(curSegs, w.Segments...)
                        curCount += len(w.Segments)
                        continue</span>
                }

                // Contiguity check: no gaps between previous end and this start.
                <span class="cov8" title="1">if w.StartTs != curEnd </span><span class="cov8" title="1">{
                        // Time gap → flush regardless of count
                        flush()
                        curStart, curEnd = w.StartTs, w.EndTs
                        curSegs = append(curSegs, w.Segments...)
                        curCount += len(w.Segments)
                        continue</span>
                }

                // Extend current batch
                <span class="cov8" title="1">curEnd = w.EndTs
                curSegs = append(curSegs, w.Segments...)
                curCount += len(w.Segments)

                // If we've hit target size (or exceeded), flush this contiguous block.
                if curCount &gt;= targetSize </span><span class="cov8" title="1">{
                        flush()
                }</span>
        }
        <span class="cov8" title="1">flush()

        // (Optional) small-tail rebalance: if we produced ≥2 batches and the last batch is tiny,
        // merge it into the previous one to avoid stragglers.
        if len(out) &gt;= 2 </span><span class="cov8" title="1">{
                last := &amp;out[len(out)-1]
                prev := &amp;out[len(out)-2]
                if len(last.Segments) &lt; targetSize/3 </span><span class="cov0" title="0">{
                        // merge into prev
                        prev.EndTs = last.EndTs
                        prev.Segments = append(prev.Segments, last.Segments...)
                        out = out[:len(out)-1]
                }</span>
        }

        <span class="cov8" title="1">return out</span>
}

// Within a batch, widen duplicates by (SegmentID, ExprID) to the batch window
// and clamp to [queryStart, queryEnd]. This ensures each worker reads a single
// contiguous time window per (segment, expr).
func normalizeAndMerge(g SegmentGroup, qStart, qEnd int64) SegmentGroup <span class="cov8" title="1">{
        start := g.StartTs
        end := g.EndTs
        if start &lt; qStart </span><span class="cov0" title="0">{
                start = qStart
        }</span>
        <span class="cov8" title="1">if end &gt; qEnd </span><span class="cov0" title="0">{
                end = qEnd
        }</span>
        <span class="cov8" title="1">if start &gt;= end </span><span class="cov0" title="0">{
                return SegmentGroup{}
        }</span>

        <span class="cov8" title="1">type key struct{ sid, eid string }
        merged := map[key]SegmentInfo{}

        for _, s := range g.Segments </span><span class="cov8" title="1">{
                k := key{s.SegmentID, s.ExprID}
                if cur, ok := merged[k]; ok </span><span class="cov0" title="0">{
                        // widen to batch bounds
                        cur.StartTs = start
                        cur.EndTs = end
                        merged[k] = cur
                }</span> else<span class="cov8" title="1"> {
                        ss := s
                        ss.StartTs = start
                        ss.EndTs = end
                        merged[k] = ss
                }</span>
        }

        <span class="cov8" title="1">out := make([]SegmentInfo, 0, len(merged))
        for _, s := range merged </span><span class="cov8" title="1">{
                out = append(out, s)
        }</span>
        <span class="cov8" title="1">return SegmentGroup{
                StartTs:  start,
                EndTs:    end,
                Segments: out,
        }</span>
}

func TargetSize(totalSegments, workers int) int <span class="cov8" title="1">{
        if workers &lt;= 0 </span><span class="cov0" title="0">{
                return totalSegments
        }</span>
        <span class="cov8" title="1">return int(math.Ceil(float64(totalSegments) / float64(workers)))</span>
}
</pre>
		
		<pre class="file" id="file129" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "sort"
        "time"
)

// TopKNode : TopK select K per step from child outputs (by current grouping).
type TopKNode struct {
        K     int
        Child ExecNode
}

func (n *TopKNode) Hints() ExecHints <span class="cov0" title="0">{
        // We still surface the hint upward, but worker-side topK is not used
        // since we decided to do ranking on the API over scalars.
        h := n.Child.Hints()
        h.WantTopK = true
        return h
}</span>

func (n *TopKNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        if n.K &lt;= 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>
        <span class="cov0" title="0">child := n.Child.Eval(sg, step)
        if len(child) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        <span class="cov0" title="0">type entry struct {
                key string
                val EvalResult
        }

        // Collect scalar, finite entries only.
        buf := make([]entry, 0, len(child))
        for k, r := range child </span><span class="cov0" title="0">{
                if r.Value.Kind != ValScalar || math.IsNaN(r.Value.Num) </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">buf = append(buf, entry{key: k, val: r})</span>
        }
        <span class="cov0" title="0">if len(buf) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>

        // Sort by value descending; tie-break by key for determinism.
        <span class="cov0" title="0">sort.SliceStable(buf, func(i, j int) bool </span><span class="cov0" title="0">{
                vi := buf[i].val.Value.Num
                vj := buf[j].val.Value.Num
                if vi == vj </span><span class="cov0" title="0">{
                        return buf[i].key &lt; buf[j].key
                }</span>
                <span class="cov0" title="0">return vi &gt; vj</span>
        })

        // Take top K.
        <span class="cov0" title="0">if len(buf) &gt; n.K </span><span class="cov0" title="0">{
                buf = buf[:n.K]
        }</span>

        <span class="cov0" title="0">out := make(map[string]EvalResult, len(buf))
        for _, e := range buf </span><span class="cov0" title="0">{
                // Pass through timestamp, tags, and scalar value.
                out[e.key] = e.val
        }</span>
        <span class="cov0" title="0">return out</span>
}
</pre>
		
		<pre class="file" id="file130" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package promql

import (
        "math"
        "time"
)

// UnaryNode applies a single-argument math function to the child's scalars.
type UnaryNode struct {
        Func  string // "abs","ceil","floor","exp","ln","log2","log10","sqrt","sgn"
        Child ExecNode
}

func (n *UnaryNode) Hints() ExecHints <span class="cov0" title="0">{ return n.Child.Hints() }</span>

func (n *UnaryNode) Eval(sg SketchGroup, step time.Duration) map[string]EvalResult <span class="cov0" title="0">{
        in := n.Child.Eval(sg, step)
        if len(in) == 0 </span><span class="cov0" title="0">{
                return map[string]EvalResult{}
        }</span>
        <span class="cov0" title="0">out := make(map[string]EvalResult, len(in))

        for k, r := range in </span><span class="cov0" title="0">{
                var num float64
                if r.Value.Kind == ValScalar </span><span class="cov0" title="0">{
                        num = applyUnary(n.Func, r.Value.Num)
                }</span> else<span class="cov0" title="0"> {
                        // Math funcs are scalar-only; sketches -&gt; NaN
                        num = math.NaN()
                }</span>
                <span class="cov0" title="0">out[k] = EvalResult{
                        Timestamp: r.Timestamp,
                        Tags:      r.Tags,
                        Value:     Value{Kind: ValScalar, Num: num},
                }</span>
        }
        <span class="cov0" title="0">return out</span>
}

func applyUnary(fn string, x float64) float64 <span class="cov0" title="0">{
        switch fn </span>{
        case "abs":<span class="cov0" title="0">
                return math.Abs(x)</span>
        case "ceil":<span class="cov0" title="0">
                return math.Ceil(x)</span>
        case "floor":<span class="cov0" title="0">
                return math.Floor(x)</span>
        case "exp":<span class="cov0" title="0">
                return math.Exp(x)</span>
        case "ln":<span class="cov0" title="0">
                if x &lt;= 0 || math.IsNaN(x) </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">return math.Log(x)</span>
        case "log2":<span class="cov0" title="0">
                if x &lt;= 0 || math.IsNaN(x) </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">return math.Log2(x)</span>
        case "log10":<span class="cov0" title="0">
                if x &lt;= 0 || math.IsNaN(x) </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">return math.Log10(x)</span>
        case "sqrt":<span class="cov0" title="0">
                if x &lt; 0 || math.IsNaN(x) </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">return math.Sqrt(x)</span>
        case "sgn":<span class="cov0" title="0">
                if math.IsNaN(x) </span><span class="cov0" title="0">{
                        return math.NaN()
                }</span>
                <span class="cov0" title="0">if x &gt; 0 </span><span class="cov0" title="0">{
                        return 1
                }</span>
                <span class="cov0" title="0">if x &lt; 0 </span><span class="cov0" title="0">{
                        return -1
                }</span>
                <span class="cov0" title="0">return 0</span>
        default:<span class="cov0" title="0">
                return math.NaN()</span>
        }
}
</pre>
		
		<pre class="file" id="file131" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package queryworker

import (
        "context"
        "fmt"
        "io"
        "log/slog"
        "os"
        "path/filepath"
        "sync"
        "time"

        "github.com/aws/aws-sdk-go-v2/aws"
        "github.com/aws/aws-sdk-go-v2/service/s3"
        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
)

type ParquetCache struct {
        cacheDir        string
        maxSizeMB       int64
        awsManager      *awsclient.Manager
        storageProfiler storageprofile.StorageProfileProvider
        enableCache     bool

        mu          sync.RWMutex
        cacheIndex  map[string]*CacheEntry
        totalSizeMB int64
}

type CacheEntry struct {
        LocalPath  string
        Size       int64
        AccessTime time.Time
}

type ParquetCacheConfig struct {
        CacheDir        string
        MaxSizeMB       int64
        AWSManager      *awsclient.Manager
        StorageProfiler storageprofile.StorageProfileProvider
        EnableCache     bool
}

func NewParquetCache(cfg ParquetCacheConfig) (*ParquetCache, error) <span class="cov0" title="0">{
        if cfg.EnableCache </span><span class="cov0" title="0">{
                if err := os.MkdirAll(cfg.CacheDir, 0755); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to create cache directory: %w", err)
                }</span>
        }

        <span class="cov0" title="0">cache := &amp;ParquetCache{
                cacheDir:        cfg.CacheDir,
                maxSizeMB:       cfg.MaxSizeMB,
                awsManager:      cfg.AWSManager,
                storageProfiler: cfg.StorageProfiler,
                enableCache:     cfg.EnableCache,
                cacheIndex:      make(map[string]*CacheEntry),
        }

        if cfg.EnableCache </span><span class="cov0" title="0">{
                if err := cache.loadCacheIndex(); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to load cache index", "error", err)
                }</span>
        }

        <span class="cov0" title="0">return cache, nil</span>
}

func (c *ParquetCache) GetFile(ctx context.Context, organizationID uuid.UUID, s3Key string) (string, error) <span class="cov0" title="0">{
        if !c.enableCache </span><span class="cov0" title="0">{
                return c.downloadToTemp(ctx, organizationID, s3Key)
        }</span>

        <span class="cov0" title="0">c.mu.RLock()
        entry, exists := c.cacheIndex[s3Key]
        c.mu.RUnlock()

        if exists </span><span class="cov0" title="0">{
                // Check if file still exists (immutable files never expire)
                if _, err := os.Stat(entry.LocalPath); err == nil </span><span class="cov0" title="0">{
                        // Update access time for LRU tracking
                        c.mu.Lock()
                        entry.AccessTime = time.Now()
                        c.mu.Unlock()
                        slog.Debug("Cache hit", "s3Key", s3Key, "localPath", entry.LocalPath)
                        return entry.LocalPath, nil
                }</span>
                // Remove stale entry if file was deleted externally
                <span class="cov0" title="0">c.mu.Lock()
                delete(c.cacheIndex, s3Key)
                c.totalSizeMB -= entry.Size / (1024 * 1024)
                c.mu.Unlock()</span>
        }

        // Cache miss - download file
        <span class="cov0" title="0">slog.Debug("Cache miss", "s3Key", s3Key)
        return c.downloadAndCache(ctx, organizationID, s3Key)</span>
}

func (c *ParquetCache) downloadAndCache(ctx context.Context, organizationID uuid.UUID, s3Key string) (string, error) <span class="cov0" title="0">{
        // Check if we need to make space
        c.evictIfNeeded()

        localPath := filepath.Join(c.cacheDir, filepath.Base(s3Key))
        if err := c.downloadFile(ctx, organizationID, s3Key, localPath); err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>

        <span class="cov0" title="0">stat, err := os.Stat(localPath)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to stat downloaded file: %w", err)
        }</span>

        <span class="cov0" title="0">entry := &amp;CacheEntry{
                LocalPath:  localPath,
                Size:       stat.Size(),
                AccessTime: time.Now(),
        }

        c.mu.Lock()
        c.cacheIndex[s3Key] = entry
        c.totalSizeMB += stat.Size() / (1024 * 1024)
        c.mu.Unlock()

        slog.Debug("File cached", "s3Key", s3Key, "localPath", localPath, "sizeMB", stat.Size()/(1024*1024))
        return localPath, nil</span>
}

func (c *ParquetCache) downloadToTemp(ctx context.Context, organizationID uuid.UUID, s3Key string) (string, error) <span class="cov0" title="0">{
        tempFile, err := os.CreateTemp("", "query-worker-*.parquet")
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to create temp file: %w", err)
        }</span>
        <span class="cov0" title="0">tempPath := tempFile.Name()
        tempFile.Close()

        if err := c.downloadFile(ctx, organizationID, s3Key, tempPath); err != nil </span><span class="cov0" title="0">{
                os.Remove(tempPath)
                return "", err
        }</span>

        <span class="cov0" title="0">return tempPath, nil</span>
}

// GetLowestInstanceStorageProfile gets the storage profile with the lowest instance number for an organization
func (c *ParquetCache) getLowestInstanceStorageProfile(ctx context.Context, organizationID uuid.UUID) (storageprofile.StorageProfile, error) <span class="cov0" title="0">{
        // Try instance 0 first (most common case)
        profile, err := c.storageProfiler.Get(ctx, organizationID, 0)
        if err == nil </span><span class="cov0" title="0">{
                return profile, nil
        }</span>

        // If instance 0 doesn't exist, we'd need a different approach
        // For now, return an error and let the user know we need a new query
        <span class="cov0" title="0">return storageprofile.StorageProfile{}, fmt.Errorf("no storage profile found for organization %s with instance 0. Query worker needs a method to get lowest instance number", organizationID)</span>
}

func (c *ParquetCache) downloadFile(ctx context.Context, organizationID uuid.UUID, s3Key, localPath string) error <span class="cov0" title="0">{
        slog.Debug("Downloading file", "s3Key", s3Key, "localPath", localPath)

        // Get storage profile for this organization
        profile, err := c.getLowestInstanceStorageProfile(ctx, organizationID)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get storage profile: %w", err)
        }</span>

        // Get S3 client for this profile
        <span class="cov0" title="0">s3Client, err := c.awsManager.GetS3ForProfile(ctx, profile)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get S3 client: %w", err)
        }</span>

        <span class="cov0" title="0">resp, err := s3Client.Client.GetObject(ctx, &amp;s3.GetObjectInput{
                Bucket: aws.String(profile.Bucket),
                Key:    aws.String(s3Key),
        })
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get S3 object: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        file, err := os.Create(localPath)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create local file: %w", err)
        }</span>
        <span class="cov0" title="0">defer file.Close()

        _, err = io.Copy(file, resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to copy S3 object to local file: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

func (c *ParquetCache) evictIfNeeded() <span class="cov0" title="0">{
        c.mu.Lock()
        defer c.mu.Unlock()

        if c.totalSizeMB &lt;= c.maxSizeMB </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Cache size exceeded, evicting files", "totalSizeMB", c.totalSizeMB, "maxSizeMB", c.maxSizeMB)

        // Sort entries by access time (LRU eviction)
        type entryWithKey struct {
                key   string
                entry *CacheEntry
        }

        var entries []entryWithKey
        for key, entry := range c.cacheIndex </span><span class="cov0" title="0">{
                entries = append(entries, entryWithKey{key: key, entry: entry})
        }</span>

        // Sort by access time (oldest first)
        <span class="cov0" title="0">for i := 0; i &lt; len(entries)-1; i++ </span><span class="cov0" title="0">{
                for j := i + 1; j &lt; len(entries); j++ </span><span class="cov0" title="0">{
                        if entries[i].entry.AccessTime.After(entries[j].entry.AccessTime) </span><span class="cov0" title="0">{
                                entries[i], entries[j] = entries[j], entries[i]
                        }</span>
                }
        }

        // Evict files until we're under the limit
        <span class="cov0" title="0">for _, e := range entries </span><span class="cov0" title="0">{
                if c.totalSizeMB &lt;= c.maxSizeMB*8/10 </span><span class="cov0" title="0">{ // Evict to 80% of max
                        break</span>
                }

                <span class="cov0" title="0">if err := os.Remove(e.entry.LocalPath); err != nil </span><span class="cov0" title="0">{
                        slog.Warn("Failed to remove cached file", "path", e.entry.LocalPath, "error", err)
                }</span> else<span class="cov0" title="0"> {
                        slog.Debug("Evicted cached file", "s3Key", e.key, "localPath", e.entry.LocalPath)
                }</span>

                <span class="cov0" title="0">c.totalSizeMB -= e.entry.Size / (1024 * 1024)
                delete(c.cacheIndex, e.key)</span>
        }
}

func (c *ParquetCache) loadCacheIndex() error <span class="cov0" title="0">{
        entries, err := os.ReadDir(c.cacheDir)
        if err != nil </span><span class="cov0" title="0">{
                if os.IsNotExist(err) </span><span class="cov0" title="0">{
                        return nil
                }</span>
                <span class="cov0" title="0">return err</span>
        }

        <span class="cov0" title="0">for _, entry := range entries </span><span class="cov0" title="0">{
                if entry.IsDir() </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">path := filepath.Join(c.cacheDir, entry.Name())
                info, err := entry.Info()
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Use filename as S3 key (simplified)
                <span class="cov0" title="0">cacheEntry := &amp;CacheEntry{
                        LocalPath:  path,
                        Size:       info.Size(),
                        AccessTime: info.ModTime(), // Use last modified as access time on startup
                }

                c.cacheIndex[entry.Name()] = cacheEntry
                c.totalSizeMB += info.Size() / (1024 * 1024)</span>
        }

        <span class="cov0" title="0">slog.Info("Loaded cache index", "files", len(c.cacheIndex), "totalSizeMB", c.totalSizeMB)
        return nil</span>
}

func (c *ParquetCache) Close() error <span class="cov0" title="0">{
        if !c.enableCache </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">slog.Info("Closing parquet cache", "totalFiles", len(c.cacheIndex), "totalSizeMB", c.totalSizeMB)
        return nil</span>
}
</pre>
		
		<pre class="file" id="file132" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package queryworker

import (
        "encoding/json"
        "fmt"
        "log/slog"
        "net/http"
        "time"

        "github.com/cardinalhq/lakerunner/promql"
)

func (s *Service) handlePushdown(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        if r.Method != http.MethodPost </span><span class="cov0" title="0">{
                http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
                return
        }</span>

        <span class="cov0" title="0">var request promql.PushDownRequest
        if err := json.NewDecoder(r.Body).Decode(&amp;request); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to decode pushdown request", "error", err)
                http.Error(w, "Invalid request body", http.StatusBadRequest)
                return
        }</span>

        <span class="cov0" title="0">slog.Info("Received pushdown request",
                "exprID", request.BaseExpr.ID,
                "startTs", request.StartTs,
                "endTs", request.EndTs,
                "segmentCount", len(request.Segments))

        // Set up SSE headers
        w.Header().Set("Content-Type", "text/event-stream")
        w.Header().Set("Cache-Control", "no-cache")
        w.Header().Set("Connection", "keep-alive")
        w.Header().Set("Access-Control-Allow-Origin", "*")

        flusher, ok := w.(http.Flusher)
        if !ok </span><span class="cov0" title="0">{
                http.Error(w, "Streaming unsupported", http.StatusInternalServerError)
                return
        }</span>

        <span class="cov0" title="0">ctx := r.Context()
        resultsCh := make(chan promql.SketchInput, 1024)

        // Process segments in a goroutine
        go func() </span><span class="cov0" title="0">{
                defer close(resultsCh)

                if err := s.processSegments(ctx, request, resultsCh); err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to process segments", "error", err)
                        // Send error event
                        if writeErr := s.writeSSE(w, flusher, "error", map[string]string{"error": err.Error()}); writeErr != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to write error SSE", "error", writeErr)
                        }</span>
                        <span class="cov0" title="0">return</span>
                }
        }()

        // Stream results
        <span class="cov0" title="0">for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        slog.Info("Client disconnected")
                        return</span>
                case result, ok := &lt;-resultsCh:<span class="cov0" title="0">
                        if !ok </span><span class="cov0" title="0">{
                                // End of stream
                                if writeErr := s.writeSSE(w, flusher, "done", map[string]string{"status": "complete"}); writeErr != nil </span><span class="cov0" title="0">{
                                        slog.Error("Failed to write done SSE", "error", writeErr)
                                }</span>
                                <span class="cov0" title="0">return</span>
                        }
                        <span class="cov0" title="0">if err := s.writeSSE(w, flusher, "data", result); err != nil </span><span class="cov0" title="0">{
                                slog.Error("Failed to write SSE", "error", err)
                                return
                        }</span>
                }
        }
}

func (s *Service) handleHealth(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        w.Header().Set("Content-Type", "application/json")
        response := map[string]interface{}{
                "status":    "healthy",
                "timestamp": time.Now().Unix(),
                "service":   "query-worker",
        }
        if err := json.NewEncoder(w).Encode(response); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to encode health response", "error", err)
                http.Error(w, "Internal server error", http.StatusInternalServerError)
        }</span>
}

func (s *Service) writeSSE(w http.ResponseWriter, flusher http.Flusher, event string, data interface{}) error <span class="cov0" title="0">{
        jsonData, err := json.Marshal(data)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">if _, err := fmt.Fprintf(w, "event: %s\n", event); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">if _, err := fmt.Fprintf(w, "data: %s\n\n", jsonData); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">flusher.Flush()
        return nil</span>
}
</pre>
		
		<pre class="file" id="file133" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package queryworker

import (
        "context"
        "fmt"
        "log/slog"
        "os"
        "path/filepath"

        "github.com/google/uuid"

        "github.com/cardinalhq/lakerunner/promql"
)

func (s *Service) processSegments(ctx context.Context, request promql.PushDownRequest, resultsCh chan&lt;- promql.SketchInput) error <span class="cov0" title="0">{
        for _, segment := range request.Segments </span><span class="cov0" title="0">{
                if err := ctx.Err(); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                <span class="cov0" title="0">if err := s.processSegment(ctx, request, segment, resultsCh); err != nil </span><span class="cov0" title="0">{
                        slog.Error("Failed to process segment",
                                "segmentID", segment.SegmentID,
                                "error", err)
                        continue</span> // Continue with other segments
                }
        }
        <span class="cov0" title="0">return nil</span>
}

func (s *Service) processSegment(ctx context.Context, request promql.PushDownRequest, segment promql.SegmentInfo, resultsCh chan&lt;- promql.SketchInput) error <span class="cov0" title="0">{
        // Construct S3 key from segment info
        s3Key := s.buildS3Key(segment)

        slog.Debug("Processing segment",
                "segmentID", segment.SegmentID,
                "s3Key", s3Key,
                "startTs", segment.StartTs,
                "endTs", segment.EndTs)

        // Parse organization ID from segment
        organizationID, err := uuid.Parse(segment.CustomerID)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse organization ID from segment: %w", err)
        }</span>

        // Get the Parquet file (from cache or S3)
        <span class="cov0" title="0">localPath, err := s.cache.GetFile(ctx, organizationID, s3Key)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get parquet file: %w", err)
        }</span>

        // Cleanup temp file if not cached
        <span class="cov0" title="0">if !s.cache.enableCache </span><span class="cov0" title="0">{
                defer func() </span><span class="cov0" title="0">{
                        if err := s.cache.cleanupTempFile(localPath); err != nil </span><span class="cov0" title="0">{
                                slog.Warn("Failed to cleanup temp file", "path", localPath, "error", err)
                        }</span>
                }()
        }

        // Query the Parquet file
        <span class="cov0" title="0">if err := s.queryParquetFile(ctx, localPath, request, segment, resultsCh); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to query parquet file: %w", err)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

func (s *Service) buildS3Key(segment promql.SegmentInfo) string <span class="cov0" title="0">{
        // Build S3 key based on segment metadata
        // Format: {dataset}/{customerID}/{dateInt}/{hour}/{segmentID}.parquet
        return fmt.Sprintf("%s/%s/%d/%s/%s.parquet",
                segment.Dataset,
                segment.CustomerID,
                segment.DateInt,
                segment.Hour,
                segment.SegmentID)
}</span>

func (s *Service) queryParquetFile(ctx context.Context, filePath string, request promql.PushDownRequest, segment promql.SegmentInfo, resultsCh chan&lt;- promql.SketchInput) error <span class="cov0" title="0">{
        // TODO: Implement actual Parquet querying logic
        // This would typically involve:
        // 1. Opening the Parquet file
        // 2. Applying filters based on request.StartTs, request.EndTs
        // 3. Evaluating the BaseExpr against the data
        // 4. Streaming results to resultsCh

        slog.Info("Querying parquet file",
                "filePath", filePath,
                "segmentID", segment.SegmentID,
                "exprID", request.BaseExpr.ID)

        // Placeholder implementation - generate mock data
        // In real implementation, this would read and process the Parquet file
        for i := range 10 </span><span class="cov0" title="0">{
                if err := ctx.Err(); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>

                // Mock result
                <span class="cov0" title="0">result := promql.SketchInput{
                        ExprID:         request.BaseExpr.ID,
                        OrganizationID: segment.CustomerID,
                        Timestamp:      request.StartTs + int64(i*1000), // 1 second intervals
                        Frequency:      segment.Frequency / 1000,        // Convert ms to seconds
                        SketchTags:     promql.SketchTags{},             // Empty for now
                }

                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                case resultsCh &lt;- result:<span class="cov0" title="0"></span>
                }
        }

        <span class="cov0" title="0">slog.Debug("Completed querying parquet file", "segmentID", segment.SegmentID)
        return nil</span>
}

// Add cleanup method to cache
func (c *ParquetCache) cleanupTempFile(path string) error <span class="cov0" title="0">{
        if filepath.Dir(path) == c.cacheDir </span><span class="cov0" title="0">{
                // Don't delete cached files
                return nil
        }</span>
        <span class="cov0" title="0">return os.Remove(path)</span>
}
</pre>
		
		<pre class="file" id="file134" style="display: none">// Copyright (C) 2025 CardinalHQ, Inc
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as
// published by the Free Software Foundation, version 3.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

package queryworker

import (
        "context"
        "errors"
        "fmt"
        "log/slog"
        "net/http"
        "os"
        "strconv"
        "time"

        "github.com/cardinalhq/lakerunner/internal/awsclient"
        "github.com/cardinalhq/lakerunner/internal/storageprofile"
)

type Service struct {
        port  int
        cache *ParquetCache
}

type Config struct {
        Port             int
        CacheDirectory   string
        CacheMaxSizeMB   int64
        EnableLocalCache bool
}

func NewService() (*Service, error) <span class="cov0" title="0">{
        config, err := loadConfig()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to load config: %w", err)
        }</span>

        // Initialize AWS manager
        <span class="cov0" title="0">awsManager, err := awsclient.NewManager(context.Background())
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create AWS manager: %w", err)
        }</span>

        // Initialize storage profile provider
        <span class="cov0" title="0">storageProfiler, err := storageprofile.SetupStorageProfiles()
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to setup storage profiles: %w", err)
        }</span>

        <span class="cov0" title="0">cache, err := NewParquetCache(ParquetCacheConfig{
                CacheDir:        config.CacheDirectory,
                MaxSizeMB:       config.CacheMaxSizeMB,
                AWSManager:      awsManager,
                StorageProfiler: storageProfiler,
                EnableCache:     config.EnableLocalCache,
        })
        if err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to create cache: %w", err)
        }</span>

        <span class="cov0" title="0">return &amp;Service{
                port:  config.Port,
                cache: cache,
        }, nil</span>
}

func (s *Service) Run(doneCtx context.Context) error <span class="cov0" title="0">{
        slog.Info("Starting query worker service", "port", s.port)

        mux := http.NewServeMux()
        mux.HandleFunc("/pushdown", s.handlePushdown)
        mux.HandleFunc("/health", s.handleHealth)

        srv := &amp;http.Server{
                Addr:    fmt.Sprintf(":%d", s.port),
                Handler: mux,
        }

        go func() </span><span class="cov0" title="0">{
                if err := srv.ListenAndServe(); err != nil &amp;&amp; !errors.Is(err, http.ErrServerClosed) </span><span class="cov0" title="0">{
                        slog.Error("Failed to start HTTP server", slog.Any("error", err))
                }</span>
        }()

        <span class="cov0" title="0">&lt;-doneCtx.Done()

        slog.Info("Shutting down query worker service")
        shutdownCtx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
        defer cancel()

        if err := srv.Shutdown(shutdownCtx); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to shutdown HTTP server", slog.Any("error", err))
                return fmt.Errorf("failed to shutdown HTTP server: %w", err)
        }</span>

        <span class="cov0" title="0">if err := s.cache.Close(); err != nil </span><span class="cov0" title="0">{
                slog.Error("Failed to close cache", slog.Any("error", err))
        }</span>

        <span class="cov0" title="0">return nil</span>
}

func loadConfig() (Config, error) <span class="cov0" title="0">{
        portStr := os.Getenv("QUERY_WORKER_PORT")
        if portStr == "" </span><span class="cov0" title="0">{
                portStr = "8080"
        }</span>
        <span class="cov0" title="0">port, err := strconv.Atoi(portStr)
        if err != nil </span><span class="cov0" title="0">{
                return Config{}, fmt.Errorf("invalid QUERY_WORKER_PORT: %w", err)
        }</span>

        <span class="cov0" title="0">cacheDir := os.Getenv("CACHE_DIRECTORY")
        if cacheDir == "" </span><span class="cov0" title="0">{
                cacheDir = "/tmp/query-worker-cache"
        }</span>

        <span class="cov0" title="0">cacheSizeStr := os.Getenv("CACHE_MAX_SIZE_MB")
        if cacheSizeStr == "" </span><span class="cov0" title="0">{
                cacheSizeStr = "1024" // 1GB default
        }</span>
        <span class="cov0" title="0">cacheSize, err := strconv.ParseInt(cacheSizeStr, 10, 64)
        if err != nil </span><span class="cov0" title="0">{
                return Config{}, fmt.Errorf("invalid CACHE_MAX_SIZE_MB: %w", err)
        }</span>

        <span class="cov0" title="0">enableCacheStr := os.Getenv("ENABLE_LOCAL_CACHE")
        enableCache := enableCacheStr != "false" // default to true

        return Config{
                Port:             port,
                CacheDirectory:   cacheDir,
                CacheMaxSizeMB:   cacheSize,
                EnableLocalCache: enableCache,
        }, nil</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
